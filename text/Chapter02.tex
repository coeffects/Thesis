%!TEX root = ../main.tex

% ==================================================================================================

\chapter{Pathways to coeffects} 
\label{ch:pathways} 

%---------------------------------------------------------------------------------------------------

There are many different directions from which the concept of \emph{coeffects} can be approached 
and, indeed, discovered. In the previous chapter, we motivated it by practical applications, but 
coeffects also naturally arise as an extension to a number of programming language theories.
Thanks to the Curry-Howard-Lambek correspondence, we can approach coeffects from the perspective of 
type theory, logic and also category theory. This chapter gives an overview of the most 
important directions.

We start by looking at coeffects as the dual of effect systems (Section~\ref{sec:path-eff}). Next,
we extend the duality to category theory, looking at the categorical dual of monads known as 
\emph{comonads} (Section~\ref{sec:path-sem}). Finally we look at logically inspired type systems 
that are closely related to our structural coeffects (Section~\ref{sec:path-logic}).

This chapter serves two purposes. Firstly, it provides a high-level overview of the  related work, 
although technical details are often postponed until later. Secondly it recasts existing ideas in 
a way that naturally leads to the coeffect systems developed later in the thesis. For this reason, 
we are not always faithful to the referenced work -- sometimes we focus on aspects that the 
authors consider unimportant or present the work differently than originally intended. The reason 
is to fulfil the second goal of the chapter. When we do so, this is explicitly said in the text.

%===================================================================================================

\section{Through type and effect systems}
\label{sec:path-eff}

Introduced by Gifford and Lucassen \cite{effects-gifford,effects-polymorphic}, type and effect 
systems have been designed to track effectful operations performed by computations. Examples 
include tracking of reading and writing from and to memory locations \cite{effects-talpin-et-al}, 
communication in message-passing systems \cite{effects-messagepassing} and atomicity in concurrent 
applications \cite{effects-atomicity}.

Type and effect systems are usually specified as judgements of the form $\Gamma \vdash e : \tau, \cclrd{r}$, 
meaning that the expression $e$ has a type $\tau$ in a (free-variable) context $\Gamma$ and 
additionally may have effects described by $\cclrd{r}$. Effect systems are typically added to a 
language that already supports effectful operations as a way of increasing the safety -- the type 
and effect system provides stronger guarantees than a plain type system. Filinsky 
\cite{effects-comprehensive} refers to this approach as \emph{descriptive}\footnote{In contrast 
to \emph{prescriptive} effect systems that implement computational effects in a pure language 
-- such as monads in Haskell.}.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x\!:\!\tau \in \Gamma }
  {\Gamma \vdash x : \tau, \cclrd{\emptyset} }
\end{equation*}
\begin{equation*}
\tyrule{write}
  {\Gamma \vdash e : \tau, \cclrd{r} & l:\ident{ref}_\rho~\tau\in \Gamma}
  {\Gamma \vdash l \leftarrow e : \ident{unit}, \cclrd{r} \cup \cclrd{\{\ident{write}(\rho)\}} }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\Gamma, x\!:\!\tau_1 \vdash e : \tau_2, \cclrd{r} }
  {\Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{r}} \tau_2, \cclrd{\emptyset} }
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\Gamma \vdash e_1 : \tau_1 \xrightarrow{\cclrd{r}} \tau_2, \cclrd{s} &
   \Gamma \vdash e_2 : \tau_1, \cclrd{t} }
  {\Gamma \vdash e_1~e_2 : \tau_2, \cclrd{r} \cup \cclrd{s} \cup \cclrd{t} }
\end{equation*}

\caption{Simple effect system}
\label{fig:path-eff}
\end{figure}

%---------------------------------------------------------------------------------------------------

\subsection{Simple effect system.}
The structure of a simple effect system\footnote{Most work on effect systems uses $\sigma$ for 
effect annotations. We use letters $\cclrd{r}, \cclrd{s}, \cclrd{t}$ and also distinguish effect 
or coeffect annotations by colour.} is demonstrated in Figure~\ref{fig:path-eff}. The example
shows typing rules for a simply typed lambda calculus with an additional (effectful) operation
$l \leftarrow e$ that writes the value of $e$ to a mutable location $l$. The type of locations
($\ident{ref}_\rho~\tau$) is annotated with a \emph{memory region} $\rho$ of the location $l$.
The effects tracked by the type and effect system over-approximate the actual effects and memory
regions provide a convenient way to build such over-approximation. The effects are 
represented as a set of effectful actions that an expression may perform and the effectful action
(\emph{write}) adds a primitive effect $\ident{write}(\rho)$.

The remaining rules are shared by a majority of effect systems. Variable access (\emph{var}) 
has no effects, application (\emph{app}) combines the effects of both expressions, together with 
the latent effects of the function to be applied. Finally, lambda abstraction (\emph{abs}) is a
pure computation that turns the \emph{actual} effects of the body into \emph{latent} effects of 
the created function.

%---------------------------------------------------------------------------------------------------

\subsection{Simple coeffect system.}
\label{sec:path-effects-coeff}
When writing the judgements of coeffect systems, we want to emphasize the fact that coeffect 
systems talk about \emph{context} rather than \emph{results}. For this reason, we write the 
judgements in the form $\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau$, associating the additional 
information with the context (left-hand side) of the judgement rather than with the result 
(right-hand side) as in $\Gamma \vdash e : \tau, \cclrd{r}$. This change alone would not be 
very interesting -- we simply used different syntax to write a predicate with four arguments. 
The more interesting difference is how the lambda abstraction rule looks.

The language in Figure~\ref{fig:path-coeff} extends simple lambda calculus with resources and
with a construct $\kvd{access}~e$ that obtains the resource specified by the expression $e$.
Most of the typing rules correspond to those of effect systems. Variable access (\emph{var}) 
has no context requirements, application (\emph{app}) combines context requirements of the two
sub-expressions and latent context-requirements of the function. 

However, the (\emph{abs}) rule is different than the corresponding rule for effect systems -- the
resource requirements of the body $\cclrd{r} \cup \cclrd{s}$ are split between the \emph{immediate 
context-requirements} associated with the current context $\coctx{\Gamma}{\cclrd{r}}$ and the 
\emph{latent context-requirements} of the function.

As will be discussed in more detail in Section~\ref{sec:applications-flat-impl}, this means that a 
resource can be captured when a function is declared (e.g.~when it is constructed on the 
server-side where database access is available), or when a function is called (\eg~when a function 
created on server-side requires access to current time-zone, it can use the resource available on
 the client-side). In other words, resources in this example support both static (lexical) and
 dynamic scoping.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x\!:\!\tau \in \Gamma }
  {\coctx{\Gamma}{\cclrd{\emptyset}} \vdash x : \tau }
\end{equation*} 
\begin{equation*}
\tyrule{access}
  {\coctx{\Gamma}{\cclrd{r}} \vdash e : \ident{res}_\rho~\tau }
  {\coctx{\Gamma}{\cclrd{r} \cup \cclrd{ \{\ident{access}(\rho)\} }} \vdash \kvd{access}~e : \tau }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{(\Gamma, x\!:\!\tau_1)}{\cclrd{r} \cup \cclrd{s}} \vdash e : \tau_2 }
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\Gamma \vdash e_1 : \tau_1 \xrightarrow{\cclrd{r}} \tau_2, \cclrd{s} \\
   \Gamma \vdash e_2 : \tau_1, \cclrd{t} }
  {\Gamma \vdash e_1~e_2 : \tau_2, \cclrd{r}\cup\cclrd{s}\cup\cclrd{t}  }
\end{equation*}

\caption{Simple coeffect system}
\label{fig:path-coeff}
\end{figure}

%===================================================================================================

\section{Through language semantics}
\label{sec:path-sem}

Another pathway to coeffects leads through the semantics of effectful and context-dependent 
computations. In a pioneering work, Moggi \cite{monad-notions} showed that effects (including
partiality, exceptions, non-determinism and I/O) can be modelled uisng the category theoretic
notion of \emph{monad}.

When using monads, we distinguish effect-free values $\tau$ from programs, or 
computations $\mtyp{}{\tau}$. The \emph{monad} $\mtyp{}{}$ abstracts the \emph{notion of 
computation} and provides a way of constructing and composing effectful computations:

\begin{definition}
A \emph{monad} over a category $\catc$ is a triple $(M, \ident{unit}, \ident{bind})$ where:
\begin{compactitem}
\item $M$ is a mapping on objects (types) $M : \catc \rightarrow \catc$
\item $\ident{unit}$ is a mapping $\alpha \rightarrow \mtyp{}{\alpha}$ 
\item $\ident{bind}$ is a mapping $(\alpha \rightarrow \mtyp{}{\beta}) 
  \rightarrow (\mtyp{}{\alpha} \rightarrow \mtyp{}{\beta})$
\end{compactitem}
such that, for all $f:\alpha \rightarrow \mtyp{}{\beta}$ and $g:\beta \rightarrow \mtyp{}{\gamma}$:
\begin{align}
\tag{\emph{left identity}}
  \ident{bind}~\ident{unit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{bind}~f \circ \ident{unit} &= f
  \\
\tag{\emph{associativity}}
  \ident{bind}~(\ident{bind}~g \circ f) &= (\ident{bind}~f) \circ (\ident{bind}~g)
\end{align}
\end{definition}

\noindent
Without providing much details, we note that well known examples of monads include the partiality
monad ($\mtyp{}{\alpha} = \alpha + {\bot}$) also corresponding to the \ident{Maybe} type in 
Haskell, list monad ($\mtyp{}{\tau} = \mu \gamma.1 + (\tau \times \gamma)$) and other.
In programming language semantics, monads can be used in two distinct ways.

%---------------------------------------------------------------------------------------------------

\subsection{Effectful languages and meta-languages}
\label{sec:path-sem-langs}

Moggi uses monads to define two formal systems. In the first formal system, a monad is used to model 
the \emph{language} itself. This means that the semantics of a language is given in terms of a 
one specific monad and the semantics can be used to reason about programs in that language. To quote 
\emph{``When reasoning about programs one has only one monad, because the programming language is 
fixed, and the main aim is to prove properties of programs''} \cite[p. 5]{monad-notions}.

In the second formal system, monads are added to the programming language as type constructors, 
together with additional constructs corresponding to monadic \ident{bind} and \ident{unit}.
A single program can use multiple monads, but the key benefit is the ability to reason
about multiple languages. To quote \emph{``When reasoning about programming languages one has different 
monads, one for each programming language, and the main aim is to study how they relate to each 
other''} \cite[p. 5]{monad-notions}.

In this thesis, we generally follow the first approach -- this means that we work with an existing
programming language without needing to add additional constructs corresponding to the primitives
of our semantics (the alternative is discussed in Section~\ref{sec:unified-meta}). To clarify the 
difference, the following two sections show a minimal example of both formal systems. We follow 
Moggi and start with language where judgements have the form $x\!:\!\tau_1 \vdash e : \tau_2$ with 
exactly one variable\footnote{This simplifies the examples as we do not need \emph{strong} monad, 
but that is an orthogonal issue to the distinction between language semantics and meta-language.}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics.} When using monads to provide semantics of a language, we do not
need to extend the language in any way -- we assume that the language already contains the 
effectful primitives (such as the assignment operator $x \leftarrow e$ or other). A judgement
of the form $x\!:\!\tau_1 \vdash e : \tau_2$ is interpreted as a morphism $\tau_1 \rightarrow \mtyp{}{\tau_2}$,
meaning that any expression is interpreted as an effectful computation. The semantics of variable
access and the application of a primitive function $f$ is interpreted as follows:
%
\begin{equation*}
\begin{array}{rcl}
 \sem{x\!:\!\tau_1 \vdash x : \tau_1} &=& \ident{unit}_\mtyp{}{}\\
 \sem{x\!:\!\tau_1 \vdash f~e : \tau_3} &=& (\ident{bind}_\mtyp{}{}~f) \circ \sem{e}\\
\end{array}
\end{equation*}
%
Variable access is an effect-free computation, that returns the value of the variable, wrapped
using $\ident{unit}_\mtyp{}{}$. In the second rule, we assume that $e$ is an expression using
the variable $x$ and producing a value of type $\tau_2$ and that $f$ is a (primitive) function
$\tau_2 \rightarrow \mtyp{}{\tau_3}$. The semantics lifts the function $f$ using $\ident{bind}_\mtyp{}{}$
to a function $\mtyp{}{\tau_2} \rightarrow \mtyp{}{\tau_3}$ which is compatible with the 
interpretation of the expression $e$.

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation.} ~When designing meta-language based on monads, we need to
extend the lambda calculus with additional type(s) and expressions that correspond to monadic
primitives. Assuming $\alpha$ is a primitive type:
%
\begin{align*}
\tau &:= \alpha \sep \tau_1 \rightarrow \tau_2 \sep \mtyp{}{\tau} \\
   e &:= x \sep f~e \sep \kvd{return}_\mtyp{}{}~e \sep \kvd{let}_\mtyp{}{}~x \Leftarrow e_1~\kvd{in}~e_2
\end{align*}
%
The types consist of the primitive type, function type and a type constructor that 
represents monadic computations. This means that the expressions in the language can create both
effect-free values, such as $\tau$ and computations $\mtyp{}{\tau}$. The additional expression
$\kvd{return}_\mtyp{}{}$ is used to create a monadic computation (with no actual effects) from a
value and $\kvd{let}_\mtyp{}{}$ is used to sequence effectful computations. In the semantics, 
monads are not needed to interpret variable access and application, they are only used in the 
semantics of additional (monadic) constructs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x\!:\!\tau \vdash x : \tau} &=& \idf{}\\
\sem{x\!:\!\tau_1 \vdash f~e : \tau_3} &=& f \circ \sem{e}\\
\sem{x\!:\!\tau_1 \vdash \kvd{return}_\mtyp{}{}~e : \mtyp{}{\tau_2}} &=& \ident{unit}_\mtyp{}{} \circ \sem{e}\\
\sem{x\!:\!\tau_1 \vdash \kvd{let}_\mtyp{}{}~y \Leftarrow e_1~\kvd{in}~e_2 : \mtyp{}{\tau_3}} &=& 
  \ident{bind}_\mtyp{}{}~\sem{e_2} \circ \sem{e_1}
\end{array}
\end{equation*}

\noindent
In this system, the interpretation of variable access becomes a simple identity function and
application is just composition. Monadic computations are constructed explicitly using 
$\kvd{return}_\mtyp{}{}$ (interpreted as $\ident{unit}_\mtyp{}{}$) and they are also sequenced
explicitly using the $\kvd{let}_\mtyp{}{}$ construct. As noted by Moggi, the first formal system
can be easily translated to the latter by inserting appropriate monadic constructs.

Moggi regards the meta-language system as more fundamental, because \emph{``its models are more 
general''}. Indeed, this is a valid and reasonable perspective. Yet, we follow the first style,
precisely because it is \emph{less general}. As discussed in Chapter~\ref{ch:intro}, our aim is 
to develop concrete context-aware programming languages (together with their type theory and 
semantics) rather than to build a general framework for reasoning about languages with 
context-dependent properties.

%---------------------------------------------------------------------------------------------------

\subsection{Marriage of effects and monads}
\label{sec:path-sem-effects}

The work on effect systems and monads both tackle the same problem -- representing and tracking of 
computational effects. The two lines of research have been joined by Wadler and Thiemann
\cite{monads-effects-marriage}. This requires extending the categorical structure. A monadic
computation $\tau_1 \rightarrow \mtyp{}{\tau_2}$ means that the computation has \emph{some} 
effects while the judgement $x\!:\!\tau_1 \vdash e : \tau_2, \cclrd{r}$ specifies \emph{what} effects
the computation has.

To solve this mismatch, Wadler and Thiemann use a \emph{family} of monads $\mtyp{\cclrd{r}}{\tau}$
with an annotation that specifies the effects that may be performed by the computation. In their
system, an effectful function $\tau_1 \xrightarrow{\cclrd{r}} \tau_2$ is modelled as a pure 
function returning monadic computation $\tau_1 \rightarrow \mtyp{\cclrd{r}}{\tau_2}$. Similarly, the
semantics of a judgement $x\!:\!\tau_1 \vdash e : \tau_2, \cclrd{r}$ can be given as a function 
$\tau_1 \rightarrow \mtyp{\cclrd{r}}{\tau_2}$. 
The precise nature of the family of monads has been later called \emph{indexed monads} by Tate
\cite{effects-producer-semantics} and further developed by Atkey \cite{monads-parameterised-notions} 
in his work on \emph{parameterized monads} and Katsumata \cite{monads-parametric}.

\paragraph{Thesis perspective.}
The key takeaway for this thesis from the outlined line of research is that, if we want to develop a 
language with type system that captures context-dependent properties of programs more precisely,
the semantics of the language also needs to be a more fine-grained structure (akin to indexed 
monads). While monads have been used to model effects, an existing research links context-dependence
with \emph{comonads} -- the categorical dual of monads.

%---------------------------------------------------------------------------------------------------
 
\subsection{Context-dependent languages and meta-languages}
\label{sec:path-sem-contextdep}

The theoretical parts of this thesis extend the work of Uustalu and Vene who use comonads
to give the semantics of data-flow computations \cite{comonads-dataflow} and more generally, 
notions of \emph{context-dependent computations} \cite{comonads-notions}. The computations discussed 
in the latter work include streams, arrays and containers. This is a more diverse set of examples, 
but they all mostly represent forms of collections. Ahman et al. \cite{comonads-containers} discuss
the relation between comonads and \emph{containers} \cite{types-containers} in more details.

The utility of comonads has been explored by a number of authors before. Brookes and Geva
\cite{comonads-computational} use \emph{computational} comonads for intensional semantics\footnote{The
structure of a computational comonad has been also used by the author of this thesis to abstract
evaluation order of monadic computations \cite{comonads-malias}.}. In functional programming,
Kieburtz \cite{comonads-and-codata} proposed to use comonads for stream programming, but also 
handling of I/O and interoperability.

Biermann and de Paiva used comonads to model the necessity modality $\square$ in intuitionistic
modal S4 \cite{logic-intuitionistic-modal}, linking programming languages derived from modal
logics to comonads. One such language has been reconstructed by Pfenning and Davies
\cite{logic-modal-reconstruction}. Nanevski et al. extend this work to Contextual Modal Type 
Theory (CMTT) \cite{logic-cmtt}, which again shows the importance of comonads for 
\emph{context-dependent} computations.

While Uustalu and Vene use comonads to define the \emph{language semantics} (the first style
of Moggi), Nanevski, Pfenning and Davies use comonads as part of meta-language, in the form 
of $\square$ modality, to reason about context-dependent computations (the second style of 
Moggi). Before looking at the details, we use the following definition of comonad:

\begin{definition}
A \emph{comonad} over a category $\catc$ is a triple $(C, \ident{counit}, \ident{cobind})$ where:
\begin{compactitem}
\item $C$ is a mapping on objects (types) $C : \catc \rightarrow \catc$
\item $\ident{counit}$ is a mapping $\ctyp{}{\alpha} \rightarrow \alpha$ 
\item $\ident{cobind}$ is a mapping $(\ctyp{}{\alpha} \rightarrow \beta) 
  \rightarrow (\ctyp{}{\alpha} \rightarrow \ctyp{}{\beta})$
\end{compactitem}
such that, for all $f:\ctyp{}{\alpha} \rightarrow \beta$ and $g:\ctyp{}{\beta} \rightarrow \gamma$:
\begin{align}
\tag{\emph{left identity}}
  \ident{cobind}~\ident{counit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{counit} \circ \ident{cobind}~f &= f
  \\
\tag{\emph{associativity}}
  \ident{cobind}~(g \circ \ident{cobind}~f) &= (\ident{cobind}~g) \circ (\ident{cobind}~f)
\end{align}
\end{definition}

\noindent
The definition is similar to a monad with ``reversed arrows''. Intuitively, the $\ident{counit}$ 
operation extracts a value $\alpha$ from a value that carries additional context $\ctyp{}{\alpha}$.
The $\ident{cobind}$ operation turns a context-dependent function 
$\ctyp{}{\alpha} \rightarrow \beta$ into a function that takes a value with context, applies
the context-dependent function to value(s) in the context and then propagates the context. The 
next section makes this intuitive definition more concrete. More detailed discussion about
comonads can be found in Orchard's PhD thesis \cite{comonads-dom-thesis}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics.}
To demonstrate the approach of Uustalu and Vene, we consider the non-empty list comonad
$\ctyp{}{\tau} = \mu \gamma.\tau + (\tau \times \gamma)$. A value of the type is either
the last element $\tau$ or an element followed by another non-empty list $\tau \times \gamma$
(consisting of the head $\tau$ and the tail $\gamma$). Note that the list must be non-empty, 
otherwise \ident{counit} would not be a complete function (it would be undefined on empty list). In 
the following, we write $(l_1, \ldots, l_n)$ for a list of $n$ elements:
%
\begin{equation*}
\begin{array}{rcl}
\ident{counit}~(l_1, \ldots, l_n) &=& l_1\\
\ident{cobind}~f~(l_1, \ldots, l_n) &=& (f (l_1, \ldots, l_n), f (l_2, \ldots, l_n), \ldots, f (l_n))
\end{array}
\end{equation*}
%
The \ident{counit} operation returns the current (first) element of the (non-empty) list.
The \ident{cobind} operation creates a new list by applying the context-dependent function $f$
to the entire list, to the suffix of the list, to the suffix of the suffix and so on. Interestingly,
it preserves the \emph{shape} of the list as it turns a list of $n$ elements into another list
of $n$ elements.

In causal data-flow, we can interpret the list as a list consisting of past values, with the 
current value in the head. Then, the $\ident{cobind}$ operation calculates the current value
of the output based on the current and all past values of the input; the second element is
calculated based on all past values and the last element is calculated based just on the initial
input $(l_n)$. In addition to the operations of comonad, the model also uses some operations that
are specific to causal data-flow:
%
\begin{equation*}
\begin{array}{rcl}
\ident{prev}~(l_1, \ldots, l_n) &=& (l_2, \ldots, l_n)\\
\end{array}
\end{equation*}
%
The operation drops the first element from the list. In the data-flow interpretation, this means
that it returns the previous state of a value. 

Now, consider a simple data-flow language with single-variable contexts, variables, 
primitive built-in functions and a construct $\kvd{prev}~e$ that returns the previous
value of the computation $e$. We omit the typing rules, but they are simple -- assuming $e$ 
has a type $\tau$, the expression $\kvd{prev}~e$ has also type $\tau$. The fact that
the language models data-flow and values are lists (of past values) is a matter of semantics,
which is defined as follows:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x\!:\!\tau \vdash x : \tau} &=& \ident{counit}_\ctyp{}{}\\
\sem{x\!:\!\tau_1 \vdash f~e : \tau_3} &=& f \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\sem{x\!:\!\tau_1 \vdash \kvd{prev}~e : \tau_2} &=& \ident{prev} \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\end{array}
\end{equation*}
%
The semantics follows that of effectful computations using monads. A variable access is interpreted
using $\ident{counit}_\ctyp{}{}$ (obtain the value and ignore additional available context); composition
uses $\ident{cobind}_\ctyp{}{}$ to propagate the context to the function $f$ and $\kvd{prev}$
is interpreted using the primitive $\ident{prev}$ (which takes a list and returns a list).

For example, the judgement $x\!:\!\tau \vdash \kvd{prev}~(\kvd{prev}~x) : \tau$ represents an 
expression that expects context with variable $x$ and returns a stream of values before the 
previous one. The semantics of the term expresses this behaviour: 
$(\ident{prev} \circ \ident{prev} \circ (\ident{cobind}_\ctyp{}{}~\ident{counit}_\ctyp{}{}))$.
Note that the first operation is simply an identity function thanks to the comonad laws discussed 
earlier.

In the outline presented here, we ignored lambda abstraction. Similarly to monadic semantics,
where lambda abstraction requires \emph{strong} monad, the comonadic semantics also requires
additional structure called \emph{symmetric (semi)monoidal} comonads. This structure is 
responsible for the splitting of context-requirements in lambda abstraction. Note that this is 
what happens in the unusual (\emph{abs}) rule in Figure~\ref{fig:path-coeff}, which distinguishes
coeffect systems from effect systems. 

We return to this topic when discussing lambda abstraction in Section~\ref{sec:applications-structure-lam} 
and semantics of flat coeffect systems in Section~\ref{sec:flat-semantics}.

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation.} ~To briefly demonstrate the app\-roach that employs comonads
as part of a meta-language, we look at an example inspired by the work of Pfenning, Davies and 
Nanevski. We do not attempt to provide a precise overview of their work. The main purpose 
of the following discussion is to provide a different intuition behind comonads, and to present an 
example of a language that includes comonad as a type constructor, together with language primitives
corresponding to comonadic operations\footnote{In fact, Pfenning, Davies and Nanevski 
\cite{logic-modal-reconstruction,logic-cmtt} never mention comonads explicitly. This is done in later 
work by Gabbay et al. \cite{logic-cmtt-semantics},  but the connection between the language and comonads
is not as direct as in case of monadic or comonadic semantics covered in the previous section.}. 

In languages inspired by modal logics, types can have the form $\square \tau$. In the work of
Pfenning and Davies, this is the type of a term that is provable with no assumptions. In distributed 
programming language ML5 by Murphy et al. \cite{app-distributed-ml5,logic-distributed-calculus}, the 
$\square \tau$ type means \emph{mobile code}, that is code that can be evaluated at any node of a 
distributed system (the evaluation corresponds to the axiom $\square \tau \rightarrow \tau$). 
Finally, Davies and Pfenning \cite{logic-modal-staged} consider staged computations and interpret 
$\square \tau$ as a type of unevaluated expressions of type $\tau$ (with no free variables).

In Contextual Modal Type Theory, the modality $\square$ is further annotated with the free variales
of the (unevaluated) expression. We write $\square^{\cclrd{\Psi}} \tau$ for a type of expressions
that requires a context $\Psi$. The type is a comonadic counterpart to \emph{indexed monads} used by 
Wadler and Thiemann when linking monads and effect systems and, indeed, it gives rise to a language 
that tracks context-dependence of computations in a type system.

In staged computation, the type $\ctyp{\cclrd{\Psi}}{\tau}$ represents an expression 
that requires the context $\Psi$ (i.e.~the expression is an open term that requires variables $\Psi$).
The Figure~\ref{fig:modal-meta} shows two typing rules for such language. The rules directly
correspond to the two operations of a comonad and can be interpreted as follows:

\begin{itemize}
\item (\emph{eval}) corresponds to $\ident{counit} : \ctyp{\cclrd{\emptyset}}{\alpha} \rightarrow \alpha$. 
  It indicates that we can evaluate a closed (unevaluated) term and obtain a value. Interestingly, the 
  rule requires a specific context annotation (empty set of free variables). 
  It is not possible to evaluate an open term.

\item (\emph{letbox}) corresponds to $\ident{cobind} : (\ctyp{\cclrd{\Psi}}{\alpha} \rightarrow \beta) 
  \rightarrow \ctyp{\cclrd{\Psi}, \cclrd{\Phi}}{\alpha} \rightarrow \ctyp{\cclrd{\Phi}}{\beta}$. 
  Given a term which requires variable context $\cclrd{\Psi}, \cclrd{\Phi}$ 
  (expression $e_1$) and a function that turns a term needing $\cclrd{\Psi}$ into an evaluated 
  value (expression $e_2$), we can construct a term that requires just $\cclrd{\Phi}$.
\end{itemize}

\noindent
The fact that the (\emph{eval}) rule requires a specific context is an interesting relaxation
from ordinary comonads where \ident{counit} needs to be defined for all values. Here, the indexed
\ident{counit} operation needs to be defined \emph{only} on values annotated with $\emptyset$.

The annotated \ident{cobind} operation that corresponds to (\emph{letbox}). An interesting aspect 
is that it propagates the context-requirements ``backwards''. The input expression (second parameter) 
requires a combination of contexts that are required by the two components -- those required by the 
input of the function (first argument) and those required by the resulting expression (result). 
This is another key aspect that distinguishes coeffects from effect systems. We return back to 
the meta-language approach of embedding comonads in Section~\ref{sec:unified-meta}.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\inference[(eval)]
  {\Gamma \vdash e : \square^{\cclrd{\emptyset}}{\tau}}
  {\Gamma \vdash !e : \tau}
\end{equation*}
\begin{equation*}
\inference[(letbox)]
  { \Gamma \vdash e_1 : \square^{\cclrd{\Phi}, \cclrd{\Psi}}{\tau_1} & 
    \Gamma, x\!:\!\square^{\cclrd{\Phi}}{\tau_1} \vdash e_2 : \tau_2 }
  { \Gamma \vdash \kvd{let~box}~x=e_1~\kvd{in}~e_2 : \square^{\cclrd{\Psi}}{\tau_2}}
\end{equation*}

\caption{Typing for a comonadic language with contextual staged computations}
\label{fig:modal-meta}
\end{figure}

%---------------------------------------------------------------------------------------------------
  
\paragraph{Thesis perspective.}
As mentioned earlier, we are interested in designing context-dependent languages and so we
use comonads for \emph{language semantics}. Uustalu and Vene present a semantics of 
context-dependent computations in terms of comonads. We provide the rest of the story known 
from the marriage of monads and effects. We develop coeffect calculus with an type system that 
tracks the context requirements more precisely (by annotating the types) and we add indexing 
to comonads and link the two by giving a formal semantics. The indexing allows us to capture 
applications that do not fit into the model provided by plain comonads.

The \emph{meta-language} approach of Pfenning, Davies and Nanevski is closely related to
our work. Most importantly, Contextual Modal Type Theory (CMTT) uses indexed $\square$ modality
which corresponds to indexed comonads (in a similar way in which effect systems correspond to 
indexed monads). The relation between CMTT and comonads has been suggested by
Gabbay et al. \cite{logic-cmtt-semantics}, but the meta-language employed by CMTT does not 
directly correspond to comonadic operations. For example, our (\emph{letbox}) typing rule from
Figure~\ref{fig:modal-meta} is not a primitive of CMTT and would correspond to 
$\ident{box}(\cclrd{\Psi}, \ident{letbox}(e_1, x, e_2))$. Nevertheless, the indexing in 
CMTT provides a useful hint for adding indexing to the work of Uustalu and Vene.

%===================================================================================================

\section{Through substructural and bunched logics}
\label{sec:path-logic}

In the coeffect system for tracking resource usage outlined earlier, we associated additional
contextual information (set of available resources) with the variable context of the typing 
judgement: $\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau$. In other words, our work focuses on 
``what is happening on the left hand side of $\vdash$''.

In the case of resources, the additional information about the context are simply added to the
variable context (as a products), but we will later look at contextual properties that affect 
how variables are represented. More importantly, \emph{structural coeffects} link additional
information to individual variables in the context, rather than the context as a whole.

In this section, we look at type systems that reconsider $\Gamma$ in a number of ways. 
First of all, substructural type systems \cite{substruct-attpl-intro} restrict the use of variables
in the language. Most famously linear type systems introduced by Wadler \cite{substruct-linear-change} 
can guarantee that a variable is used exactly once. This has interesting implications for memory
management and I/O. 

In bunched typing developed by O'Hearn \cite{substruct-bunched}, the variable context is a tree 
formed by multiple different constructors (e.g.~one that allows sharing and one that does not). 
Most famously, bunched typing has contributed to the development of separation logic
\cite{substruct-separation-logic} (starting a fruitful line of research in software verification), 
but it is also interesting on its own. 

%---------------------------------------------------------------------------------------------------

\subsection{Substructural type systems.}

Traditionally, $\Gamma$ is viewed as a set of assumptions and typing rules admit (or explicitly
include) three transformations that manipulate the variable contexts which are shown in 
Figure~\ref{fig:substructural-rules}. The (\emph{exchange}) rule allows reordering of variables
(which is implicit when assumptions are treated as set); (\emph{weakening}) makes it possible
to discard an assumption -- this has the implication that a variable may be declared but never
used. Finally, (\emph{contraction}) makes it possible to use a single variable multiple times
(in the rule, this is done explicitly by joining multiple variables into a single one using 
substitution).

In substructural type systems, the assumptions are typically treated as a list. As a result,
they have to be manipulated explicitly. Different systems allow different subsets of the rules.
For example, \emph{affine} systems allows exchange and weakening, leading to a system where 
variable may be used at most once; in \emph{linear} systems, only exchange is permitted and so 
every variable has to be used exactly once.

When tracking context-dependent properties associated with individual variables, we need to 
be more explicit in how variables are used. Substructural type systems provide a way to do this.
Even if we allow all three operations, we can use a variation on the three rules (exchange, 
weakening and contraction) to track which variables are used and how (and to track additional 
contextual information about variables). 

\begin{figure}
\begin{equation*}
\tyrule{exchange}
  {\Gamma, x\!:\!\tau_1, y\!:\!\tau_2 \vdash e : \gamma}
  {\Gamma, y\!:\!\tau_2, x\!:\!\tau_1 \vdash e : \gamma}
\end{equation*}
\begin{equation*}
\tyrule{weakening}
  {\Gamma, \Delta \vdash e : \gamma}
  {\Gamma, x\!:\!\tau, \Delta \vdash e : \gamma}
\end{equation*}
\begin{equation*}
\tyrule{contraction}
  {\Gamma, x\!:\!\tau_1, y\!:\!\tau_1, \Delta \vdash e : \tau_2}
  {\Gamma, x\!:\!\tau_1, \Delta \vdash \subst{e}{y}{x} : \tau_2}
\end{equation*}

\caption{Exchange, weakening and contraction typing rules}
\label{fig:substructural-rules}
\end{figure}

%---------------------------------------------------------------------------------------------------

\subsection{Bunched type systems.}
Bunched typing makes one more refinement to how $\Gamma$ is treated. Rather than having a list
of assumptions, the context becomes a tree that contains variable typings (or special identity
values) in the leaves and has multiple different types of nodes. The context can be defined,
for example, as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x\!:\!\alpha \sep I \sep \Gamma, \Gamma \sep 1 \sep \Gamma; \Gamma
\end{equation*}
%
The values $I$ and $1$ represent two kinds of ``empty'' contexts. More interestingly, non-empty
variable contexts may be constructed using two distinct constructors -- $\Gamma, \Gamma$ and 
$\Gamma; \Gamma$ -- that have different properties. In particular, weakening and contraction is
only allowed for the $;$ constructor, while exchange is allowed for both.  

The structural rules for bunched typing are shown in Figure~\ref{fig:substructural-bunched}.
The syntax $\Gamma(\Delta)$ is used to mean an assumption tree that contains $\Delta$ as a 
sub-tree and so, for example, (\emph{exchange1}) can switch the order of contexts anywhere in the
tree. The remaining rules are similar to the rules of linear logic.

One important note about bunched typing is that it requires a different interpretation. The omission
of weakening and contraction in linear logic means that variable can be used exactly once. 
In bunched typing, variables may still be duplicated, but only using the ``;'' separator.
The type system can be interpreted as specifying whether a variable may be shared between the 
body of a function and the context where a function is declared. 

The system introduces two 
distinct function types $\tau_1 \rightarrow \tau_2$ and $\tau_1~ \textendash\!\!\!\ast \tau_2$
(corresponding to ``;'' and ``,'' respectively). The key property is that only the first kind
of functions can share variables with the context where a function is declared, while the second
restricts such sharing. We do not attempt to give a detailed description here as it is not 
immediately related to coeffects -- for more information, refer to O'Hearn's introduction 
\cite{substruct-bunched}.

\begin{figure}
\begin{equation*}
\tyrule{exchange1}
  {\Gamma(\Delta, \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma, \Delta) \vdash e : \alpha}
\end{equation*}
\begin{equation*}
\tyrule{exchange2}
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma; \Delta) \vdash e : \alpha}
\end{equation*}
\begin{equation*}
\tyrule{weakening}
  {\Gamma(\Delta) \vdash e : \alpha}
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
\end{equation*}
\begin{equation*}
\tyrule{contraction}
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Delta) \vdash \subst{e}{\Sigma}{\Delta} : \alpha}
\end{equation*}
\caption{Exchange, weakening and contraction rules for bunched typing}
\label{fig:substructural-bunched}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective.}

From the perspective of substructural and bunched types, our work can be viewed as annotating 
bunches. Such annotations then specify additional information about the context -- or, more
specifically, about the sub-tree of the context. Although this is not the exact definition used in 
Chapter~\ref{ch:unified}, we could define contexts as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x\!:\!\alpha \sep 1 \sep \Gamma, \Gamma \sep \coctx{\Gamma}{\cclrd{r}}
\end{equation*}
%
Now we can not only annotate an entire context with some information (as in the simple coeffect
system for tracking resources that used judgements of a form $\cclrd{\Gamma}{\cclrd{r}} \vdash e : \tau$).
We can also annotate individual components. For example, a context containing variables $x,y,z$
where only $x$ is used could be written as $\coctx{(x\!:\!\tau_1}{\ident{\cclrd{used}}}, \coctx{(y\!:\!\tau_2, z\!:\!\tau_3)}{\ident{\cclrd{unused}}}$.

For the purpose of this introduction, we ignore important aspects such as how are nested annotations
interpreted. The main goal is to show that coeffects can be easily viewed as an extension to the 
work on bunched logic. Aside from this principal connection, \emph{structural coeffects} also 
use some of the proof techniques from the work on bunched logics.


%===================================================================================================

\section{Context oriented programming}

The importance of context-aware computations is perhaps most obvious when considering mobile
application, client/server web applications or even the internet of things. A pioneering work
in the area using functional languages has been done by Serrano \cite{app-hop-diffuse,app-hop-lang}
(which also inspired the motivating example presented in Chapter~\ref{ch:intro}). His HOP language supports 
cross-compilation and programs execute in different contexts. However, HOP is not statically 
type checked.

In the software engineering community, a number of authors have addressed the
problem of context-aware computations. Hirschfeld et al. propose \emph{Context-Oriented Programming} 
(COP) as a methodology \cite{app-cop-method}. The COP paradigm has been later implemented by
programming language features. Costanza \cite{app-cop-contextl} develops a domain-specific LISP-like 
language ContextL and Bardram \cite{app-cop-javafwk} proposes a Java framework for COP.

Finally, the subject of context-awareness has also been addressed in work focusing on the development 
of mobile applications \cite{app-cop-mobile,app-cop-mobile2}. Here, the \emph{context} focuses more 
on concrete physical context (obtained from the device sensors) than context as an abstract 
language feature.

We approach the problem from a different perspective, building on the tradition of 
statically-typed functional programming languages, focusing on type systems as the primary way
of capturing contextual properties. 

%===================================================================================================

\section{Summary}

This chapter presented three different pathways leading to the idea of coeffects. We also 
introduced the most important related work, although presenting related work was not the
primary goal of the chapter. The primary goal was to present the idea of coeffects as a logical 
follow up to a number of research directions. For this reason, we highlighted only certain aspects 
of the discussed related work -- the remaining aspects as well as important technical details are
covered throughout the thesis.

The first pathway follows as a dualization of well-known effect systems. However, this is not simply 
a syntactic transformation. As we further discuss in the next chapter, coeffect systems treat lambda 
abstraction differently. The second pathway follows by extending comonadic semantics of context-dependent 
computations with indexing and building a type system analogous to effect system from the ``marriage of 
effects and monads''. Finally, the third pathway starts with substructural type systems. Coeffect
systems naturally arise by annotating bunches in bunched logics with additional information. In this
thesis, we mostly follow the first two approaches.