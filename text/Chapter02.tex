\chapter{Pathways to coeffects} 
\label{ch:pathways} 

%---------------------------------------------------------------------------------------------------

There are many different directions from which the concept of \emph{coeffects} can be approached 
and, indeed, discovered. In the previous chapter, we motivated it by practical applications, but 
coeffects also naturally arise as an extension to a number of programming language theories.
Thanks to the Curry-Howard-Lambek correspondence, we can approach coeffects from the perspective of 
type theory, logic and also category theory. This chapter gives an overview of the most 
important directions.

We start by revisiting practical applications and existing language features that are related to 
coeffects (Section~\ref{sec:path-apps}), then we look at coeffects as the dual of effect systems
(Section~\ref{sec:path-eff}) and extend the duality to category theory, looking at the categorical 
dual of monads known as \emph{comonads} (Section~\ref{sec:path-sem}). Finally we look at logically 
inspired type systems that are closely related to our structural coeffects 
(Section~\ref{sec:path-logic}).

This chapter serves two purposes. Firstly, it provides a high-level overview of the  related work, 
although technical details are often postponed until later. Secondly it recasts existing ideas in 
a way that naturally leads to the coeffect systems developed later in the thesis. For this reason, 
we are not always faithful to the referenced work -- sometimes we focus on aspects that the 
authors consider unimportant or present the work differently than originally intended. The reason 
is to fulfil the second goal of the chapter. When we do so, this is explicitly said in the text.

%===================================================================================================

\section{Through type and effect systems}
\label{sec:path-eff}

Introduced by Gifford and Lucassen \cite{effects-gifford,effects-polymorphic}, type and effect 
systems have been designed to track effectful operations performed by computations. Examples 
include tracking of reading and writing from and to memory locations \cite{effects-talpin-et-al}, 
communication in message-passing systems \cite{effects-messagepassing} and atomicity in concurrent 
applications \cite{effects-atomicity}.

Type and effect systems are usually specified judgements of the form $\Gamma \vdash e : \alpha, \sigma$, 
meaning that the expression $e$ has a type $\alpha$ in (free-variable) context $\Gamma$ and 
additionally may have effects described by $\sigma$. Effect systems are typically added to a 
language that already supports effectful operations as a way of increasing the safety -- the type
and effect system provides stronger guarantees than a plain type system. Filinsky 
\cite{effects-comprehensive} refers to this approach as \emph{descriptive}\footnote{In contrast
to \emph{prescriptive} effect systems that implement computational effects in a pure language 
-- such as monads in Haskell}.

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\inference[(var)]
  {x:\alpha \in \Gamma }
  {\Gamma \vdash x : \alpha, \emptyset }
\quad
\inference[(write)]
  {\Gamma \vdash e : \alpha, \sigma & l:\ident{ref}_\rho~\alpha\in \Gamma}
  {\Gamma \vdash l \leftarrow e : \ident{unit}, \sigma \cup \{\ident{write}(\rho)\} }
\end{equation*}
\begin{equation*}
\inference[(fun)]
  {\Gamma, x:\alpha_1 \vdash e : \beta, \sigma }
  {\Gamma \vdash \lambda x.e : \alpha \xrightarrow{\sigma} \beta, \emptyset }
\quad  
\inference[(app)]
  {\Gamma \vdash e_1 : \alpha \xrightarrow{\sigma_1} \beta, \sigma_2 \\
   \Gamma \vdash e_2 : \alpha, \sigma_3 }
  {\Gamma \vdash e_1~e_2 : \beta, \sigma_1 \cup \sigma_2 \cup \sigma_3 }
\end{equation*}

\caption{Simple effect system}
\label{fig:path-eff}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Simple effect system}
The structure of a simple effect system is demonstrated in Figure~\ref{fig:path-eff}. The example
shows typing rules for a simply typed lambda calculus with an additional (effectful) operation
$l \leftarrow e$ that writes the value of $e$ to a mutable location $l$. The type of locations
($\ident{ref}_\rho~\alpha$) is annotated with a \emph{memory region} $\rho$ of the location $l$.
The effects tracked by the type and effect system over-approximate the actual effects and memory
regions provide a convenient way to build such over-approximation. The effects are 
represented as a set of effectful actions that an expression may perform and the effectful action
(\emph{write}) adds a primitive effect $\ident{write}(\rho)$.

The remaining rules are shared by a majority of effect systems. Variable access (\emph{var}) 
has no effects, application (\emph{app}) combines the effects of both expressions, together with 
the latent effects of the function to be applied. Finally, lambda abstraction (\emph{fun}) is a
pure computation that turns the \emph{actual} effects of the body into \emph{latent} effects of 
the created function.

%---------------------------------------------------------------------------------------------------

\paragraph{Simple coeffect system}
When writing the judgements of coeffect systems, we want to emphasize the fact that coeffect 
systems talk about \emph{context} rather than \emph{results}. For this reason, we write the 
judgements in the form $\Gamma @ \sigma \vdash e : \alpha$, associating the additional information
with the context (left-hand side) of the judgement rather than with the result (right-hand side)
as in $\Gamma \vdash e : \alpha, \sigma$. This change alone would not be very interesting -- we 
simply used different syntax to write a predicate with four arguments. As already mentioned, the 
key difference follows from the lambda abstraction rule. 

The language in Figure~\ref{fig:path-coeff} extends simple lambda calculus with resources and
with a construct $\kvd{access}~e$ that obtains the resource specified by the expression $e$.
Most of the typing rules correspond to those of effect systems. Variable access (\emph{var}) 
has no context requirements, application (\emph{app}) combines context requirements of the two
sub-expressions and latent context-requirements of the function. 

The (\emph{fun}) rule is different -- the resources requirements of the body $\sigma_1 \cup \sigma_2$
are split between the \emph{immediate context-requirements} associated with the current context 
$\Gamma @ \sigma_1$ and the \emph{latent context-requirements} of the function.

As demonstrated by examples in the Chapter~\ref{ch:introduction}, this means that the resource
can be captured when a function is declared (e.g.~when it is constructed on the server-side
where database access is available), or when a function is called (e.g.~when a function created
on server-side requires access to current time-zone, it can use the resource available on the
client-side).

%---------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\inference[(var)]
  {x:\alpha \in \Gamma }
  {\Gamma @ \emptyset \vdash x : \alpha }
\quad
\inference[(access)]
  { \Gamma @ \sigma \vdash e : \ident{res}_\rho~\alpha }
  {\Gamma @ \sigma_1 \cup \{\ident{access}(\rho)\} \vdash \kvd{access}~e : \alpha }
\end{equation*}
\begin{equation*}
\inference[(fun)]
  {\Gamma, x:\alpha @ \sigma_1 \cup \sigma_2 \vdash e : \beta }
  {\Gamma @ \sigma_1 \vdash \lambda x.e : \alpha \xrightarrow{\sigma_2} \beta}
\quad  
\inference[(app)]
  {\Gamma \vdash e_1 : \alpha \xrightarrow{\sigma_1} \beta, \sigma_2 \\
   \Gamma \vdash e_2 : \alpha, \sigma_3 }
  {\Gamma \vdash e_1~e_2 : \beta, \sigma_1 \cup \sigma_2 \cup \sigma_3 }
\end{equation*}

\caption{Simple effect system}
\label{fig:path-coeff}
\end{figure}

%===================================================================================================

\section{Through language semantics}
\label{sec:path-sem}

Another pathway to coeffects leads through the semantics of effectful and context-dependent 
computations. In a pioneering work, Moggi \cite{monad-notions} showed that effects (including
partiality, exceptions, non-determinism and I/O) can be modelled uisng the category theoretic
notion of \emph{monad}.

When using monads, we distinguish effect-free values $\alpha$ from programs, or 
computations $\mtyp{}{\alpha}$. The \emph{monad} $\mtyp{}{}$ abstracts the \emph{notion of 
computation} and provides a way of constructing and composing effectful computations:

\begin{definition}
A \emph{monad} over a category $\catc$ is a triple $(M, \ident{unit}, \ident{bind})$ where:
\begin{compactitem}
\item $M$ is a mapping on objects (types) $M : \catc \rightarrow \catc$
\item $\ident{unit}$ is a mapping $\alpha \rightarrow \mtyp{}{\alpha}$ 
\item $\ident{bind}$ is a mapping $(\alpha \rightarrow \mtyp{}{\beta}) 
  \rightarrow (\mtyp{}{\alpha} \rightarrow \mtyp{}{\beta})$
\end{compactitem}
such that, for all $f:\alpha \rightarrow \mtyp{}{\beta}, g:\beta \rightarrow \mtyp{}{\gamma}$:
\begin{align}
\tag{\emph{left identity}}
  \ident{bind}~\ident{unit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{bind}~f \circ \ident{unit} &= f
  \\
\tag{\emph{associativity}}
  \ident{bind}~(\ident{bind}~g \circ f) &= (\ident{bind}~f) \circ (\ident{bind}~g)
\end{align}
\end{definition}

\noindent
Without providing much details, we note that well known examples of monads include the partiality
monad ($\mtyp{}{\alpha} = \alpha + {\bot}$) also corresponding to the \ident{Maybe} type in 
Haskell, list monad ($\mtyp{}{\alpha} = \mu \gamma.1 + (\alpha \times \gamma)$) and other.
In programming language semantics, monads can be used in two distinct ways.

%---------------------------------------------------------------------------------------------------

\subsection{Effectful languages and meta-languages}

Moggi uses monads to define two formal systems. In the first formal system, a monad is used to model 
the \emph{language} itself. This means that the semantics of a language is given in terms of a 
one specific monad and the semantics can be used to reason about programs in that language. To quote 
\emph{``When reasoning about programs one has only one monad, because the programming language is 
fixed, and the main aim is to prove properties of programs''} \cite[p. 5]{monad-notions}.

In the second formal system, monads are added to the programming language as type constructors, 
together with additional constructs corresponding to monadic \ident{bind} and \ident{unit}.
A single program can use multiple monads, but the key benefit is the ability to reason
about multiple languages. To quote \emph{``When reasoning about programming languages one has different 
monads, one for each programming language, and the main aim is to study how they relate to each 
other''} \cite[p. 5]{monad-notions}.

In this thesis, we generally follow the first approach -- this means that we work with an existing
programming language (without needing to add additional constructs corresponding to the primitives
of our semantics). To explain the difference in greater detail, the following two sections show a
minimal example of both formal systems. We follow Moggi and start with language where judgements have
the form $x:\alpha \vdash e : \beta$ with exactly one variable\footnote{This simplifies the examples
as we do not need \emph{strong} monad, but that is an orthogonal issue to the distinction between
language semantics and meta-language.}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics} When using monads to provide semantics of a language, we do not
need to extend the language in any way -- we assume that the language already contains the 
effectful primitives (such as the assignment operator $x \leftarrow e$ or other). A judgement
of the form $x:\alpha \vdash e : \beta$ is interpreted as a morphism $\alpha \rightarrow \mtyp{}{\beta}$,
meaning that any expression is interpreted as an effectful computation. The semantics of variable
access ($x$) and the application of a primitive function $f$ is interpreted as follows:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \ident{unit}_\mtyp{}{}\\
\sem{x:\alpha \vdash f~e : \gamma} &=& (\ident{bind}_\mtyp{}{}~f) \circ \sem{e}\\
\end{array}
\end{equation*}
%
Variable access is an effect-free computation, that returns the value of the variable, wrapped
using $\ident{unit}_\mtyp{}{}$. In the second rule, we assume that $e$ is an expression using
the variable $x$ and producing a value of type $\beta$ and that $f$ is a (primitive) function
$\beta \rightarrow \mtyp{}{\gamma}$. The semantics lifts the function $f$ using $\ident{bind}_\mtyp{}{}$
to a function $\mtyp{}{\beta} \rightarrow \mtyp{}{\gamma}$ which is compatible with the 
interpretation of the expression $e$.

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation} When designing meta-language based on monads, we need to
extend the lambda calculus with additional type(s) and expressions that correspond to monadic
primitives:
%
\begin{align*}
\alpha, \beta, \gamma &:= \tau \sep \alpha \rightarrow \beta \sep \mtyp{}{\alpha} \\
e &:= x \sep f~e \sep \kvd{return}_\mtyp{}{}~e \sep \kvd{let}_\mtyp{}{}~x \Leftarrow e_1~\kvd{in}~e_2
\end{align*}
%
The types consist of primitive type ($\tau$), function type and a type constructor that 
represents monadic computations. This means that the expressions in the language can create both
effect-free values, such as $\alpha$ and computations $\mtyp{}{\alpha}$. The additional expression
$\kvd{return}_\mtyp{}{}$ is used to create a monadic computation (with no actual effects) from a
value and $\kvd{let}_\mtyp{}{}$ is used to sequence effectful computations. In the semantics, 
monads are not needed to interpret variable access and application, they are only used in the 
semantics of additional (monadic) constructs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \idf{}\\
\sem{x:\alpha \vdash f~e : \beta} &=& f \circ \sem{e}\\
\sem{x:\alpha \vdash \kvd{return}_\mtyp{}{}~e : \mtyp{}{\beta}} &=& \ident{unit}_\mtyp{}{} \circ \sem{e}\\
\sem{x:\alpha \vdash \kvd{let}_\mtyp{}{}~y \Leftarrow e_1~\kvd{in}~e_2 : \mtyp{}{\beta}} &=& 
  \ident{bind}_\mtyp{}{}~\sem{e_2} \circ \sem{e_1}
\end{array}
\end{equation*}

\noindent
In this system, the interpretation of variable access becomes a simple identity function and
application is just composition. Monadic computations are constructed explicitly using 
$\kvd{return}_\mtyp{}{}$ (interpreted as $\ident{unit}_\mtyp{}{}$) and they are also sequenced
explicitly using the $\kvd{let}_\mtyp{}{}$ construct. As noted by Moggi, the first formal system
can be easily translated to the latter by inserting appropriate monadic constructs.

Moggi regards the meta-language system as more fundamental, because \emph{``its models are more 
general''}. Indeed, this is a valid and reasonable perspective. Yet, we follow the first style,
precisely because it is \emph{less general} -- our aim is to develop concrete context-aware 
programming languages (together with their type theory and semantics) rather than to build a 
general framework for reasoning about languages with context-dependent properties.

%---------------------------------------------------------------------------------------------------

\subsection{Marriage of effects and monads}
\label{sec:path-sem-effects}

The work on effect systems and monads both tackle the same problem -- representing and tracking of 
computational effects. The two lines of research have been joined by Wadler and Thiemann
\cite{monads-effects-marriage}. This requires extending the categorical structure. A monadic
computation $\alpha \rightarrow \mtyp{}{\beta}$ means that the computation has \emph{some} 
effects while the judgement $\Gamma \vdash e : \alpha, \sigma$ specifies \emph{what} effects
the computation has.

To solve this mismatch, Wadler and Thiemann use a \emph{family} of monads $\mtyp{\sigma}{\alpha}$
with an annotation that specifies the effects that may be performed by the computation. In their
system, an effectful function $\alpha \xrightarrow{\sigma} \beta$ is modelled as a pure 
function returning monadic computation $\alpha \rightarrow \mtyp{\sigma}{\beta}$. Similarly, the
semantics of a judgement $x:\alpha \vdash e : \beta, \sigma$ can be given as a function 
$\alpha \rightarrow \mtyp{\sigma}{\beta}$. 
The precise nature of the family of monads has been later called \emph{indexed monads} (e.g.~by Tate
\cite{effects-producer-semantics}) and further developed by Atkey \cite{monads-parameterised-notions} 
in his work on \emph{parameterized monads}.

\paragraph{Thesis perspective}
The key takeaway for this thesis from the outlined line of research is that, if we want to develop a 
language with type system that captures context-dependent properties of programs more precisely,
the semantics of the language also needs to be a more fine-grained structure (akin to indexed 
monads). While monads have been used to model effects, an existing research links context-dependence
with \emph{comonads} -- the categorical dual of monads.

%---------------------------------------------------------------------------------------------------
 
\subsection{Context-dependent languages and meta-languages}
\label{sec:path-sem-contextdep}

The theoretical parts of this thesis extend the work of Uustalu and Vene who use comonads
to give the semantics of data-flow computations \cite{comonads-dataflow} and more generally, 
notions of \emph{context-dependent computations} \cite{comonads-notions}. The computations discussed 
in the latter work include streams, arrays and containers -- this is a more diverse set of examples, 
but they all mostly represent forms of collections. Ahman et al. \cite{comonads-containers} discuss
the relation between comonads and \emph{containers} in more details.

The utility of comonads has been explored by a number of authors before. Brookes and Geva
\cite{comonads-computational} use \emph{computational} comonads for intensional semantics\footnote{The
structure of computational comonad has been also used by the author of this thesis to abstract
evaluation order of monadic computations \cite{comonads-malias}.}. In functional programming,
Kieburtz \cite{comonads-and-codata} proposed to use comonads for stream programming, but also 
handling of I/O and interoperability.

Biermann and de Paiva used comonads to model the necessity modality $\square$ in intuitionistic
modal S4 \cite{logic-intuitionistic-modal}, linking programming languages derived from modal
logics to comonads. One such language has been reconstructed by Pfenning and Davies
\cite{logic-modal-reconstruction}. Nanevski et al. extend this work to Contextual Modal Type 
Theory (CMTT) \cite{logic-cmtt}, which again shows the importance of comonads for 
\emph{context-dependent} computations.

While Uustalu and Vene use comonads to define the \emph{language semantics} (the first style
of Moggi), Nanevski, Pfenning and Davies use comonads as part of meta-language, in the form 
of $\square$ modality, to reason about context-dependent computations (the second style of 
Moggi). Before looking at the details, we use the following definition of comonad:

\begin{definition}
A \emph{comonad} over a category $\catc$ is a triple $(C, \ident{counit}, \ident{cobind})$ where:
\begin{compactitem}
\item $C$ is a mapping on objects (types) $C : \catc \rightarrow \catc$
\item $\ident{counit}$ is a mapping $\ctyp{}{\alpha} \rightarrow \alpha$ 
\item $\ident{cobind}$ is a mapping $(\ctyp{}{\alpha} \rightarrow \beta) 
  \rightarrow (\ctyp{}{\alpha} \rightarrow \ctyp{}{\beta})$
\end{compactitem}
such that, for all $f:\alpha \rightarrow \mtyp{}{\beta}, g:\beta \rightarrow \mtyp{}{\gamma}$:
\begin{align}
\tag{\emph{left identity}}
  \ident{cobind}~\ident{counit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{counit} \circ \ident{cobind}~f &= f
  \\
\tag{\emph{associativity}}
  \ident{cobind}~(\ident{cobind}~g \circ f) &= (\ident{cobind}~f) \circ (\ident{cobind}~g)
\end{align}
\end{definition}

\noindent
The definition is similar to monad with ``reversed arrows''. Intuitively, the $\ident{counit}$ 
operation extracts a value $\alpha$ from a value that carries additional context $\ctyp{}{\alpha}$.
The $\ident{cobind}$ operation turns a context-dependent function 
$\ctyp{}{\alpha} \rightarrow \beta$ into a function that takes a value with context, applies
the context-dependent function to value(s) in the context and then propagates the context. The 
next section makes this intuitive definition more concrete. More detailed discussion about
comonads can be found in Orchard's PhD thesis \cite{comonads-dom-thesis}.

%---------------------------------------------------------------------------------------------------

\paragraph{Language semantics}
To demonstrate the approach of Uustalu and Vene, we consider the non-empty list comonad
$\ctyp{}{\alpha} = \mu \gamma.\alpha + (\alpha \times \gamma)$. A value of the type is either
the last element $\alpha$ or an element followed by another non-empty list $\alpha \times \gamma$.
Note that the list must be non-empty -- otherwise \ident{counit} would not be a complete 
function (it would be undefined on empty list). In the following, we write $(l_1, \ldots, l_n)$
for a list of $n$ elements:
%
\begin{equation*}
\begin{array}{rcl}
\ident{counit}~(l_1, \ldots, l_n) &=& l_1\\
\ident{cobind}~f~(l_1, \ldots, l_n) &=& (f (l_1, \ldots, l_n), f (l_2, \ldots, l_n), \ldots, f (l_n))
\end{array}
\end{equation*}
%
The \ident{counit} operation returns the current (first) element of the (non-empty) list.
The \ident{cobind} operation creates a new list by applying the context-dependent function $f$
to the entire list, to the suffix of the list, to the suffix of the suffix and so on.

In causal data-flow, we can interpret the list as a list consisting of past values, with the 
current value in the head. Then, the $\ident{cobind}$ operation calculates the current value
of the output based on the current and all past values of the input; the second element is
calculated based on all past values and the last element is calculated based just on the initial
input $(l_n)$. In addition to the operations of comonad, the model also uses some operations that
are specific to causal data-flow:
%
\begin{equation*}
\begin{array}{rcl}
\ident{prev}~(l_1, \ldots, l_n) &=& (l_2, \ldots, l_n)\\
\end{array}
\end{equation*}
%
The operation drops the first element from the list. In the data-flow interpretation, this means
that it returns the previous state of a value. 

Now, consider a simple data-flow language with single-variable contexts, variables, 
primitive built-in functions and a construct $\kvd{prev}~e$ that returns the previous
value of the computation $e$. We omit the typing rules, but they are simple -- assuming $e$ 
has a type $\alpha$, the expression $\kvd{prev}~e$ has also type $\alpha$. The fact that
the language models data-flow and values are lists (of past values) is a matter of semantics,
which is defined as follows:
%
\begin{equation*}
\begin{array}{rcl}
\sem{x:\alpha \vdash x : \alpha} &=& \ident{counit}_\ctyp{}{}\\
\sem{x:\alpha \vdash f~e : \gamma} &=& f \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\sem{x:\alpha \vdash \kvd{prev}~e : \gamma} &=& \ident{prev} \circ (\ident{cobind}_\ctyp{}{} ~\sem{e})\\
\end{array}
\end{equation*}
%
The semantics follows that of effectful computations using monads. A variable access is interpreted
using $\ident{counit}_\ctyp{}{}$ (obtain the value and ignore additional available context); composition
uses $\ident{cobind}_\ctyp{}{}$ to propagate the context to the function $f$ and $\kvd{prev}$
is interpreted using the primitive $\ident{prev}$ (which takes a list and returns a list).

For example, the judgement $x:\alpha \vdash \kvd{prev}~(\kvd{prev}~x) : \alpha$ represents an 
expression that expects context with variable $x$ and returns a stream of values before the 
previous one. The semantics of the term expresses this behaviour: 
$(\ident{prev} \circ \ident{prev} \circ (\ident{cobind}_\ctyp{}{}~\ident{counit}_\ctyp{}{}))$.
Note that the first operation is simply an identity function thanks to the comonad laws discussed 
earlier.

In the outline presented here, we ignored lambda abstraction. Similarly to monadic semantics,
where lambda abstraction requires \emph{strong} monad, the comonadic semantics also requires
additional structure called \emph{symmetric (semi)monoidal} comonads. This structure is 
responsible for the splitting of context-requirements in lambda abstraction. We return to this
topic when discussing flat coeffect system later in the thesis.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\inference[(eval)]
  {\Gamma \vdash e : \ctyp{\emptyset}{\alpha}}
  {\Gamma \vdash !e : \alpha}
\quad
\inference[(letbox)]
  {\Gamma \vdash e_1 : \ctyp{\Phi, \Psi}{\alpha} & \Gamma, x : \ctyp{\Phi}{\alpha} \vdash e_2 : \beta }
  {\Gamma \vdash \kvd{let~box}~x=e_1~\kvd{in}~e_2 : \ctyp{\Psi}{\beta}}
\end{equation*}

\caption{Typing for a comonadic language with contextual staged computations}
\label{fig:modal-meta}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Meta-language interpretation} To briefly demonstrate the approach that employs comonads
as part of a meta-language, we look at an example inspired by the work of Pfenning, Davies and 
Nanevski et al. We do not attempt to provide precise overview of their work. The main purpose 
of our discussion is to provide a different intuition behind comonads, and to give an example
of a language that includes comonad as a type constructor, together with language primitives
corresponding to comonadic operations\footnote{In fact, Pfenning and Davies \cite{logic-modal-reconstruction,logic-cmtt}
never mention comonads explicitly. This is done in later work by Gabbay et al. \cite{logic-cmtt-semantics}, 
but the connection between the language and comonads is not as direct as in case of monadic or
comonadic semantics covered in the last few pages.}. 

In languages inspired by modal logics, types can have the form $\square \alpha$. In the work of
Pfenning and Davies, this means a term that is provable with no assumptions. In distributed 
programming language ML5, Murphy et al. \cite{app-distributed-ml5,logic-distributed-calculus} use the 
$\square \alpha$ type to mean \emph{mobile code}, that is code that can be evaluated at any node of a 
distributed system (the evaluation corresponds to the axiom $\square \alpha \rightarrow \alpha$). 
Finally, Davies and Pfenning \cite{logic-modal-staged} consider staged computations and interpret 
$\square \alpha$ as a type of (unevaluated) expressions of type $\alpha$.

In Contextual Modal Type Theory, the modality $\square$ is further annotated. To keep the syntax
consistent with earlier examples, we use $\ctyp{\Psi}{\alpha}$ for a type $\square \alpha$ with an
annotation $\Psi$. The type is a comonadic counterpart to the \emph{indexed monads} used by Wadler
and Thiemann when linking monads and effect systems and, indeed, it gives rise to a language that
tracks context-dependence of computations in a type system.

In staged computation, the type $\ctyp{\Psi}{\alpha}$ represents an expression 
that requires the context $\Psi$ (i.e.~the expression is an open term that requires variables $\Psi$).
The Figure~\ref{fig:modal-meta} shows two typing rules for such language. The rules directly
correspond to the two operations of a comonad and can be interpreted as follows:

\begin{itemize}
\item (\emph{eval}) corresponds to $\ident{counit} : \ctyp{\emptyset}{\alpha} \rightarrow \alpha$. It means
  that we can evaluate a closed (unevaluated) term and obtain a value. Note that the rule requires
  a specific context annotation. It is not possible to evaluate an open term.

\item (\emph{letbox}) corresponds to $\ident{cobind} : (\ctyp{\Psi}{\alpha} \rightarrow \beta) 
  \rightarrow \ctyp{\Psi, \Phi}{\alpha} \rightarrow \ctyp{\Phi}{\beta}$. It means that given
  a term which requires variable context $\Psi, \Phi$ (expression $e_1$) and a function that turns 
  a term needing $\Psi$ into an evaluated value (expression $e_2$), we can construct a term 
  that requires just $\Phi$.
\end{itemize}

\noindent
The fact that the (\emph{eval}) rule requires a specific context is an interesting relaxation
from ordinary comonads where \ident{counit} needs to be defined for all values. Here, the indexed
\ident{counit} operation needs to be defined only on values annotated with $\emptyset$.

The annotated \ident{cobind} operation that corresponds to (\emph{letbox}) is in details 
introduced in Chapter~X. An interesting aspect is that it propagates the context-requirements
``backwards''. The input expression (second parameter) requires a combination of contexts that
are required by the two components -- those required by the input of the function (first
argument) and those required by the resulting expression (result). This is another key aspect
that distinguishes coeffects from effect systems.
  
\paragraph{Thesis perspective}
As mentioned earlier, we are interested in designing context-dependent languages and so we
use comonads as \emph{language semantics}. Uustalu and Vene present a semantics of 
context-dependent computations in terms of comonads. We provide the rest of the story known 
from the marriage of monads and effects. We develop coeffect calculus with a type system that 
tracks the context requirements more precisely (by annotating the types) and we add indexing 
to comonads and link the two by giving a formal semantics. 

The \emph{meta-language} approach of Pfenning, Davies and Nanevski et al. is closely related to
our work. Most importantly, Contextual Modal Type Theory (CMTT) uses indexed $\square$ modality
which seems to correspond to indexed comonads (in a similar way in which effect systems 
correspond to indexed monads). The relation between CMTT and comonads has been suggested by
Gabbay et al. \cite{logic-cmtt-semantics}, but the meta-language employed by CMTT does not 
directly correspond to comonadic operations. For example, our \ident{let box} typing rule from
Figure~\ref{fig:modal-meta} is not a primitive of CMTT and would correspond to 
$\ident{box}(\Psi, \ident{letbox}(e_1, x, e_2))$. Nevertheless, the indexing in CMTT provides a useful
hint for adding indexing to the work of Uustalu and Vene.

%===================================================================================================

\section{Through sub-structural and bunched logics}
\label{sec:path-logic}

In the coeffect system for tracking resource usage outlined earlier, we associated additional
contextual information (set of available resources) with the variable context of the typing 
judgement: $\Gamma @ \sigma \vdash e : \alpha$. In other words, our work focuses on ``what is
happening on the left hand side of $\vdash$''.

In the case of resources, the additional information about the context are simply added to the
variable context (as a products), but we will later look at contextual properties that affect 
how variables are represented. More importantly, \emph{structural coeffects} link additional
information to individual variables in the context, rather than the context as a whole.

In this section, we look at type systems that reconsider $\Gamma$ in a number of ways. 
First of all, sub-structural type systems \cite{substruct-attpl-intro} restrict the use of variables
in the language. Most famously linear type systems introduced by Wadler \cite{substruct-linear-change} 
can guarantee that variable is used exactly once. This has interesting implications for memory
management and I/O. 

In bunched typing developed by O'Hearn \cite{substruct-bunched}, the variable context is a tree 
formed by multiple different constructors (e.g.~one that allows sharing and one that does not). 
Most importantly, bunched typing has contributed to the development of separation logic
\cite{substruct-separation-logic} (starting a fruitful line of research in software verification), 
but it is also interesting on its own. 

%---------------------------------------------------------------------------------------------------

\paragraph{Sub-structural type systems}

Traditionally, $\Gamma$ is viewed as a set of assumptions and typing rules admit (or explicitly
include) three operations that manipulate the variable contexts which are shown in 
Figure~\ref{fig:substructural-rules}. The (\emph{exchange}) rule allows us to reorder variables
(which is implicit, when assumptions are treated as set); (\emph{weakening}) makes it possible
to discard an assumption -- this has the implication that a variable may be declared but never
used. Finally, (\emph{contraction}) makes it possible to use a single variable multiple times
(by joining multiple variables into a single one using substitution).

\begin{figure}
\begin{equation*}
\inference[(exchange)]
  {\Gamma, x:\alpha, y:\beta \vdash e : \gamma}
  {\Gamma, y:\beta, x:\alpha \vdash e : \gamma}
\quad
\inference[(weakening)]
  {\Gamma, \Delta \vdash e : \gamma}
  {\Gamma, x:\alpha, \Delta \vdash e : \gamma}
\end{equation*}
\begin{equation*}
\inference[(contraction)]
  {\Gamma, x:\alpha, y:\alpha, \Delta \vdash e : \gamma}
  {\Gamma, x:\alpha, \Delta \vdash \subst{e}{y}{x} : \gamma}
\end{equation*}

\caption{Exchange, weakening and contraction typing rules}
\label{fig:substructural-rules}
\end{figure}

In sub-structural type systems, the assumptions are typically treated as a list. As a result,
they have to be manipulated explicitly. Different systems allow different subset of the rules.
For example, \emph{affine} systems allows exchange and weakening, leading to a system where 
variable may be used at most once; in \emph{linear} systems, only exchange is permitted and so 
every variable has to be used exactly once.

When tracking context-dependent properties associated with individual variables, we need to 
be more explicit in how variables are used. Sub-structural type systems provide a way to do this.
Even when we allow all three operations, we can track which variables are used and how
(and use that to track additional contextual information about variables). 

%---------------------------------------------------------------------------------------------------

\paragraph{Bunched type systems}
Bunched typing makes one more refinement to how $\Gamma$ is treated. Rather than having a list
of assumptions, the context becomes a tree that contains variable typings (or special identity
values) in the leaves and has multiple different types of nodes. The context can be defined,
for example, as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x:\alpha \sep I \sep \Gamma, \Gamma \sep 1 \sep \Gamma; \Gamma
\end{equation*}
%
The values $I$ and $1$ represent two kinds of ``empty'' contexts. More interestingly, non-empty
variable contexts may be constructed using two distinct constructors -- $\Gamma, \Gamma$ and 
$\Gamma; \Gamma$ -- that have different properties. In particular, weakening and contraction is
only allowed for the $;$ constructor, while exchange is allowed for both.  

The structural rules for bunched typing are shown in Figure~\ref{fig:substructural-bunched}.
The syntax $\Gamma(\Delta)$ is used to mean an assumption tree that contains $\Delta$ as a 
sub-tree and so, for example, (\emph{exchange1}) can switch the order of contexts anywhere in the
tree. The remaining rules are similar to the rules of linear logic.

One important note about bunched typing is that it requires a different interpretation. The omission
of weakening and contraction in linear logic means that variable can be used exactly once. 
In bunched typing, variables may still be duplicated, but only using the ``;'' separator.
The type system can be interpreted as specifying whether a variable may be shared between the 
body of a function and the context where a function is declared. The system introduces two 
distinct function types $\alpha \rightarrow \beta$ and $\alpha~ \textendash\!\!\!\ast \beta$
(corresponding to ``;'' and ``,'' respectively). The key property is that only the first kind
of functions can share variables with the context where a function is declared, while the second
restricts such sharing. We do not attempt to give a detailed description here as it is not 
immediately to coeffects -- for more information, refer to O'Hearn's introduction 
\cite{substruct-bunched}.

\begin{figure}
\begin{equation*}
\inference[(exchange1)]
  {\Gamma(\Delta, \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma, \Delta) \vdash e : \alpha}
\quad
\inference[(weakening)]
  {\Gamma(\Delta) \vdash e : \alpha}
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
\end{equation*}
\begin{equation*}
\inference[(exchange2)]
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Sigma; \Delta) \vdash e : \alpha}
\quad
\inference[(contraction)]
  {\Gamma(\Delta; \Sigma) \vdash e : \alpha}
  {\Gamma(\Delta) \vdash \subst{e}{\Sigma}{\Delta} : \alpha}
\end{equation*}
\caption{Exchange, weakening and contraction rules for bunched typing}
\label{fig:substructural-bunched}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Thesis perspective}

Our work can be viewed as annotating bunches. Such annotations then specify additional information
about the context -- or, more specifically, about the sub-tree of the context. Although this is not
the exact definition used in Chapter~X, we could define contexts as follows:
%
\begin{equation*}
\Gamma, \Delta, \Sigma := x:\alpha \sep 1 \sep \Gamma, \Gamma \sep \Gamma @ \sigma
\end{equation*}
%
Now we can not only annotate an entire context with some information (as in the simple coeffect
system for tracking resources that used judgements of a form $\Gamma @ \sigma \vdash e : \alpha$).
We can also annotate individual components. For example, a context containing variables $x,y,z$
where only $x$ is used could be written as $(x:\alpha \,@\, \ident{used}), ((y:\alpha, z:\alpha) 
\,@\, \ident{unused})$.

For the purpose of this introduction, we ignore important aspects such as how are nested annotations
interpreted. The main goal is to show that coeffects can be easily viewed as an extension to the 
work on bunched logic. Aside from this principal connection, \emph{structural coeffects} also 
use some of the proof techniques from the work on bunched logics, because they also use tree-like
structure of variable contexts.


%===================================================================================================

\section{Context oriented programming}

The importance of context-aware computations is perhaps most obvious when considering mobile
application, client/server web applications or even the internet of things. A pioneering work
in the area using functional languages has been done by Serrano \cite{app-hop-diffuse,app-hop-lang}
(which also inspired the example presented in Chapter~\ref{ch:intro}). His HOP language supports 
cross-compilation and programs execute in different contexts. However, HOP is not statically 
type checked.

In the software engineering community, a number of authors have addressed the
problem of context-aware computations. Hirschfeld et al. propose \emph{Context-Oriented Programming} 
(COP) as a methodology \cite{app-cop-method}. The COP paradigm has been later implemented by
programming language features. Costanza \cite{app-cop-contextl} develops a domain-specific LISP-like 
language ContextL and Bardram \cite{app-cop-javafwk} proposes a Java framework for COP.

Finally, the subject of context-awareness has also been addressed in work focusing on the development 
of mobile applications \cite{app-cop-mobile,app-cop-mobile2}. Here, the \emph{context} focuses more 
on concrete physical context (obtained from the device sensors) than context as an abstract 
language feature.

We approach the problem from a different perspective, building on the tradition of 
statically-typed functional programming languages and their theories. 

%===================================================================================================

\section{Summary}

This chapter presented four different pathways leading to the idea of coeffects. We also 
introduced the most important related work, although presenting related work was not the
main goal of the chapter. The main goal was to show the idea of coeffects as a logical follow up
to a number of research directions. For this reason, we highlighted only certain aspects of 
related work -- the remaining aspects as well as important technical details are covered 
in later chapters.

The first pathway looks at applications and systems that involve notion of \emph{context}.
The two coeffect calculi we present aim to unify some of these systems. The second pathway
follows as a dualization of well-known effect systems. However, this is not simply a syntactic
transformation, because coeffect systems treat lambda abstraction differently. The third 
pathway follows by extending comonadic semantics of context-dependent computations with 
indexing and building a type system analogous to effect system from the ``marriage of effects
and monads''. Finally, the fourth pathway starts with sub-structural type systems. Coeffect
systems naturally arise by annotating bunches in bunched logics with additional information.


% \section{Missing}
% ~
% 
% indexed/layered/etc. monads, productors or whatever