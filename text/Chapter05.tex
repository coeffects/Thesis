% ==================================================================================================

\chapter{Semantics of flat coeffects}
\label{ch:semantics}

The \emph{flat coeffect calculus} introduced in the previous chapter uniformly captures a number
of context-aware systems outlined in Chapter~\ref{ch:applications}. The coeffect calculus
can be seen as a \emph{language framework} that simplifies the construction of concrete
\emph{domain-specific} coeffect lnguages. In the previous chapter, we discussed how it provides a
type system that tracks the required context. In this chapter, we show that the language framework
also provides a way for defining the semantics of concrete domain-specific coeffect languages,
guides their implementation and simplifies safety proofs.

This is done using a \emph{comonadically-inspired translation}. We translate a program written
using the coeffect calculus into a simple functional language with additional coeffect-specific
comonadically-inspired primitives that implement the concrete notion of context-awareness.

We use comonads in a syntactic way, following the example of Wadler and Thiemann \cite{monads-effects-marriage}
and Haskell's use of monads. The translation is the same for all coeffect languages, but the safety
depends on the concrete coeffect-specific comonadically-inspired primitives. We prove the soundness
of two concrete coeffect calculi (dataflow and implicit parameters). We note that the proof
crucially relies on a relationship between coeffect annotations (provided by the type system) and
the comonadically-inspired primitives (defining the semantics), which makes it easy to extend it to
other concrete context-aware languages.

\paragraph{Chapter structure and contributions}

\begin{itemize}
\item We introduce \emph{indexed comonads}, a generalization of comonads, a category-theoretical
  dual of monads (Section~\ref{sec:semantics-theory}) and we discuss how they provide semantics
  for coeffect calculus. This provides an insight into how (and why) the coeffect calculus works and
  shows an intriguing link with effects and monads.

\item We use indexed comonads to guide our \emph{translational semantics} of coeffect calculus
  (Section~\ref{sec:semantics-translation}). We define a simple sound functional programming
  language (with type system and operational semantics). We extend it with uninterpreted
  comonadically-inspired primitives and define a translation that turns well-typed context-aware
  coeffect programs into programs of our functional language.

\item For two sample coeffect calculi discussed earlier (dataflow and implicit parameters),
  we give reduction rules for the comonadically-inspired primitives and we extend the progress
  and preservation proofs, showing that well-typed programs produced by translation from two
  coeffect languages do not get stuck (Section~\ref{sec:semantics-proofs})

\item We note that the proof for concrete coeffect language (dataflow and implicit parameters) can
  be generalized -- rather than reconsidering progress and preservation of the whole target
  language, we rely just on the correctness of the coeffect-specific comonadically-inspired
  primitives and abstraction mechanism provided by languages such as ML and Haskell
  (Section~\ref{sec:semantics-related}).
\end{itemize}


% ==================================================================================================
%
%    ###
%     #  #    # ##### #####   ####  #####  #    #  ####  ##### #  ####  #    #
%     #  ##   #   #   #    # #    # #    # #    # #    #   #   # #    # ##   #
%     #  # #  #   #   #    # #    # #    # #    # #        #   # #    # # #  #
%     #  #  # #   #   #####  #    # #    # #    # #        #   # #    # #  # #
%     #  #   ##   #   #   #  #    # #    # #    # #    #   #   # #    # #   ##
%    ### #    #   #   #    #  ####  #####   ####   ####    #   #  ####  #    #
%
% ==================================================================================================

\section{Introduction and safety}
\label{sec:semantics-intro}

This chapter links together a number of different technical developments presented in this thesis.
We take the flat coeffect calculus introduced in Chatper~\ref{ch:flat}, define its \emph{abstract
comonadic semantics} and use it to define a translation that gives a \emph{concrete operational
semantics} to a number of concrete context-aware languages. The type system is used to guarantee
that the resulting programs are correct. Finally, the development in this chapter is closely
mirrored by the implementation presented in Chapter~\ref{ch:impl}, which implements the
translation together with an interpreter for the target language.

The key claim of this thesis is that writing context-aware programs using coeffects is easier and
less error-prone. In this chapter, we substantiate the claim by showing that programs written in the
coeffect calculus and evaluated using the translation provided here do not ``go wrong''.

To provide an intuition, consider two context-aware programs. The first calls a function that
adds two implicit parameters in a context where one of them is defined. The second calculates
the difference between the current and the previous value in a dataflow computation.
For comparison, we show the code written in a coeffect dataflow language (on the left) and
using standard ML-like libraries (on the right):
%
\begin{equation*}
\begin{array}{lcl}
\begin{array}{l}
\kvd{let}~\ident{add}=\kvd{fun}~\ident{x}`\rightarrow`\\[-0.2em]
 \quad \ident{?one} + \ident{?two}~\kvd{in}\\[-0.2em]
\kvd{let}~\ident{?one} = 10~\kvd{in}\\[-0.2em]
\ident{add}~0
\end{array}
&\quad&
\begin{array}{l}
\kvd{let}~\ident{add}=\kvd{fun}~\ident{x}~\ident{params}\rightarrow\\[-0.2em]
 \quad \ident{lookup}~\str{one}~\ident{params}~+ \\[-0.2em]
 \quad\quad \ident{lookup}~\str{two}~\ident{params}~\kvd{in}\\[-0.2em]
\ident{add}~0~(\ident{cons}~\str{one}~10~\ident{params})
\end{array}
\\[3.5em]
\begin{array}{l}
\kvd{let}~\ident{diff}=\kvd{fun}~\ident{x}\rightarrow\\[-0.2em]
 \quad \ident{x}-\kvd{prev}~\ident{x}
\end{array}
&&
\begin{array}{l}
\kvd{let}~\ident{diff}=\kvd{fun}~\ident{x}\rightarrow\\[-0.2em]
 \quad \ident{List.head}~\ident{x}-\ident{List.head}~(\ident{List.tail}~\ident{x})
\end{array}
\end{array}
\end{equation*}
%
The \ident{add} function (on the left) has a type $\ident{int}\xrightarrow{\cclrd{ \{ \ident{?one},\ident{?two} \} }}\ident{int}$.
We call it in a context containing $\cclrd{\ident{?one}}$ and so the coeffect of the program is
$\cclrd{ \{ \ident{?two} \} }$. The safety property for implicit parameters
(Theorem~\ref{thm:semantics-sound-impl}) guarantees that, when executed in a context that
provides a value for the implicit parameter $\cclrd{\ident{?one}}$, the program reduces to
a value of the correct type (or never terminates).

If we wrote the code without coeffects (on the right), we could use a dynamic map to pass around
a dictionary of parameters (the \ident{lookup} function obtains a value and \ident{add} adds a new
assignment to the map). In that case, the type of \ident{add} is just $\ident{int}\rightarrow\ident{int}$
and so the user does not know which implicit parameters it will need.

Similarly, the \ident{diff} function can be implemented in terms of lists (on the right) as
a function of type $\ident{num}~\ident{list}\rightarrow\ident{num}$. The function fails for input
lists containing only zero or one elements and this is not reflected in the type and is not
enforced by the type checker.

Using coeffects (on the left), the function has a type $\ident{num}\xrightarrow{\cclrd{1}}\ident{num}$
meaning that it requires one past value (in addition to the current value). The safety property
for dataflow (Theorem~\ref{thm:semantics-sound-df}) shows that, when called with a context that
contains the required number of past values as captured by the coeffect type system, the function
does not get stuck.

In summary, a coeffect type system, captures certain runtime
demands of context-aware programs and (as we show in this chapter), eliminates common errors
related to working with context.



% ==================================================================================================
%
%    #######
%       #    #    # ######  ####  #####  #   #
%       #    #    # #      #    # #    #  # #
%       #    ###### #####  #    # #    #   #
%       #    #    # #      #    # #####    #
%       #    #    # #      #    # #   #    #
%       #    #    # ######  ####  #    #   #
%
% ==================================================================================================

\section{Categorical motivation}
\label{sec:semantics-theory}

The type system of the flat coeffect calculus arises syntactically, as a generalization of the examples
discussed in Chapter~\ref{ch:applications}, but we can also obtain it by looking at the categorical
semantics of context-dependent computations. This is a direction that we explore in this section.
Although the development presented here is interesting in its own, our main focus is \emph{using}
categorical semantics to motivate and explain the translation discussed in
Section~\ref{sec:semantics-translation}.

% --------------------------------------------------------------------------------------------------

\subsection{Comonads are to coeffects what monads are to effects}

The development in this chapter closely follows the example of effectful computations.
Effect systems provide a type system for tracking effects and monadic translation can be used as
a basis for implementing effectful domain-specific languages (e.g.~through the do-notation in
Haskell).

The correspondence between effect system and monads has been pointed out by Wadler and Thiemann
\cite{monads-effects-marriage} and further explored by Atkey \cite{monads-parameterised-notions}
and Vazou and Leijen \cite{monads-effects-remarriage}). This line of work relates effectful
functions $\tau_1 \xrightarrow{\sigma} \tau_2$ to monadic computations
$\tau_1 \rightarrow \mtyp{\sigma} \tau_2$. In this chapter, we show a similar correspondence between
\emph{coeffect systems} and \emph{comonads}. However, due to the asymmetry of $\lambda$-calculus,
defining the semantics in terms of comonadic computations is not a simple mechanical dualisation
of the work on effect systems and monads.

Our approach is inspired by the work of Uustalu and Vene \cite{comonads-notions} who present the
semantics of contextual computations (mainly for dataflow) in terms of comonadic functions
$\ctyp{}\tau_1 \rightarrow \tau_2$. We introduce \emph{indexed comonads} that annotate the structure
with information about the required context, \ie~$\ctyp{\cclrd{r}} \tau_1 \rightarrow \tau_2$.
This is similar to the recent development on monads and effects by Katsumata \cite{monads-parametric}
who parameterizes monads in a similar way to our indexed comonads.

% --------------------------------------------------------------------------------------------------

\subsection{Categorical semantics}

As discussed in Section~\ref{sec:path-sem}, a categorical semantics interprets terms as morphisms
in some category. For typed calculi, the semantics defined by $\sem{-}$ usually interprets a term
with a typing derivation leading to a judgement $x_1 \!:\! \tau_1 \ldots x_n \!:\! \tau_n \vdash e: \tau$
as a morphism $\sem{\tau_1 \times \ldots \times \tau_n} \rightarrow \sem{\tau}$.

For a well-defined semantics, we need to ensure that a well-typed term is assigned exactly one
meaning. This can be achieved in a number of ways. First, we can prove the \emph{coherence}
\cite{semantics-bltres} and show the morhphisms assigned to multiple typing derivations are equivalent.
Second, the typing judgement can have a unique typing derivation. We follow the latter approach,
using the uniqye typing derivation specified in Section~\ref{sec:flat-unique}.

As a best known example, Moggi \cite{monad-notions} showed that the semantics of various effectful
computations can be captured uniformly using (\emph{strong}) \emph{monads}. In that
approach, computations are interpreted as $\tau_1 \times \ldots \times \tau_n \rightarrow \mtyp{}{\tau}$,
for some monad $\mtyp{}{}$. For example, $\mtyp{}{\alpha} = \alpha \cup \{ \bot \}$ models
failures (the Maybe monad), $\mtyp{}{\alpha} = \mathcal{P}(\alpha)$ models non-determinism (list
monad) and side-effects can be modelled using $\mtyp{}{\alpha} = S \rightarrow (\alpha \times S)$
(state monad). Here, the structure of a strong monad provides necessary ``plumbing'' for composing
monadic computations -- sequential composition and strength for lifting free variables into the
body of computation under a lambda abstraction.

Following a similar approach to Moggi, Uustalu and Vene \cite{comonads-notions} showed that
(\emph{monoidal}) \emph{comonads} uniformly capture the semantics of various kinds of context-dependent
computations~\cite{comonads-notions}. For example, data-flow computations over non-empty lists
are modelled using the non-empty list comonad $\ident{NEList}\,\alpha = \alpha + (\alpha \times \ident{NEList}\,\alpha)$.

The monadic and comonadic model outlined aboe represents at most a binary analysis of effects or
context-dependence. A function $\tau_1 \rightarrow \tau_2$ performs \emph{no} effects (requires no
context) whereas $\tau_1 \rightarrow \mtyp{}{\tau_2}$ performs \emph{some} effects and
$\ctyp{}{\tau_1} \rightarrow \tau_2$ requires \emph{some} context\footnote{This is an
over-simplification as we can use \eg~stacks of monad transformers and model functions with
two different effects using $\tau_1 \rightarrow M_1(M_2~\tau_2)$. However, monad transformers
require the user to define complex systems of lifting to be composable. Consequently, they are usually used
for capturing different kinds of impurities (exceptions, non-determinism, state), but not for
capturing fine-grained properties (\eg~a set of memory regions that may be accessed by a
stateful computation).}.

In the next section, we introduce \emph{indexed comonads}, which provide a more precise analysis
and let us model computations with context demands $\cclrd{r}$ as functions
$\ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2$ using an \emph{indexed comonad} $\ctyp{\cclrd{r}}{}$.

% --------------------------------------------------------------------------------------------------

\subsection{Introducing comonads}

In category theory, \emph{comonad} is a dual of \emph{monad}. As already outlined in
Chapter~\ref{ch:pathways}, we obtain a definition of a comonad by taking a definition of a monad
and ``reversing the arrows''. More formally, one of the equivalent definitions of comonad
looks as follows (repeated from Section~\ref{sec:path-sem}):

\begin{definition}
A \emph{comonad} over a category $\catc$ is a triple $(C, \ident{counit}, \ident{cobind})$ where:
\begin{compactitem}
\item $C$ is a mapping on objects (types) $C : \catc \rightarrow \catc$
\item $\ident{counit}$ is a mapping $\ctyp{}{\alpha} \rightarrow \alpha$
\item $\ident{cobind}$ is a mapping $(\ctyp{}{\alpha} \rightarrow \beta)
  \rightarrow (\ctyp{}{\alpha} \rightarrow \ctyp{}{\beta})$
\end{compactitem}
such that, for all $f:\ctyp{}{\alpha} \rightarrow \beta$ and $g:\ctyp{}{\beta} \rightarrow \gamma$:
\begin{align}
\tag{\emph{left identity}}
  \ident{cobind}~\ident{counit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{counit} \circ \ident{cobind}~f &= f
  \\
\tag{\emph{associativity}}
  \ident{cobind}~(g \circ \ident{cobind}~f) &= (\ident{cobind}~g) \circ (\ident{cobind}~f)
\end{align}
\end{definition}

\noindent
From the functional programming perspective, we can see $\ctyp{}{}$ as a parametric data type such as
\ident{NEList}. The $\ident{counit}$ operations extracts a value $\alpha$ from a value that carries
additional context $\ctyp{}{\alpha}$. The $\ident{cobind}$ operation turns a context-dependent function
$\ctyp{}{\alpha} \rightarrow \beta$ into a function that takes a value with context, applies
the context-dependent function to value(s) in the context and then propagates the context.

As mentioned earlier, Uustalu and Vene \cite{comonads-notions} use comonads to model data-flow
computations. They describe infinite (coinductive) streams and non-empty lists as example comonads.

\begin{example}[Non-empty list]
A non-empty list is a recursive data-type defined as $\ident{NEList}\,\alpha = \alpha + (\alpha \times \ident{NEList}\,\alpha)$.
We write \kvd{inl} and \kvd{inr} for constructors of the left and right cases, respectively. The
type \ident{NEList} forms a comonad together with the following \ident{counit} and \ident{cobind} mappings:
%
\begin{equation*}
\begin{array}{rclll}
\ident{counit}~l &\narrow{=}& h &\quad&\textnormal{when}~l=\kvd{inl}~h\\[-0.25em]
\ident{counit}~l &\narrow{=}& h &&\textnormal{when}~l=\kvd{inr}~(h, t)\\[0.5em]
\ident{cobind}\,f~l &\narrow{=}& \kvd{inl}~(f\,l) &&\textnormal{when}~l=\kvd{inl}~h\\[-0.25em]
\ident{cobind}\,f~l &\narrow{=}& \kvd{inr}~(f\,l,\;\ident{cobind}~f~t) &&\textnormal{when}~l=\kvd{inr}~(h, t)
\end{array}
\end{equation*}
\end{example}

\noindent
The \ident{counit} operation returns the head of the non-empty list. Note that it is crucial that
the list is \emph{non-empty}, because we always need to be able to obtain a value. The \ident{cobind}
operation defined here returns a list of the same length as the original where, for each element, the
function $f$ is applied on a \emph{suffix} list starting from the element. Using a simplified
notation for list, the result of applying \ident{cobind} to a function that sums elements of a
list gives the following behaviour:
%
\begin{equation*}
\ident{cobind}~\ident{sum}~(7,6,5,4,3,2,1,0) = (28,21,15,10,6,3,1,0)
\end{equation*}
%
The fact that the function $f$ is applied to a \emph{suffix} is important in order to satisfy the
\emph{left identity} law, which requires that $\ident{cobind}~\ident{counit}~l = l$.

It is also interesting to examine some data types that do \emph{not} form a comonad. As already
mentioned, list $\ident{List}~\alpha = 1 + (\alpha \times \ident{List}~\alpha)$ is not a comonad,
because the \ident{counit} operation is not defined for the value $\kvd{inl}~()$. The \ident{Maybe}
data type defined as $1 + \alpha$ is not a comonad for the same reason. However, if we consider
flat coeffect calculus for liveness, it appears natural to model computations as functions
$\ident{Maybe}~\tau_1 \rightarrow \tau_2$. To use such a model, we need to generalize comonads
to \emph{indexed comonads}.

% --------------------------------------------------------------------------------------------------

\subsection{Generalising to indexed comonads}
\label{sec:semantics-flat-idx}

The flat coeffect algebra includes a monoid $(\C, \cseq, \cunit)$, which defines the behaviour of
sequential composition, where the element $\cunit$ represents a variable access. An indexed
comonad is formed by a data type (object mapping) $\ctyp{\cclrd{r}}{\alpha}$ where the $\cclrd{r}$
(also called \emph{annotation}) is a member of the set $\C$ and determines what context is required.

\begin{definition}
Given a monoid $(\C, \cseq, \cunit)$ with binary operator $\cseq$ and unit $\cunit$, an
\emph{indexed comonad} over a category $\catc$ is a triple
$(\ctyp{\cclrd{r}{}}, \ident{counit}_{\cunit}, \ident{cobind}_{\cclrd{r}, \cclrd{s}})$ where:

\begin{compactitem}
\item $\ctyp{\cclrd{r}}{}$ for all $\cclrd{r} \in \C$ is a family of object mappings
\item $\ident{counit}_{\cunit}$ is a mapping $\ctyp{\cunit}{\alpha} \rightarrow \alpha$
\item $\ident{cobind}_{\cclrd{r}, \cclrd{s}}$ is a mapping $(\ctyp{\cclrd{r}}{\alpha} \rightarrow \beta)
  \rightarrow (\ctyp{\cclrd{r}\cseq\cclrd{s}}{\alpha} \rightarrow \ctyp{\cclrd{s}}{\beta})$
\end{compactitem}
such that, for all $f:\ctyp{\cclrd{r}}{\alpha} \rightarrow \beta$ and $g:\ctyp{\cclrd{s}}{\beta} \rightarrow \gamma$:f
\begin{align}
\tag{\emph{left identity}}
  \ident{cobind}_{\cunit, \cclrd{s}}~\ident{counit}_{\cunit} &= \idf{}
  \\
\tag{\emph{right identity}}
  \ident{counit}_{\cunit} \circ \ident{cobind}_{\cclrd{r}, \cunit}~f &= f
  \\
\tag{\emph{associativity}}
\hspace{-10em}
  \ident{cobind}_{\cclrd{r}\cseq\cclrd{s},\cclrd{t}}~(g \circ \ident{cobind}_{\cclrd{r}, \cclrd{s}}~f) &=
    (\ident{cobind}_{\cclrd{s}, \cclrd{t}}~g) \circ (\ident{cobind}_{\cclrd{r}, \cclrd{s}\cseq\cclrd{t}}~f)
\end{align}
\end{definition}

\noindent
Rather than defining a single mapping $\ctyp{}{}$, we are now defining a family of mappings
$\ctyp{\cclrd{r}}{}$ indexed by elements of the monoid structure $\C$. Similarly, the $\ident{cobind}_{\cclrd{r}, \cclrd{s}}$
operation is now formed by a \emph{family} of mappings for different pairs of indices
$\cclrd{r}, \cclrd{s}$. To be fully precise, $\ident{cobind}$ is a family of natural transformations
and we should include objects $\alpha, \beta$ (modeling types) as indices, writing $\ident{cobind}_{\cclrd{r},\cclrd{s}}^{\alpha, \beta}$.
For the purpose of this thesis, it is sufficient to omit the superscripts and treat $\ident{cobind}$ just
as a family of mappings (rather than natural transformations). When this does not introduce ambiguity,
we also occasionally omit the subscripts.

The $\ident{counit}$ operation is not defined for all $\cclrd{r} \in \C$, but only for
the unit $\cunit$. Nevertheless we continue to write $\ident{counit}_{\cunit}$,
but this is merely for symmetry and as a useful reminder to the reader. Crucially, this means that
the operation is defined only for special contexts.

If we look at the indices in the comonad axioms, we can see that the left and right identity
require $\cunit$ to be the unit of $\cseq$. Similarly, the associativity law implies the
associativity of the $\cseq$ operator.

\paragraph{Composition.}
The co-Kleisli category that models sequential composition is formed by the unit arrow (provided
by $\ident{counit}$) together with the (associative) composition operation that composes computations
with contextual demands as follows:
%
\begin{equation*}
\begin{array}{ccl}
\textnormal{--}\, \hat{\circ} \,\textnormal{--}&\narrow{:}& (\ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2)
  \rightarrow (\ctyp{\cclrd{s}}{\tau_2} \rightarrow \tau_3)
  \rightarrow (\ctyp{\cclrd{r} \cseq \cclrd{s}}{\tau_1} \rightarrow \tau_3) \\
g \, \hat{\circ} \, f &\narrow{=}& g \circ (\ident{cobind}_{\cclrd{r}, \cclrd{s}} f)
\end{array}
\end{equation*}
%
The composition $\hat{\circ}$ best expresses the intention of indexed comonads. Given two functions
with contextual demands $\cclrd{r}$ and $\cclrd{s}$, their composition is a function that
requires $\cclrd{r}\,\cseq\,\cclrd{s}$. The contextual demands propagate \emph{backwards} and
are attached to the input of the composed function.

% --------------------------------------------------------------------------------------------------

\paragraph{Examples.}

Any comonad can be turned into an indexed comonad using a trivial monoid. However, indexed comonads
are more general and can be used with other data types, including indexed \ident{Maybe}.

\begin{example}[Comonads]
Any comonad $\ctyp{}{}$ is an indexed comonad with an index provided by a trivial monoid $(\{1\},\ast,1)$
where $1\ast 1 = 1$. The mapping $\ctyp{1}{}$ is the mapping $\ctyp{}{}$ of the underlying comonad. The
operations $\ident{counit}_1$ and $\ident{cobind}_{1,1}$ are defined by the operations $\ident{counit}$
and $\ident{cobind}$ of the comonad.
\end{example}

\begin{example}[Indexed Maybe]
The \emph{indexed Maybe comonad} is defined over a monoid $(\{ \ident{L},\ident{D} \}, \sqcup,\ident{L})$
where $\sqcup$ is defined as earlier, \ie~$\ident{L} = \cclrd{r} \sqcup \cclrd{s} \Longleftrightarrow \cclrd{r}=\cclrd{s}=\ident{L}$.
Assuming $1$ is the unit type inhabited by $()$, the mappings are defined as follows:
%
\begin{equation*}
\begin{array}{l}
\ctyp{\ident{L}}{\alpha} = \alpha\\
\ctyp{\ident{D}}{\alpha} = 1\\
\\
\ident{counit}_{\ident{L}} : \ctyp{\ident{L}}{\alpha} \rightarrow \alpha \\
\ident{counit}_{\ident{L}}~v = v\\
\end{array}
\qquad
\begin{array}{lcl}
\multicolumn{3}{l}{
  \ident{cobind}_{\cclrd{r},\cclrd{s}} ~:~ (\ctyp{\cclrd{r}}{\alpha} \rightarrow \beta)
    \rightarrow (\ctyp{\cclrd{r}\sqcup\cclrd{s}}{\alpha} \rightarrow \ctyp{\cclrd{s}}{\beta}) }\\
\ident{cobind}_{\ident{L},\ident{L}}~f~x &\narrow{=}& f~x\\
\ident{cobind}_{\ident{L},\ident{D}}~f~() &\narrow{=}& ()\\
\ident{cobind}_{\ident{D},\ident{L}}~f~() &\narrow{=}& f~()\\
\ident{cobind}_{\ident{D},\ident{D}}~f~() &\narrow{=}& ()\\
\end{array}
\end{equation*}
\end{example}

\noindent
The \emph{indexed Maybe comonad} models the semantics of the liveness coeffect system discussed in
Section~\ref{sec:applications-flat-live}, where $\ctyp{\ident{L}}{\alpha} = \alpha$ models a live context
and $\ctyp{\ident{D}}{\alpha}=1$ models a dead context which does not contain a value. The \ident{counit}
operation extracts a value from a live context. As in the direct model discussed in Chapter~\ref{ch:appendix},
the \ident{cobind} operation can be seen as an implementation of dead code elimination. The definition
only evaluates $f$ when the result is marked as live and is thus required, and it only accesses $x$ if
the function $f$ requires its input.

The indexed family $\ctyp{\cclrd{r}}{}$ in the above example is analogous to the \ident{Maybe}
(or option) data type $\ident{Maybe}\,\alpha = 1 + \alpha$. As mentioned earlier, this type does not
permit (non-indexed) comonad structure, because $\ident{counit}~()$ is not defined. This is not a
problem with indexed comonads, because live contexts are distinguished by the (type-level) coeffect
annotation and \ident{counit} only needs to be defined on live contexts.

\begin{example}[Indexed product]
The semantics of implicit parameters is modelled by an indexed product comonad. We use a monoid
$(\mathcal{P}(\ident{Id}), \cup, \emptyset)$ where \ident{Id} is the set of (implicit parameter) names.
We assume that, all implicit parameters have the type $\ident{num}$. The data type $\ctyp{\cclrd{r}}{\alpha}
= \alpha \times (\cclrd{r} \rightarrow \ident{num})$ represents a value $\alpha$ together with a function that
associates a parameter value $\ident{num}$ with every implicit parameter name in $\cclrd{r} \subseteq \ident{Id}$.
The cobind and counit operations are defined as:
%
\begin{equation*}
\begin{array}{l}
\ident{counit}_{\emptyset} : \ctyp{\emptyset}{\alpha} \rightarrow \alpha \\[-0.25em]
\ident{counit}_{\emptyset}~(a, g) = a\\[0.5em]
\end{array}
\quad
\begin{array}{l}
\ident{cobind}_{\cclrd{r},\cclrd{s}} ~:~ (\ctyp{\cclrd{r}}{\alpha} \rightarrow \beta)
    \rightarrow (\ctyp{\cclrd{r}\cup\cclrd{s}}{\alpha} \rightarrow \ctyp{\cclrd{s}}{\beta})\\[-0.25em]
\ident{cobind}_{\cclrd{r},\cclrd{s}}~f~(a,g) = (f(a,\restr{g}{\cclrd{r}}), \restr{g}{\cclrd{s}})\\[0.5em]
\end{array}
\end{equation*}
\end{example}

\noindent
In the definition, we use the notation $(a, g)$ for a pair containing a value of type $\alpha$
together with $g$, which is a function of type $\cclrd{r} \rightarrow \ident{num}$. The \ident{counit} operation
takes a value and a function (with empty set as a domain), ignores the function and extracts the
value. The \ident{cobind} operation uses the restriction operation $\restr{g}{\cclrd{r}}$ to
restrict the domain of $g$ to implicit parameters $\cclrd{r}$ and $\cclrd{s}$ in oder to get
implicit parameters required by the argument of $f$ and by the resulting computation, respectively
(\ie~semantically, it \emph{splits} the available context capabilities). The function $g$ passed
to \ident{cobind} is defined on $\cclrd{r} \cup \cclrd{s}$ and so the restriction is
valid in both cases.

The structure of \emph{indexed comonads} is sufficient to model sequential composition of
computations that use a single variable (as discussed in Section~\ref{sec:path-sem}). To model
full $\lambda$-calculus with lambda abstraction and multiple-variable contexts, we need
additional operations introduced in the next section.

% --------------------------------------------------------------------------------------------------

\subsection{Flat indexed comonads}
\label{sec:semantics-flat-monoidal}

Because of the asymmetry of $\lambda$-calculus (discussed in Section~\ref{sec:applications-structure}),
the duality between monads and comonads does not lead us towards the additional structure
required to model full $\lambda$-calculus. In comonadic computations, additional information is attached
to the context. In application and lambda abstraction, the context is propagated differently than
in effectful computations.

To model the effectful $\lambda$-calculus, Moggi~\cite{monad-notions} requires a \emph{strong} monad which
has an additional operation $\ident{strength} : \alpha\times\mtyp{}{\beta} \rightarrow \mtyp{}{(\alpha\times\beta)}$.
This allows lifting of free variables into an effectful computation. In Haskell, strength can be expressed
in the host language and so is implicit.

To model $\lambda$-calculus with contextual properties, Uustalu and Vene \cite{comonads-notions}
require \emph{lax semi-monoidal} comonad. This structure requires an additional monoidal operation:
%
\begin{equation*}
\ident{m} : \ctyp{}{\alpha} \times \ctyp{}{\beta} \rightarrow \ctyp{}{(\alpha \times \beta)}
\end{equation*}
%
The \ident{m} operation is needed in the semantics of lambda abstraction. Semantically, it represents
merging of contextual capabilities attached to the variable contexts of the declaration site (containing free variables)
and the call site (containing bound variable). For example, for implicit parameters, this combines
the additional parameters defined in the two contexts.

The semantics of flat coeffect calculus requires not only operations for \emph{merging}, but also for
\emph{splitting} of contexts.

\begin{definition}
Given a flat coeffect algebra $(\C, \cseq, \cpar, \czip, \cunit, \czero, \cleq)$,
a \emph{flat indexed comonad} is an indexed comonad over the monoid $(\C, \cseq, \cunit)$
equipped with families of operations $\ident{merge}_{\cclrd{r},\cclrd{s}}$, $\ident{split}_{\cclrd{r},\cclrd{s}}$ where:
%
\begin{compactitem}
\item $\ident{merge}_{\cclrd{r},\cclrd{s}}$ is a family of mappings
  $\ctyp{\cclrd{r}}{\alpha} \times \ctyp{\cclrd{s}}{\beta} \rightarrow \ctyp{\cclrd{r}\czip\cclrd{s}}{(\alpha \times \beta)}$
\item $\ident{split}_{\cclrd{r},\cclrd{s}}$ is a family of mappings
  $\ctyp{\cclrd{r}\cpar\cclrd{s}}{(\alpha \times \beta)} \rightarrow \ctyp{\cclrd{r}}{\alpha} \times \ctyp{\cclrd{s}}{\beta}$
\end{compactitem}
\end{definition}

\noindent
The $\ident{merge}_{\cclrd{r},\cclrd{s}}$ operation is the most interesting one. Given two comonadic
values with additional contexts specified by $\cclrd{r}$ and $\cclrd{s}$, it combines them into a
single value with additional context $\cclrd{r}\,\czip\,\cclrd{s}$. The $\czip$ operation often represents
\emph{greatest lower bound}. We look at examples of this operation in the next section.

The $\ident{split}_{\cclrd{r},\cclrd{s}}$ operation splits a single comonadic value (containing a tuple)
into two separate values. Note that this does not simply duplicate the value, because the additional
context is also split. To obtain coeffects $\cclrd{r}$ and $\cclrd{s}$, the input needs to provide
\emph{at least} $\cclrd{r}$ and $\cclrd{s}$, so the tags are combined using the $\cpar$, which is often
the \emph{least upper-bound}\footnote{The $\czip$ and $\cpar$ operations are the greatest and least upper
bounds in the liveness and data-flow examples, but not for implicit parameters. However, they remain useful
as an informal analogy.}.

\paragraph{Semantics of sub-coeffecting.}
Although we do not include sub-coeffecting in the core flat coeffect calculus, it is an interesting
extension to consider. Semantically, sub-coeffecting drops some of the available contextual
capabilities (drops some of the implicit parameters or some of the past values). This can be
modelled by adding a (family of) lifting operation(s):
%
\begin{itemize}
 \item $\ident{lift}_{\cclrd{r'},\cclrd{r}}$ is a family of mappings
   $\ctyp{\cclrd{r'}}{\alpha} \rightarrow \ctyp{\cclrd{r}}{\alpha}$~ for all $\cclrd{r'}, \cclrd{r}$ such that $\cclrd{r}\,\cleq\,\cclrd{r'}$
\end{itemize}
%
The axioms of flat coeffect algebra do not, in general, require that
$\cclrd{r} \;\cleq\; \cclrd{r}\,\cpar\,\cclrd{s}$ and $\cclrd{s} \;\cleq\; \cclrd{r}\,\cpar\,\cclrd{s}$,
but the property holds for the three sample coeffect systems we consier. For systems with
the above property, the \ident{split} operation can be expressed in terms of lifting
(sub-coeffecting) as follows:
%
\begin{equation*}
\begin{array}{rcl}
\ident{map}_{\cclrd{r}}~f &\narrow{=}& \ident{cobind}_{\cclrd{r}, \cclrd{r}}~(f\circ\ident{counit}_{\cunit}) \\
\ident{split}_{\cclrd{r}, \cclrd{s}}~c &\narrow{=}&
  ( \ident{map}_{\cclrd{r}}~\ident{fst}~(\ident{lift}_{\cclrd{r}\cpar\cclrd{s}, \cclrd{r}}~c),~
    \ident{map}_{\cclrd{s}}~\ident{snd}~(\ident{lift}_{\cclrd{r}\cpar\cclrd{s}, \cclrd{s}}~c) )
\end{array}
\end{equation*}
%
The $\ident{map}_{\cclrd{r}}$ operation is the mapping on arrows that corresponds to the object
mapping $\ctyp{\cclrd{r}}{}$. The definition is dual to the standard definition of \ident{map}
for monads in terms of \ident{bind} and \ident{unit}. The functions \ident{fst} and \ident{snd}
are first and second projections from a two-element pair. To define the
$\ident{split}_{\cclrd{r}, \cclrd{s}}$ operation, we use the argument $c$ twice, use lifting
to throw away additional parts of the context and then transform the values in the
context.

This alternative definition is valid for our examples, but we do not use it for three reasons. First,
it requires making sub-coeffecting a part of the core definition. Second, this would be the only
place where our semantics uses a variable \emph{twice} (in this case $c$). Note therefore that
our use of an explicit \ident{split} means that the structure required by our semantics does not
need to provide variable duplication and our model could be embedded in linear or affine category.
Finally, explicit \ident{split} is similar to the definition that is needed for structural coeffects
in Chapter~\ref{ch:structural} and it makes the connection between the two easier to see.

\paragraph{Examples.}
All the examples of \emph{indexed comonads} discussed in Section~\ref{sec:semantics-flat-idx} can
be extended into \emph{flat indexed comonads}. Note however that this cannot be done mechanically,
because each example requires us to define additional operations, specific for the example.

\begin{example}[Monoidal comonads]
Just like indexed comonads generalize co\-monads, the additional structure of
flat indexed comonads generalizes the symmetric semimonoidal comonads of Uustalu
and Vene \cite{comonads-notions}. The flat coeffect algebra is defined as $(\{1\}, \ast, \ast, \ast, 1, 1, =)$
where $1\ast1=1$ and $1=1$. The additional operation $\ident{merge}_{1,1}$ is provided by the
monoidal operation called \ident{m} by Uustalu and Vene. The $\ident{split}_{1,1}$ operation
is defined by duplication.
\end{example}

\begin{example}[Indexed Maybe comonad]
\label{thm:semantics-indexed-opt}

The flat coeffect algebra for liveness defines $\cpar$ and $\czip$, respectively as $\sqcup$ and $\sqcap$
and specifies that $\ident{D} \sqsubseteq \ident{L}$. Recall also that the object mapping is defined
as $\ctyp{\ident{L}}{\alpha} = \alpha$ and $\ctyp{\ident{D}}{\alpha} = 1$. The additional operations
of a flat indexed comonad are defined as follows:
%
\begin{equation*}
\begin{array}{rcl}
\ident{merge}_{\ident{L}, \ident{L}}~(a, b) &\narrow{=}& (a, b)\\
\ident{merge}_{\ident{L}, \ident{D}}~(a, ()) &\narrow{=}& ()\\
\ident{merge}_{\ident{D}, \ident{L}}~((), b) &\narrow{=}& ()\\
\ident{merge}_{\ident{D}, \ident{D}}~((), ()) &\narrow{=}& ()\\
\end{array}
\qquad
\begin{array}{rcl}
\ident{split}_{\ident{L}, \ident{L}}~(a, b) &\narrow{=}& (a, b)\\
\ident{split}_{\ident{L}, \ident{D}}~(a, b) &\narrow{=}& (a, ())\\
\ident{split}_{\ident{D}, \ident{L}}~(a, b) &\narrow{=}& ((), b)\\
\ident{split}_{\ident{D}, \ident{D}}~() &\narrow{=}& ((), ()))\\
\end{array}
\end{equation*}
\end{example}

\noindent
Without the indexing, the \ident{merge} operations implements \emph{zip} on Maybe values,
returning a value only when both values are present. The behaviour of the \ident{split}
operation is partly determined by the indices. When the input is \emph{dead}, both values have
to be dead (this is also the only solution of $\cclrd{\ident{D}} =\cclrd{r}\sqcap\cclrd{s}$), but when
the input is \emph{live}, the operation can perform implicit sub-coeffecting and drop one of
the values.

\begin{example}[Indexed product]
\label{thm:semantics-indexed-prod}

For implicit parameters, both $\czip$ and $\cpar$ are the $\cup$ operation and the relation
$\cleq$ is formed by the subset relation $\subseteq$. Recall that the comonadic data type $\ctyp{\cclrd{r}}{\alpha}$
is $\alpha \times (\cclrd{r} \rightarrow \ident{num})$ where $\ident{num}$ is the type of implicit parameter values.
The additional operations are defined as:
%
\begin{equation*}
\begin{array}{rcl}
\ident{split}_{\cclrd{r}, \cclrd{s}}~((a,b), g) &\narrow{=}& ((a, \restr{g}{\cclrd{r}}), (b, \restr{g}{\cclrd{s}}))\\
\ident{merge}_{\cclrd{r}, \cclrd{s}}~((a, f), (b, g)) &\narrow{=}& ((a, b), f \uplus g)\\
\end{array}
\quad
\begin{array}{l}
\textnormal{where}~f \uplus g = \\[-0.25em]
\quad\restr{f}{\, \textit{dom}(f) \setminus \textit{dom}(g)} \cup g
\end{array}
\end{equation*}
\end{example}

\noindent
The \ident{split} operation splits the tuple and restricts the function (representing available
implicit parameters) to the required subsets. The \ident{merge} operation is more
interesting. It uses the $\uplus$ operation that we defined when introducing implicit parameters
in Section~\ref{sec:applications-flat-impl}. It merges the values, preferring the definitions from
the right-hand side (call site) over left-hand side (declaration site). Thus the operation is not
symmetric.

\begin{example}[Indexed list]
\label{thm:semantics-indexed-list}

Our last example provides the semantics of data-flow computations. The flat coeffect algebra
is formed by $(\mathbb{N}, +, \mathit{max}, \mathit{min}, 0, 0, \leq)$. In a
non-indexed version, the semantics is provided by a non-empty list. In the indexed semantics,
the index represents the number of available past values. The data type is then a pair of
the current value, followed by $n$ past values. The mappings that form the flat indexed comonad
are defined as follows:
%
\begin{equation*}
\begin{array}{l}
\ident{counit}_{0}\langle a_0 \rangle = a_0
\\[0.45em]
\ident{cobind}_{m, n}~f \langle a_0, \ldots a_{m+n} \rangle = \\[-0.25em]
\quad \langle f \langle a_0, \ldots, a_m \rangle, \ldots, f \langle a_{n}, \ldots, a_{m+n} \rangle \rangle
\\[0.45em]
\ident{merge}_{m, n} (\langle a_0, \ldots, a_m \rangle, \langle b_0, \ldots, b_n\rangle) = \\[-0.25em]
\quad \langle (a_0, b_0), \ldots, (a_{\mathit{min}(m,n)}, b_{\mathit{min}(m,n)}) \rangle
\\[0.45em]
\ident{split}_{m, n} \langle (a_0, b_0), \ldots, (a_{\mathit{max}(m,n)}, b_{\mathit{max}(m,n)}) \rangle = \\[-0.25em]
\quad (\langle a_0, \ldots, a_m \rangle, \langle b_0, \ldots, b_n\rangle)
\end{array}
\begin{array}{l}
\hspace{-2em}\ctyp{n}{\alpha} = \underbrace{\alpha \times \ldots \times \alpha}_{(n+1)-\textnormal{times}}\\[8em]
~\\
\end{array}
\end{equation*}
\end{example}

\noindent
The reader is invited to check that the number of required past elements in each of the mappings
matches the number specified by the indices. The index specifies the number of \emph{past} elements
and so the list always contains at least one value. Thus \ident{counit} returns the element of a
singleton list.

The $\ident{cobind}_{m,n}$ operation requires $m + n$ elements in order to generate $n$ past results
of the $f$ function, which itself requires $m$ past values. When combining two lists,
$\ident{merge}_{m,n}$ behaves as \emph{zip} and produces a list that has the length of the shorter
argument. When splitting a list, $\ident{split}_{m, n}$ needs the maximum of the required lengths.


% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]
The semantics is defined over a typing derivation:
%
\begin{equation*}
\hspace{-3em}
\begin{array}{ll}
\hspace{5.2em}\semdef
  {\coctx{\Gamma}{\cunit} \vdash x_i : \tau_i }
  {\pi_i \circ \ident{counit}_{\cunit}}
& (\emph{var})
\\[1em]
\hspace{4.9em}\semdef
  {\coctx{\Gamma}{\czero} \vdash n : \ident{num} }
  {\ident{const}~n}
& (\emph{num})
\\[1.5em]
\hspace{2.2em}\semdeff
  {\coctx{\Gamma, x:\tau_1}{\cclrd{r}\;\czip\;\cclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 }
  {f}
  {f \circ \ident{curry}~\ident{merge}_{\cclrd{r}, \cclrd{s}} }
& (\emph{abs})
\\[2em]
\emdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\begin{array}{l}\sem{\coctx{\Gamma}{\cclrd{r} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{t})} \vdash e_1~e_2 : \tau_2}\\[-0.3em]~\end{array}}
  {f}
  {g}
  {\hspace{-0.5em}\begin{array}{l}
  \ident{app}~\circ~f\hspace{-0.15em}\times\hspace{-0.15em}(\ident{cobind}_{\cclrd{s}, \cclrd{t}}~g)~\circ~\ident{split}_{\cclrd{r}, \cclrd{s} \,\cseq\, \cclrd{t}} \\[-0.3em]
  ~~\circ~\ident{map}_{\cclrd{r} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{t})}~\ident{dup}\\[-0.3em]
  \end{array}\hspace{-0.5em}}
& (\emph{app})
\end{array}
\end{equation*}

~

Assuming the following auxiliary operations:
%
\begin{equation*}
\begin{array}{rcl}
  \ident{map}_\cclrd{r}}~f &=& \ident{cobind}_{\cunit, \cclrd{r}}~(f\circ\ident{counit}_\cunit) \\[-0.3em]
  \ident{const}~v &=& \lambda x.v \\[-0.3em]
  \ident{curry}~f~x~y &=& \lambda f.\lambda x.\lambda y.f~(x, y)\\[-0.3em]
  \ident{dup}~x &=& (x, x)\\[-0.3em]
  f \times g &=& \lambda (x, y).(f~x, g~y)\\[-0.3em]
  \ident{app}~(f, x) &=& f~x
\end{array}
\end{equation*}


\figcaption{Categorical semantics of the flat coeffect calculus}
\label{fig:semantics-flat}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\subsection{Semantics of flat calculus}
\label{sec:semantics-flat-calculus}

In Section~\ref{sec:applications-flat}, we defined the semantics of concrete (flat) context-dependent
computations including implicit parameters, liveness and data-flow. Using the \emph{flat indexed
comonad} structure, we can now define a single uniform semantics that is capable of capturing all
our examples, as well as various other computations.

As discussed in Section~\ref{sec:flat-unique}, different typing derivations of coeffect programs
may have different meaning (\eg~when working with implicit parameters) and so the semantics is
defined over a \emph{typing derivation} rather than over an \emph{term}. To assign a semantics to
a term, we need to choose a particular typing derivation. The algorithm for choosing a unique
typing derivation for our three systems has been defined in Section~\ref{sec:flat-unique}.

\paragraph{Contexts and types.}
The modelling of contexts and functions generalizes the concrete examples discussed in
Chapter~\ref{ch:applications}. We use the family of mappings $\ctyp{\cclrd{r}}{}$ as an (indexed)
data-type that wraps the product of free variables of the context and the arguments of functions:
%
\begin{equation*}
\begin{array}{rcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \cclrd{r} } \vdash e : \tau}
  &:& \ctyp{\cclrd{r}}{(\tau_1 \times \ldots \times \tau_n)} \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\cclrd{r}} \tau_2} &=& \ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2
\end{array}
\end{equation*}

\paragraph{Expressions.}
The definition of the semantics is shown in Figure~\ref{fig:semantics-flat}. For consistency
with earlier work \cite{comonads-notions,comonads-dom-thesis}, the definitions use a point-free
categorical notation. The semantics uses a number of auxiliary definitions that can be expressed
in a Cartesian-closed category such as currying \ident{curry}, value duplication \ident{dup},
function pairing (given $f:A\rightarrow B$ and $g:C\rightarrow D$ then $f\times g : A\times C \rightarrow B \times D$)
and application \ident{app}. We will embed the definitions in a simple programming language
later (Section~\ref{sec:semantics-translation}).

The semantics of variable access and abstraction are the same as in the semantics of Uustalu and
Vene \cite{comonads-notions}, modulo the indexing. The semantics of variable access (\emph{var}) uses
$\ident{counit}_{\cunit}$ to extract a product of free variables, followed by projection
$\pi_i$ to obtain the variable value. Abstraction (\emph{abs}) is interpreted as a curried
function that takes the declaration-site context and a function argument, merges them using
$\ident{merge}_{\cclrd{r}, \cclrd{s}}$ and passes the result to the semantics of the body $f$.
Assuming the context $\Gamma$ contains variables of types $\sigma_1, \ldots, \sigma_n$, this gives
us a value $\ctyp{\cclrd{r}\czip\cclrd{s}}((\sigma_1 \times \ldots \times \sigma_n) \times \tau_1)$.
Assuming that $n$-element tuples are associated to the left, the wrapped context is equivalent to
$\sigma_1 \times \ldots \times \sigma_n \times \tau_1$, which can then be passed to the body of the
function.

The semantics of application (\emph{app}) first duplicates the free-variable product inside the
context (using $\ident{map}_{\cclrd{r}}$ and duplication). Then it splits this context using
$\ident{split}_{\cclrd{r}, \cclrd{s} \cpar \cclrd{t}}$. The two contexts contain the same variables
(as required by sub-expressions $e_1$ and $e_2$), but different coeffect annotations. The first
context (with index $\cclrd{r}$) is used to evaluate $e_1$ using the semantic function $f$. The
result is a function $\ctyp{\cclrd{t}}{\tau_1} \rightarrow \tau_2$. The second context
(with index $\cclrd{s}\cseq\cclrd{t}$) is used to evaluate $e_2$ and using the semantic function $g$
and wrap it with context required by the function $e_1$ by applying $\ident{cobind}_{\cclrd{s}, \cclrd{t}}$.
The \ident{app} operation than applies the function (first element) on the argument (second element).
Finally, numbers (\emph{num}) become constant functions that ignore the context.

\paragraph{Properties.}
The categorical semantics  in Section~\ref{sec:semantics-translation} defines a translation
that embeds context-dependent computations in a functional programming language, similarly to how
monads and the do notation provide a way of embedding effectful computations in Haskell.

An important property of the translation is that it respects the coeffect annotations provided
by the type system. The annotations of the semantic functions match the annotations in the typing
judgement and so the semantics is well-defined.
This provides a further validation for the design of the type system developed in
Section~\ref{sec:flat-calculus-types} -- if the coeffect annotations for (\emph{app}) and (\emph{abs})
were different, we would not be able to provide a well-defined semantics using flat indexed comonads.

Informally, the following states that if we see the semantics as a translation, the resulting code
is well-typed. We revisit the property in Lemma~\ref{thm:semantics-welltyped} once we define
the target language and its typing.

\begin{lemma}[Correspondence]
\label{thm:flat-correspondence}
In the semantics defined in Figure~\ref{fig:semantics-flat}, the context annotations $\cclrd{r}$ of
typing judgements $\coctx{\Gamma}{\cclrd{r}} \vdash e : \tau$ and function types
$\tau_1 \xrightarrow{\cclrd{r}} \tau_2$  on the left-hand side correspond to the indices of mappings
$\ctyp{\cclrd{r}}{}$ in the corresponding semantic function on the right-hand side.
\end{lemma}
\begin{proof}
By analysis of the semantic rules in Figure~\ref{fig:semantics-flat}. We need to check that the
domains and codomains of the morphisms in the semantics (right-hand side) match.
\end{proof}

\noindent
Thanks to indexing, the correspondence provides more guarantees than for a non-indexed system.
In the semantics, we not only know which values are comonadic, but we also know what contextual
information they are required to provide. In Section~\ref{sec:semantics-generalising}, we note
that this lets us generalize the proofs about concrete languages discussed in this chapter to
a more general setting.

The semantics is also a generalization of the concrete semantics given when introducing
context-aware programming languages in Chapter~\ref{ch:applications}.

\begin{theorem}[Generalization]
\label{thm:flat-generalization}

Consider a typing derivation obtained according to the rules for finding unique typing derivations
as specified in Section~\ref{sec:flat-unique} for a coeffect language with liveness, dataflow or
implicit parameters.

The semantics obtained by instantiating the rules in Figure~\ref{fig:semantics-flat} with the
concrete operations defined in Example~\ref{thm:semantics-indexed-opt},
Example~\ref{thm:semantics-indexed-prod} or Example~\ref{thm:semantics-indexed-list} is the
same as the one defined in Figure~\ref{fig:applications-flat-livsem},
Figure~\ref{fig:applications-flat-implsem} and Figure~\ref{fig:applications-flat-dfsem},
respectively.
\end{theorem}
\begin{proof}
Simple expansion of the definitions for the unique typing derivation.
\end{proof}


% ==================================================================================================
%
%      #######
%      #       #    # #####  ###### #####  #####  # #    #  ####
%      #       ##  ## #    # #      #    # #    # # ##   # #    #
%      #####   # ## # #####  #####  #    # #    # # # #  # #
%      #       #    # #    # #      #    # #    # # #  # # #  ###
%      #       #    # #    # #      #    # #    # # #   ## #    #
%      ####### #    # #####  ###### #####  #####  # #    #  ####
%
% ==================================================================================================


\begin{figure}[t]
\paragraph{Language syntax}
\begin{equation*}
\begin{array}{rcl}
  v &  = & n \sep \lambda x.e \sep (v_1, \ldots, v_n) \\
  e &  = & x \sep n \sep \pi_i~e \sep (e_1, \ldots, e_n) \sep e_1~e_2 \sep \lambda x.e \\
  \tau &  = & \ident{num} \sep \tau_1 \times \ldots \times \tau_n \sep \tau_1 \rightarrow \tau_2 \\
  K  & = & (v_1, \ldots, v_{i-1}, \_, e_{i+1}, \ldots e_n) \sep v~\_ \sep \_~e \sep \pi_i~\_
\end{array}
\end{equation*}

~
\paragraph{Reduction rules}
\begin{equation*}
\begin{array}{rll}
  \footnotesize{(\emph{fn})}  & (\lambda x.e)~v \rightsquigarrow e[x\leftarrow v] \\[0.25em]
  \footnotesize{(\emph{prj})} & \pi_i (v_1, \ldots, v_n) \rightsquigarrow v_i\\[0.25em]
  \footnotesize{(\emph{ctx})}  & K[e] \rightsquigarrow K[e']  & (\textnormal{when}~e\rightsquigarrow e')\\[0.25em]
\end{array}
\end{equation*}

~
\paragraph{Typing rules}
\begin{equation*}
\begin{array}{l}
\tyrule{var}
  { x:\tau \in \Gamma }
  { \Gamma \vdash x:\tau }
\\[1.25em]
\tyrule{num}
  { ~ }
  { \Gamma \vdash n:\ident{num} }
\\[1.25em]
\tyrule{abs}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 }
  { \Gamma \vdash \lambda x.e : \tau_1 \rightarrow \tau_2 }
\\[1.25em]
\tyrule{app}
  { \Gamma \vdash e_1 : \tau_1 \rightarrow \tau_2  & \Gamma \vdash e_2 : \tau_1 }
  { \Gamma \vdash e_1~e_2 : \tau_2 }
\\[1.25em]
\tyrule{proj}
  { \Gamma \vdash e : \tau_1 \times \ldots \tau_i \times \ldots \times \tau_n }
  { \Gamma \vdash \pi_i~e:\tau_i }
\\[1.25em]
\tyrule{tup}
  { \forall i\in\{1 \ldots n\}.~ \Gamma \vdash e_i : \tau_i }
  { \Gamma \vdash (e_1, \ldots, e_n) : \tau_1 \times \ldots \times \tau_n }
\end{array}
\end{equation*}

\caption{Common syntax and reduction rules of the target language}
\label{fig:semantics-target}
\end{figure}

% --------------------------------------------------------------------------------------------------

\section{Translational semantics}
\label{sec:semantics-translation}

Although the notion of indexed comonads presented in the previous section is novel and interesting
in its own, the main reason for introducing it is that we can view it as a translation that provides
embedding of context-aware domain-specific languages in a simple target functional language.
In this section, we follow the example of effects and monads and we use the semantics to define a
translation akin to the do notation in Haskell.

A context-aware \emph{source} program written using a concrete context-aware domain-specific
language (capturing dataflow, implicit parameters or other kinds of context awareness) with
domain-specific language extensions (the \kvd{prev} keyword, or the \ident{?impl} syntax)
is translated to a \emph{target} language that is not context-aware. The target language is
a small functional language consisting of:
%
\begin{itemize}
  \item Simple functional subset formed by lambda calculus with support for tuples and numbers.
  \item Comonadically-inspired primitives corresponding to \emph{counit}, \emph{cobind} and
    other operations of flat indexed comonads.
  \item Additional primitives that model contextual operations of each concrete coeffect language
    (\emph{prev} for the \kvd{prev} keyword, \emph{lookup} for the \ident{?p} syntax and
    \emph{letimpl} for the $\kvd{let}~\ident{?p}=\ldots$ notation).
\end{itemize}
%
The syntax, typing and reduction rules of the first part (simple functional language) are common to
all concrete coeffect domain-specific languages. The syntax and typing rules of the second part
(comonadically-inspired) primitives are also shared by all coeffect DSLs, however the \emph{reduction
rules} for the comonadically-inspired primitives differ -- they capture the concrete notions of
context. Finally, the third part (domain-specific primitives) will differ for each coeffect
domain-specific language.

% --------------------------------------------------------------------------------------------------

\subsection{Functional target language}
\label{sec:semantics-translation-target}

The target language for the translation is a simply typed lambda calculus with integers and tuples.
We include integers as an example of a concrete type. Tuples are needed by the translation, which
keeps a tuple of variable assignments. Encoding those without tuples would be possible, but
cumbersome. In this section, we define the common parts of the language without the
comonadically-inspired primitives.

The syntax of the target programming language is shown in Figure~\ref{fig:semantics-target}.
The values include numbers $n$, tuples and function values. The expressions include variables $x$,
values, lambda abstraction and application and operations on tuples. We do not need recursion or
other data types (although a realistic programming language would include them).
In what follows, we also use the following syntactic sugar for let binding:
%
\begin{equation*}
\begin{array}{rcl}
  \kvd{let}~x=e_1~\kvd{in}~e_2 &=& (\lambda x.e_2)~e_1
\end{array}
\end{equation*}
%
Finally, $K[e]$ defines the syntactic evaluation context in which sub-expressions are evaluated.
Together with the evaluation rules shown in  Figure~\ref{fig:semantics-target}, this captures the
standard call-by-name semantics of the common parts of the target language. The (standard) typing rules
for the common expressions of the target language are also shown in Figure~\ref{fig:semantics-target}.

% --------------------------------------------------------------------------------------------------

\subsection{Safety of functional target language}

The functional subset of the language described so far models a simple ML-like language. We
choose call-by-value over call-by-name for no particular reason and Haskell-like language would
work equally well.

The subset of the language introduced so far is type-safe in the standard sense that
``well-typed programs do not get stuck''. Although standard, we outline the important parts
of the proof for the functional subset here, before we extend it to concrete context-aware
languages in Section~\ref{sec:semantics-proofs}.

We use the standard syntactic approach to type safety introduced by Milner \cite{syntactic-sml}.
Following Wright, Felleisen and Pierce \cite{syntactic-tapl,syntactic-approach}, we prove the
type preservation property (reduction does not change the type of an expression) and the progress
property (a well-typed expression is either a value or can be further reduced).

\begin{lemma}[Canonical forms]
\label{thm:semantics-fp-canon}
For all $e, \tau$, if $\vdash e : \tau$ and $e$ is a value then:
\begin{enumerate}
  \item If $\tau=\ident{num}$ then $e = n$ for some $n \in \mathbb{Z}$
  \item If $\tau=\tau_1 \rightarrow \tau_2$ then $e = \lambda x.e'$ for some $x, e'$
  \item If $\tau=\tau_1\times\ldots\times\tau_n$ then $e = (v_1, \ldots, v_n)$ for some $v_i$
\end{enumerate}
\end{lemma}
\begin{proof}
  For (1), the last typing rule must have been (\emph{num}); for (2), it must have been
  (\emph{abs}) and for (3), the last typing rule must have been (\emph{tup})
\end{proof}

\begin{lemma}[Preservation under substitution]
\label{thm:semantics-fp-pres-subst}
For all $\Gamma, e, e', \tau, \tau'$, if $\Gamma, x:\tau \vdash e : \tau'$ and $\Gamma \vdash e' : \tau$
then $\Gamma \vdash e[x \leftarrow e'] : \tau$.
\end{lemma}
\begin{proof}
By induction over the derivation of $\Gamma, x:\tau \vdash e : \tau'$.
\end{proof}

\begin{theorem}[Type preservation]
\label{thm:semantics-fp-pres}
  If $\Gamma \vdash e : \tau$ and $e \rightarrow e'$ then $\Gamma \vdash e' : \tau$
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{fn}): $e = (\lambda x.e_0)~v$, from Lemma~\ref{thm:semantics-fp-pres-subst}
  it follows that $\Gamma \vdash e_0[x \leftarrow v] : \tau$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{prj}): $e = \pi_i(v_1, \ldots, v_n)$ and so the last applied typing rule must have been
  (\emph{tup}) and $\Gamma \vdash (v_1, \ldots, v_n) : \tau_1 \times\ldots\times \tau_n$ and
  $\tau = \tau_i$. After applyng (\emph{prj}) reduction, $e' = v_i$ and so $\Gamma \vdash e' : \tau_i$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{ctx}): By induction hypothesis, the type of the reduced sub-expression does not change
  and the last used rule in the derivation of $\Gamma \vdash e : \tau$ also applies on $e'$
  giving $\Gamma \vdash e' : \tau$.
\end{proof}

\begin{theorem}[Progress]
\label{thm:semantics-fp-prog}
  If $\vdash e : \tau$ then either $e$ is a value or there exists $e'$ such that $e \rightsquigarrow e'$
\end{theorem}
\begin{proof}
  By rule induction over $\vdash$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{num}): $e = n$ for some $n$ and so $e$ is a value.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{abs}): $e = \lambda x.e'$ for some $x, e'$, which is a value.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{var}): This case cannot occur, because $e$ is a closed expression.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{app}): $e = e_1~e_2$ which is not a value. By induction, $e_1$ is either
a value or it can reduce. If it can reduce, apply (\emph{ctx}) reduction with context $\_~e$. Otherwise
consider $e_2$. If it can reduce, apply (\emph{ctx}) with context $v~\_$. If both are values,
Lemma~\ref{thm:semantics-fp-canon} guarantees that $e_1 = \lambda x.e_1'$ and so we can apply
reduction (\emph{fn}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{proj}): $e = \pi_i e_0$ and $\tau=\tau_1\times\ldots\tau_n$. If $e_0$ can be reduced,
  apply (\emph{ctx}) with context $\pi_i~\_$. Otherwise from Lemma~\ref{thm:semantics-fp-canon},
  we have that $e_0=(v_1, \ldots, v_n)$ and we can apply reduction (\emph{prj}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{tup}): $e = (e_1, \ldots, e_n)$. If all sub-expressions are values, then $e$ is also
  a value. Otherwise, we can apply reduction using (\emph{ctx}) with a context $(v_1, \ldots, v_{i-1}, \_, e_{i+1}, \ldots, e_n)$.
\end{proof}

\begin{theorem}[Safety of functional target language]
  If $\Gamma \vdash e : \tau$ and $e \rightsquigarrow^* e'$ then either $e'$ is a value of type $\tau$ or
  there exists $e''$ such that $e' \rightsquigarrow e''$ and $\Gamma \vdash e'' : \tau$.
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow^*$ using Theorem~\ref{thm:semantics-fp-pres} and Theorem~\ref{thm:semantics-fp-prog}.
\end{proof}

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\paragraph{Language syntax}
Given $(\C, \cseq, \cpar, \czip, \cunit, \czero, \cleq)$, extend the programming language
syntax with the following constructs:

\begin{equation*}
\begin{array}{rcl}
  e &  =  &\ldots \sep\ident{cobind}_{\cclrd{s},\cclrd{r}}~e_1~e_2 \sep \ident{counit}_{\cunit}~e \sep \ident{merge}_{\cclrd{r},\cclrd{s}}~e
         \sep \ident{split}_{\cclrd{r},\cclrd{s}}~e \sep \ident{lift}_{\cclrd{r},\cclrd{r'}}~e \\
  \tau &  = &\ldots \sep \ctyp{\cclrd{r}}{\tau} \\
  K  & = &\ldots \sep \ident{cobind}_{\cclrd{s},\cclrd{r}}~\_~e \sep \ident{cobind}_{\cclrd{s},\cclrd{r}}~v~\_ \sep \ident{counit}_{\cunit}~\_ \\
    && \hspace{1.4em} \sep \ident{merge}_{\cclrd{r},\cclrd{s}}~\_
           \sep \ident{split}_{\cclrd{r},\cclrd{s}}~\_ \sep \ident{lift}_{\cclrd{r},\cclrd{r'}}~\_ \\
\end{array}
\end{equation*}

~

~

\paragraph{Typing rules}
Given $(\C, \cseq, \cpar, \czip, \cunit, \czero, \cleq)$, add the typing rules:

\begin{equation*}
\begin{array}{l}
\tyrule{counit}
  {\Gamma \vdash e : \ctyp{\cunit}{\tau}}
  {\Gamma \vdash \ident{counit}_{\cunit}~e : \tau} \\
\\
\tyrule{cobind}
  {\Gamma \vdash e_1 : \ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2 & \Gamma \vdash e_2 : \ctyp{\cclrd{r}\cseq\cclrd{s}}{\tau_1} }
  {\Gamma \vdash \ident{cobind}_{\cclrd{r}, \cclrd{s}}~e_1~e_2 : \ctyp{\cclrd{s}}{\tau_2}} \\
  \\
\tyrule{merge}
  {\Gamma \vdash  e : \ctyp{\cclrd{r}}{\tau_1} \times \ctyp{\cclrd{s}}{\tau_2} }
  {\Gamma \vdash  \ident{merge}_{\cclrd{r},\cclrd{s}}~e : \ctyp{\cclrd{r}\czip\cclrd{s}}{(\tau_1 \times \tau_2)} }\\
    \\
\tyrule{split}
  {\Gamma \vdash  e : \ctyp{\cclrd{r}\cpar\cclrd{s}}{(\tau_1 \times \tau_2)} }
  {\Gamma \vdash  \ident{split}_{\cclrd{r},\cclrd{s}}~e : \ctyp{\cclrd{r}}{\tau_1} \times \ctyp{\cclrd{s}}{\tau_2}} \\
\end{array}
\end{equation*}

\caption{Comonadically-inspired extensions for the target language}
\label{fig:semantics-ext}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Comonadically-inspired translation}
\label{sec:semantics-translation-transl}

In Section~\ref{sec:semantics-theory}, we presented the semantics of the flat coeffect calculus in
terms of indexed comonads. We treated the semantics as denotational -- interpreting the meaning of
a given typing derivation of a program in terms of category theory.

In this chapter, we use the same structure in a different way. Rather than treating the rules as
\emph{denotation} in categorical sense, we treat them as \emph{translation} from a source
domain-specific coeffect language into a target language with comonadically-inspired primitives
described in the previous section.

\paragraph{Language extension.}
Given a coeffect language with a flat coeffect algebra $(\C, \cseq, \cpar, \czip, \cunit, \czero, \cleq)$,
we first extend the language syntax and typing rules with terms that correspond to the
comonadically-inspired operations. This is done in the same way for all concrete coeffect
domain-specific languages and so we give the common additional syntax, evaluation context and
typing rules once in Figure~\ref{fig:semantics-ext}. We consider examples later in
Section~\ref{sec:semantics-proofs}.

The new type $\ctyp{\cclrd{r}}$ represents an indexed comonad, which is left abstract for now.
The additional expressions such as $\ident{counit}_\cunit$ and $\ident{cobind}_{\cclrd{r,s}}$
correspond to the operations of indexed comonads. Note that the we embed the coeffect annotations
into the target language -- these are known when translating a term with a chosen typing derivation
from a source language and they will be useful when proving that sufficient context (as specified
by the coeffect annotations) is available.

Figure~\ref{fig:semantics-ext} defines the syntax and the typing rules, but it does not define the
reduction rules. These -- together with the values for a concrete notion of context -- will be
defined separately for each individual coeffect language.

\paragraph{Contexts and types.}
The interpretation of contexts and types in the category now becomes a translation from types and
contexts in the source language into the types of the target language:
%
\begin{equation*}
\begin{array}{rcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{\cclrd{r}}} &=& \ctyp{\cclrd{r}}{(\sem{\tau_1} \times \ldots \times \sem{\tau_n})} \\[0.5em]
\sem{\tau_1 \xrightarrow{\cclrd{r}} \tau_2} & = & \ctyp{\cclrd{r}}{\sem{\tau_1}} \rightarrow \sem{\tau_2} \\[-0.2em]
\sem{\ident{num}} & = & \ident{num} \\
\end{array}
\end{equation*}

\noindent
Here, a context becomes a comonadically-inspired data type wrapping a tuple of variable values
and a coeffectful function is translated into an ordinary function in the target language
with a comonadically-inspired data type wrapping the input type.

% --------------------------------------------------------------------------------------------------

\begin{figure*}[t]

The translation is defined over a typing derivation:
%
\begin{equation*}
\hspace{-3em}
\begin{array}{ll}
\hspace{4.8em}\semdef
  {\coctx{\Gamma}{\cunit} \vdash x_i : \tau_i }
  {\lambda\ctx.\pi_i~(\ident{counit}_{\cunit}~\ctx)}
& (\emph{var})
\\[1em]
\hspace{4.3em}\semdef
  {\coctx{\Gamma}{\czero} \vdash n : \ident{num} }
  {\lambda\ctx.n}
& (\emph{num})
\\[1.5em]
\hspace{1.5em}\emdeff
  {\coctx{\Gamma, x_i:\tau_1}{\cclrd{r}\;\czip\;\cclrd{s}} \vdash e : \tau_2}
  {\hspace{-1em}\begin{array}{l}
    \sem{\coctx{\Gamma}{\cclrd{r}} \vdash \lambda x_i.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2}
    \\[-0.3em]~\\[-0.3em]~ \\[-0.3em]~
  \end{array} }
  {f}
  {\hspace{-1em}\begin{array}{l}
    \lambda \ctx.\lambda v.\\[-0.3em]
    \quad \kvd{let}~\ident{reassoc} = \lambda x.\\[-0.3em]
    \quad\quad (\pi_1(\pi_1~x), \ldots, \pi_{i-1}(\pi_1~x), \pi_2~x)\\[-0.3em]
    \quad f~(\ident{map}_{\cclrd{r}\czip\cclrd{s}}~\ident{reassoc}~(\ident{merge}_{\cclrd{r}, \cclrd{s}}~(\ctx, v)))
   \end{array} }
& (\emph{abs})
\\[4em]
\emdefff
  {\coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2}
  {\coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_1 }
  {\begin{array}{r}\sem{\coctx{\Gamma}{\cclrd{r} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{t})} \vdash e_1~e_2 : \tau_2}\\[-0.3em]~\\[-0.3em]~\\[-0.3em]~\end{array}}
  {f}
  {g}
  {\hspace{-1em}\begin{array}{l}
  \lambda\ctx.~~\\[-0.3em]
    \quad \kvd{let}~\ctx_0 = \ident{map}_{\cclrd{r} \;\cpar\; (\cclrd{s} \,\cseq\, \cclrd{t})}~\ident{dup}~\ctx\\[-0.3em]
    \quad \kvd{let}~(\ctx_1, \ctx_2) = \ident{split}_{\cclrd{r}, \cclrd{s} \,\cseq\, \cclrd{t}}~\ctx_0\\[-0.3em]
    \quad f~\ctx_1~
      (\ident{cobind}_{\cclrd{s}, \cclrd{t}}~g~\ctx_2)
  \end{array} }
& (\emph{app})
\end{array}
\end{equation*}

~

~

Assuming the following auxiliary operations:
%
\begin{equation*}
\begin{array}{rcl}
  \ident{map}_\cclrd{r}}~f &=& \ident{cobind}_{\cunit, \cclrd{r}}~(\lambda x.f~({\ident{counit}_\cunit}~x)) \\[-0.3em]
  \ident{dup} &=& \lambda x. (x, x)
\end{array}
\end{equation*}


\figcaption{Translation from a flat DSL to a comonadically-inspired target language}
\label{fig:semantics-translation}
\end{figure*}

% --------------------------------------------------------------------------------------------------

\paragraph{Expressions.}
The rules shown in Figure~\ref{fig:semantics-translation} define how expressions of the source
language are translated into the target language. The rules are very similar to those shown earlier
in Figure~\ref{fig:semantics-flat}. The consequent is now written as source code in the
target programming language rather than as composition of morphisms in a category. However,
thanks to the relationship between $\lambda$-calculus and cartesian closed categories, both
interpretations are equivalent.

One change from Figure~\ref{fig:semantics-flat} is that we are now more explicit about the tuple
that contains variable assignments. Previously, we assumed that the tuple is appropriately
reassociated. For programming language translation and the implementation (discussed in
Chapter~\ref{ch:impl}), we perform the reassociation explicitly. We keep a flat tuple of variables, so
given $\Gamma=x_1\!:\!\tau_1,\ldots,x_n\!:\!\tau_n$, the tuple has a type $\tau_1\times\ldots\times\tau_n$.
In (\emph{var}), we access a variable using $\pi$, but in (\emph{abs}), the \ident{merge} operation
produces a tuple $(\tau_1\times\ldots\times\tau_{i-1})\times\tau_i$ that we turn into a flat
tuple $\tau_1\times\ldots\times\tau_{i-1}\times\tau_i$ using the \ident{assoc} function.

\paragraph{Properties.}
The most important property of the translation is that it produces well-typed programs in the
target language. This is akin to the correspondence property of the semantics discussed earlier
(Theorem~\ref{thm:flat-correspondence}), but now it has more obvious practical consequences.

In Section~\ref{sec:semantics-proofs}, we will prove safety properties of well-typed programs in
the target language. Thanks to the fact that the translation produces a well-typed program
means that we are also proving safety of well-typed programs in the source context-aware languages.

\begin{theorem}[Well-typedness of the translation]
\label{thm:semantics-welltyped}
Given a typing derivation for a well-typed closed expression $\coctx{}{\cclrd{r}} \vdash e : \tau$
written in a context-aware programming langugae that is translated to the target language as
(we write $\ldots$ for the omitted part of the translation tree):
%
\begin{equation*}
  \semdeff
    {~~(\ldots)~~}
    {\coctx{}{\cclrd{r}} \vdash e : \tau }
    {(\ldots)}
    { ~~f }
\end{equation*}
%
Then $f$ is well-typed, \ie~in the target language: $\vdash f : \sem{\coctx{\Gamma}{\cclrd{r}}} \rightarrow \sem{\tau}$.
\end{theorem}
\begin{proof}
By rule induction over the derivation of the translation. Given a judgement
$\coctx{x_1\!:\!\tau_1 \ldots x_n\!:\!\tau_n}{\cclrd{c}} \vdash e : \tau$, the translation
constructs a function of type $\ctyp{\cclrd{c}}(\sem{\tau_1} \times\ldots\times \sem{\tau_n}) \rightarrow \sem{\tau}$.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{var}): $\cclrd{c}=\cunit$ and $\tau = \tau_i$ and so $\pi_i ({\ident{counit}_\cunit}~\ctx)$ is well-typed.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{num}): $\tau = \ident{num}$ and so the body $n$ is well-typed.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{abs}): The type of $\ctx$ is $\ctyp{\cclrd{r}}(\ldots)$ and the type of $v$ is $\ctyp{\cclrd{s}}\tau_1$,
  calling $\ident{merge}_{\cclrd{r},\cclrd{s}}$ and reassociating produces
  $\ctyp{\cclrd{r}\czip\cclrd{s}}(\ldots)$ as expected by $f$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{app}): After applying $\ident{split}_{\cclrd{r}, \cclrd{s}\cseq\cclrd{t}}$, the types of
  $\ctx_1, \ctx_2$ are $\ctyp{\cclrd{r}}(\ldots)$ and $\ctyp{\cclrd{s}\cseq\cclrd{t}}(\ldots)$, respectively.
  $g$ requires $\ctyp{\cclrd{s}}(\ldots)$ and so the result of $\ident{cobind}_{\cclrd{s},\cclrd{t}}$ is
  $\ctyp{\cclrd{t}}\tau_1$ as required by $f$.
\end{proof}



% ==================================================================================================
%
%       #####
%      #     #   ##   ###### ###### ##### #   #
%      #        #  #  #      #        #    # #
%       #####  #    # #####  #####    #     #
%            # ###### #      #        #     #
%      #     # #    # #      #        #     #
%       #####  #    # #      ######   #     #
%
% ==================================================================================================

\section{Safety of context-aware languages}
\label{sec:semantics-proofs}

The language defined in Figure~\ref{fig:semantics-target} and Figure~\ref{fig:semantics-ext}
provide a general structure that we now use to prove the safety of various context-aware
programming languages based on the coeffect language framework. As examples, we consider a language
for dataflow computations (Section~\ref{sec:semantics-proofs-df}) and for implicit parameters
(Section~\ref{sec:semantics-proofs-impl}). In both cases, we extend the progress and preservation
theorems of the functional subset of the target language, but the approach can be generalized as
discussed in Section~\ref{sec:semantics-generalising}.

As outlined in the table at the beginning of Part~\ref{part:coeffect-calculi}, we now covered the
parts of the semantics that are shared by all context-aware languages. This includes the functional
target language with comonadically-inspired uninterpreted type $\ctyp{\cclrd{r}}{\tau}$ and the
syntax for comonadically-inspired uninterpreted primitives such as
$\ident{cobind}_{\cclrd{s},\cclrd{r}}$ and $\ident{counit}_{\cunit}$, together with their typing.

Using dataflow and implicit parameters as two examples, we now add the domain-specific extensions
needed for a concrete context-aware programming language. This includes syntax for values and
expressions of the comonad-inspired type $\ctyp{\cclrd{r}}{\tau}$ and reduction rules for the
comonadically-inspired operations ($\ident{cobind}_{\cclrd{s},\cclrd{r}}$, $\ident{counit}_{\cunit}$, etc.).

% --------------------------------------------------------------------------------------------------

\subsection{Coeffect language for dataflow}
\label{sec:semantics-proofs-df}

The types of the comonadically-inspired operations are the same for each concrete coeffect DSL, but
each DSL introduces its own \emph{values} of type $\ctyp{\cclrd{r}}\tau$ and also its own reduction
rules that define how comonadically-inspired operations evaluate.

We first consider dataflow computations. As discussed earlier in the
semantics of dataflow, the indexed comonad for a context with $n$ past values carries $n+1$
values. When reducing translated programs, the comonadic values will not be directly manipulated by the
user code. In a programming language, it could be seen as an \emph{abstract data type} whose only
operations are the comonadically-inspired ones defined earlier, together with an additional
\emph{domain-specific} operation that models the \kvd{prev} construct.

The Figure~\ref{fig:semantics-ext-df} extensionds the target language with syntax, typing rules,
additional translation rule and reductions for modelling dataflow computations. We introduce a
new kind of values written as $\ident{Df}\langle v_0, \ldots, v_n\rangle$
and a matching kind of expressions. We specify how the \kvd{prev} keyword is translated into a
$\ident{prev}_\cclrd{r}$ operation of the target language nd we also add a typing rule
(\emph{df}) that checks the types of the elements of the stream and also guarantees
that the number of elements in the stream matches the number in the coeffect.
The additional reduction rules mirror the semantics that we discussed in
Example~\ref{thm:semantics-indexed-list} when discussing the indexed list comonad.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\paragraph{Language syntax}

\begin{equation*}
\begin{array}{rcl}
v &=& \ldots \sep \ident{Df}\langle v_0, \ldots, v_n\rangle \\
e &=& \ldots \sep \ident{Df}\langle e_0, \ldots, e_n\rangle \sep \ident{prev}_{\cclrd{n}}~e\\
K &=& \ldots \sep \ident{prev}_{\cclrd{n}}~\_ \sep \ident{Df}\langle v_0, \ldots, v_{i-1}, \_, e_{i+1} \ldots, e_n\rangle
\end{array}
\end{equation*}

\vspace{1.25em}
\paragraph{Typing rules}

\begin{equation*}
\tyrule{df}
  { \forall i\in\{ 0 \ldots n \}. ~ \Gamma \vdash e_i : \tau}
  { \Gamma \vdash \ident{Df}\langle e_0, \ldots, e_n \rangle : \ctyp{\cclrd{n}}{\tau} }
\end{equation*}
\begin{equation*}
\tyrule{prev}
  { \Gamma \vdash e : \ctyp{\cclrd{n+1}}{\tau} }
  { \Gamma \vdash \ident{prev}_{\cclrd{n}}~e : \ctyp{\cclrd{n}}{\tau} }
\end{equation*}

\vspace{1.25em}
\paragraph{Translation}

\begin{equation*}
\semdeff
  { \coctx{\Gamma}{\cclrd{n}} \vdash e : \tau }
  { \coctx{\Gamma}{\cclrd{n+1}} \vdash \kvd{prev}~e : \tau }
  {f}
  {\lambda ctx.\ident{prev}_{\cclrd{n}}~\ctx }
\end{equation*}

\vspace{1.25em}
\paragraph{Reduction rules}

\begin{equation*}
\begin{array}{rl}
{\footnotesize(\emph{counit})} & \begin{array}{l}
\ident{counit}_{\cclrd{0}}(\ident{Df} \langle v_0 \rangle)   \rightsquigarrow v_0
\end{array}
\\[0.5em]
{\footnotesize(\emph{cobind})} & \begin{array}{l}
\ident{cobind}_{\cclrd{m}, \cclrd{n}}~f~(\ident{Df}\langle v_0, \ldots v_{m+n} \rangle) \rightsquigarrow
\\[-0.25em]
\quad (\ident{Df}\langle f (\ident{Df}\langle v_0, \ldots, v_m \rangle), \ldots, f (\ident{Df}\langle v_{n}, \ldots, v_{m+n} \rangle) \rangle)
\end{array}
\\[0.5em]
{\footnotesize(\emph{merge})} & \begin{array}{l}
\ident{merge}_{\cclrd{m}, \cclrd{n}} ((\ident{Df}\langle v_0, \ldots, v_m \rangle), (\ident{Df}\langle v'_0, \ldots, v'_n\rangle)) \rightsquigarrow
\\[-0.25em]
\quad (\ident{Df}\langle (v_0, b_0), \ldots, (v_{\mathit{min}(m,n)}, v'_{\mathit{min}(m,n)}) \rangle)
\end{array}
\\[0.5em]
{\footnotesize(\emph{split})} & \begin{array}{l}
\ident{split}_{\cclrd{m}, \cclrd{n}} (\ident{Df}\langle (v_0, b_0), \ldots, (v_{\mathit{max}(m,n)}, b_{\mathit{max}(m,n)}) \rangle)  \rightsquigarrow
\\[-0.25em]
\quad \ident{Df}\langle v_0, \ldots, v_m \rangle, (\ident{Df}\langle b_0, \ldots, b_n\rangle
\end{array}
\\[0.5em]
{\footnotesize(\emph{prev})} & \begin{array}{l}
\ident{prev}_{\cclrd{n}} (\ident{Df}\langle v_0, \ldots, v_n, v_{n+1} \rangle) \rightsquigarrow
\\[-0.25em]
\quad \ident{Df}\langle v_0, \ldots, v_n \rangle
\end{array}
\end{array}
\end{equation*}

\caption{Additional constructs for modelling dataflow in the target language}
\label{fig:semantics-ext-df}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Properties.}
Now consider a target language consisting of the core (ML-subset) defined by the syntax,
reduction rules and typing rules given in Figure~\ref{fig:semantics-target} and comonadically-inspired
primtives defined in Figure~\ref{fig:semantics-ext} and also concrete notion of comonadically-inspired
value and reduction rules for dataflow as defined in Figure~\ref{fig:semantics-ext-df}.

In order to prove type safety, we first extend the \emph{canonical forms lemma}
(Lemma~\ref{thm:semantics-fp-canon}) and the \emph{preservation under substitution lemma}
(Lemma~\ref{thm:semantics-fp-pres-subst}). Those need to consider the new (\emph{df})
and (\emph{prev}) typing rules and substitution under the newly introduced expression forms
$\ident{Df}\langle\ldots\rangle$ and $\ident{prev}_{\cclrd{n}}$. We show that the translation
rule for \kvd{prev} produces well-typed expressions. Finally, we extend the type preservation
(Theorem~\ref{thm:semantics-fp-pres}) and progress (Theorem~\ref{thm:semantics-fp-prog}) theorems.

\begin{theorem}[Well-typedness of the \kvd{prev} translation]
\label{thm:semantics-df-welltyped}
Given a typing derivation for a well-typed closed expression $\coctx{}{\cclrd{r}} \vdash e : \tau$,
the translated program $f$ obtained using the rules in Figure~\ref{fig:semantics-translation}
and Figure~\ref{fig:semantics-ext-df} is well-typed, \ie~in the target language: $\vdash f : \sem{\coctx{\Gamma}{\cclrd{r}}} \rightarrow \sem{\tau}$.
\end{theorem}
\begin{proof}
By rule induction over the derivation of the translation.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{var, num, abs, app}): As before.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{prev}): Type of $\ctx$ is $\ctyp{\cclrd{n+1}}\tau$ and so we can apply the (\emph{prev}) rule.
\end{proof}

\begin{lemma}[Canonical forms]
\label{thm:semantics-df-canon}
For all $e, \tau$, if $\vdash e : \tau$ and $e$ is a value then:
\begin{enumerate}
  \item If $\tau=\ident{num}$ then $e = n$ for some $n \in \mathbb{Z}$
  \item If $\tau=\tau_1 \rightarrow \tau_2$ then $e = \lambda x.e'$ for some $x, e'$
  \item If $\tau=\tau_1\times\ldots\times\tau_n$ then $e = (v_1, \ldots, v_n)$ for some $v_i$
  \item If $\tau=\ctyp{\cclrd{n}}\tau_1$ then $e = \ident{Df}\langle v_0, \ldots v_n\rangle$ for some $v_i$
\end{enumerate}
\end{lemma}
\begin{proof}
  (1,2,3) as before; for (4) the last typing rule must have been (\emph{df}).
\end{proof}

\begin{lemma}[Preservation under substitution]
\label{thm:semantics-df-pres-subst}
For all $\Gamma, e, e', \tau, \tau'$, if $\Gamma, x:\tau \vdash e : \tau'$ and $\Gamma \vdash e' : \tau$
then $\Gamma \vdash e[x \leftarrow e'] : \tau$.
\end{lemma}
\begin{proof}
  By induction over the derivation of $\Gamma, x:\tau \vdash e : \tau'$ as before, with new
  cases for $\ident{Df}\langle\ldots\rangle$ and $\ident{prev}_{\cclrd{n}}$.
\end{proof}

\begin{theorem}[Type preservation]
\label{thm:semantics-df-pres}
  If $\Gamma \vdash e : \tau$ and $e \rightsquigarrow e'$ then $\Gamma \vdash e' : \tau$
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{fn}, \emph{prj}, \emph{ctx}): As before, using Lemma~\ref{thm:semantics-df-pres-subst} for (\emph{fn}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{counit}): $e = \ident{counit}_{\cclrd{0}}(\ident{Df} \langle v_0 \rangle)$. The last rule in the type
  derivation of $e$ must have been (\emph{counit}) with $\Gamma \vdash \ident{Df} \langle v_0 \rangle : \ctyp{\cclrd{0}}\tau$
  and therefore $\Gamma \vdash v_0 : \tau$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{cobind}): $e = \ident{cobind}_{\cclrd{m}, \cclrd{n}}~f~(\ident{Df}\langle v_0, \ldots v_{m+n} \rangle)$. The
  last rule in the type derivation of $e$ must have been (\emph{cobind}) with a type $\tau = \ctyp{\cclrd{n}}\tau_2$ and assumptions
  $\Gamma \vdash f : \ctyp{\cclrd{m}}{\tau_1} \rightarrow \tau_2$ and $\Gamma \vdash \ident{Df}\langle v_0, \ldots v_{m+n} \rangle : \ctyp{\cclrd{m+n}}{\tau}$.
  The reduced expression has a type $\ctyp{\cclrd{n}}\tau_2$:
\begin{equation*}
\inference
  { \inference
      { \Gamma \vdash f : \ctyp{\cclrd{m}}{\tau_1} \rightarrow \tau_2 & \forall i\in 0 \ldots n.~\Gamma\vdash \ident{Df}\langle v_i, \ldots, v_{i+m} \rangle :  \ctyp{\cclrd{m}}{\tau_1}}
      { \forall i\in 0 \ldots n.~\Gamma\vdash f (\ident{Df}\langle v_i, \ldots, v_{i+m} \rangle) : \tau_2} }
  { \Gamma \vdash \ident{Df}\langle f (\ident{Df}\langle v_0, \ldots, v_m \rangle), \ldots, f (\ident{Df}\langle v_{n}, \ldots, v_{m+n} \rangle) \rangle : \ctyp{\cclrd{n}}\tau_2 }
\end{equation*}

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{merge}, \emph{split}, \emph{next}): Similar. In all three cases, the last typing rule in the derivation of $e$
  guarantees that the stream contains a sufficient number of elements of correct type.
\end{proof}

\begin{theorem}[Progress]
\label{thm:semantics-df-prog}
  If $\vdash e : \tau$ then either $e$ is a value or there exists $e'$ such that $e \rightsquigarrow e'$
\end{theorem}
\begin{proof}
  By rule induction over $\vdash$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{num,abs,var,app,proj,tup}): As before, using the adapted canonical forms lemma
  (Lemma~\ref{thm:semantics-df-canon}) for (\emph{app}) and (\emph{proj}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{counit}): $e = {\ident{counit}_\cunit}~e_1$. If $e_1$ is not a value, it can be reduced
  using (\emph{ctx}) with context ${\ident{counit}_\cunit}~\_$, otherwise it is a value. From Lemma~\ref{thm:semantics-df-canon},
  $e_1 = \ident{Df}\langle v\rangle$ and so we can apply (\emph{counit}) reduction rule.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{cobind}): $e = \ident{cobind}_{\cclrd{m}, \cclrd{n}}~e_1~e_2$. If $e_1$ is not a value,
  reduce using (\emph{ctx}) with context ${\ident{cobind}_{\cclrd{m},\cclrd{n}}}~\_~e$. If $e_2$ is
  not a value reduce using (\emph{ctx}) with context ${\ident{cobind}_{\cclrd{m},\cclrd{n}}}~v~\_$.
  If both are values, then from Lemma~\ref{thm:semantics-df-canon}, we have that
  $e_2 = \ident{Df}\langle v_0, \ldots v_{m+n} \rangle$ and so we can apply the (\emph{cobind})
  reduction.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{merge}): $e = \ident{merge}_{\cclrd{m}, \cclrd{n}} e_1$. If $e_1$ is not a value,
  reduce using (\emph{ctx}) with context $e = \ident{merge}_{\cclrd{m}, \cclrd{n}}~\_$. If $e_1$ is
  a value, it must be a pair of streams $(\ident{Df}\langle v_0, \ldots, v_m \rangle, \ident{Df}\langle v'_0, \ldots, v'_n\rangle)$
  using Lemma~\ref{thm:semantics-df-canon} and it can reduce using (\emph{merge}) reduction.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{df}): $e = \ident{Df}\langle e_0, \ldots, e_n\rangle$. If $e_i$ is not a value
  then reduce using (\emph{ctx}) with context $\ident{Df}\langle v_0, \ldots, v_{i-1}, \_, e_{i+1} \ldots, e_n\rangle$.
  Otherwise, $e_0, \ldots, e_n$ are values and so $\ident{Df}\langle e_0, \ldots, e_n\rangle$
  is also a value.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{split}, \emph{prev}): Similar. Either sub-expression is not a value, or the type
  guarantees that it is a stream with correct number of elements to enable the (\emph{split})
  or (\emph{prev}) reduction, respectively.
\end{proof}

\begin{theorem}[Safety of context-aware dataflow language]
  If $\Gamma \vdash e : \tau$ and $e \rightsquigarrow^{*} e'$ then either $e'$ is a value of type $\tau$ or
  there exists $e''$ such that $e' \rightsquigarrow e''$ and $\Gamma \vdash e'' : \tau$.
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow^*$ using Theorem~\ref{thm:semantics-df-pres} and Theorem~\ref{thm:semantics-df-prog}.
\end{proof}


% --------------------------------------------------------------------------------------------------

\subsection{Coeffect language for implicit parameters}
\label{sec:semantics-proofs-impl}

We now turn to our second example. As discussed earlier (Example~\ref{thm:semantics-indexed-prod}),
implicit parameters can be modelled by an indexed product comonad, which annotates a value with
additional context -- in our case, a mapping from implicit parameter names to their values. In this
section, we embed this model into the target language.

As with dataflow computations, we take the core functional subset (Figure~\ref{fig:semantics-target})
with comonadically-inspired extensions (Figure~\ref{fig:semantics-ext}) and we specify a new kind
of values of type $\ctyp{\cclrd{r}}\tau$ and domain-specific reduction rules that specify how
the operations propagate and access the context containing implicit parameter bindings.
Again, the $\ctyp{\cclrd{r}}\tau$ values can be seen as an \emph{abstract data type}, which are
never manipulated directly, except by the comonadically-inspired operations
($\ident{cobind}_{\cclrd{s},\cclrd{r}}$, $\ident{counit}_{\cunit}$, etc.).

\paragraph{Domain-specific extensions.}

The Figure~\ref{fig:semantics-ext-impl} shows extensions to the target language for modelling
implicit parameters. A comonadic value with a coeffect $\cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n \} }}$
is modelled by a new kind of value written as
$\ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots \ident{?p}_n \mapsto v_n \})$ which contains
a value $v$ together with implicit parameter assignments for all the parameters specified in the
coeffect. We add a corresponding kind of expression with its typing rule (\emph{impl}).

There are also two domain-specific operations for working with implicit parameters. The
$\ident{lookup}_{\cclrd{\ident{?p}}}$ operation reads a value of an implicit parameter and
the $\ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}$ operation adds a mapping assigning a value
to an implicit parameter \ident{?p}. The typing rule (\emph{lookup}) specifies that the accessed
parameter need to be a part of the context and the rule (\emph{letimpl}) specifies that the
\ident{letimpl} operation extends the context with a new implicit parameter binding.

The new translation rules specify how implicit parameter access, written as \ident{?p}, and
implicit parameter binding, written as $\kvd{let}~\ident{?p}~=e_1~\kvd{in}~e_2$ are translated to the
target language. The first one is straightforward. The binding is similar to the translation for
function application -- we split the context, evaluate $e_1$ using the first part of the context
$\ctx_1$ and then add the new binding to the remaining context $\ctx_2$.

Finally, Figure~\ref{fig:semantics-ext-impl} also defines the reduction rules. The (\emph{lookup})
rule accesses an implicit parameter and (\emph{letimpl}) adds a new binding. The reduction rules
closely model the product comonad discussed in Example~\ref{thm:semantics-indexed-prod}. Reductions
for (\emph{cobind}) and (\emph{split}) restrict the set of available implicit parameters according
to the annotations and (\emph{merge}) combines them, preferring the values from the call-site.

For the semantics of implicit parameter programs that we consider, the preference of call-site
bindings over declaration-site bindings in (\emph{merge}) does not matter. The unique typing
derivations for implicit parameter coeffects obtained in Section~\ref{sec:flat-unique} always
split implicit parameters into \emph{disjoint sets}, so preferences do not come into play.

% --------------------------------------------------------------------------------------------------

\begin{figure}[h!]
\paragraph{Language syntax}

\begin{equation*}
\begin{array}{rcl}
v &=& \ldots \sep \ident{Impl}(v, \{ \ident{?p}_1\mapsto v_1, \ldots, \ident{?p}_n\mapsto v_n\}) \\
e &=& \ldots \sep \ident{Impl}(e, \{\ident{?p}_1\mapsto e_1, \ldots, \ident{?p}_n\mapsto e_n\}) \\
  && \hspace{1.4em} \sep \ident{lookup}_{\cclrd{\ident{?p}}}~e \sep \ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}~e_1~e_2\\
K &=& \ldots \sep \ident{lookup}_{\cclrd{\ident{?p}}}~\_ \sep \ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}~\_~e \sep \ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}~v~\_ \\
  && \hspace{1.4em} \sep \ident{Impl}(\_, \{ \ident{?p}_1\mapsto e_1, .., \ident{?p}_n\mapsto e_n\})\\
  && \hspace{1.4em} \sep \ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, .., \ident{?p}_{i-1} \mapsto v_{i-1}, \ident{?p}_i \mapsto \_, \ident{?p}_{i+1} \mapsto v_{i+1}, .. \ident{?p}_n \mapsto e_n\})
\end{array}
\end{equation*}

\vspace{1em}
\paragraph{Typing rules}

\begin{equation*}
  \hspace{-2em}
\tyrule{impl}
  { \Gamma \vdash e:\tau & \forall i\in\{ 1 \ldots n \}. ~ \Gamma \vdash e_i : \ident{num}}
  { \Gamma \vdash \ident{Impl}(e, \{ \ident{?p}_1\mapsto e_1, \ldots, \ident{?p}_n\mapsto e_n \}) : \ctyp{\cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n \}}}{\tau} }
\end{equation*}
\begin{equation*}
  \hspace{-2em}
\tyrule{lookup}
  { \Gamma \vdash e : \ctyp{\cclrd{ \{\ident{?p}\} }}{\tau} }
  { \Gamma \vdash \ident{lookup}_{\cclrd{\ident{?p}}}~e : \ident{num} }
\end{equation*}
\begin{equation*}
  \hspace{-2em}
\tyrule{letimpl}
  { \Gamma \vdash e_1 : \ident{num} &
    \Gamma \vdash e_2 : \ctyp{\cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n \} }}{\tau} }
  { \Gamma \vdash \ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n \} }}~e_1~e_2 :
      \ctyp{\cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n, \ident{?p} \} }}{\tau} }
\end{equation*}

\vspace{1em}
\paragraph{Translation}

\begin{equation*}
\begin{array}{rl}
(\footnotesize{\emph{lookup}}) &
\semdef
  { \coctx{\Gamma}{\cclrd{ \{\ident{?p}\} }} \vdash \ident{?p} : \ident{num} }
  {\lambda ctx.\ident{lookup}_{\cclrd{\ident{?p}}}~\ctx }
\\[2em]
\begin{array}{l}(\footnotesize{\emph{letimpl}})\\[1.25em]~\end{array}&
\semdefff
  { \coctx{\Gamma}{\cclrd{r}} \vdash e_1 : \tau_1}
  { \coctx{\Gamma}{\cclrd{s}} \vdash e_2 : \tau_2}
  {\hspace{-1em}\begin{array}{l}
      \coctx{\Gamma}{\cclrd{r} \;\cclrd{\cup\; (\cclrd{s} \setminus \{ \ident{?p}) \}} }\\[-0.3em]
        \quad \vdash \kvd{let}~\ident{?p}=e_1\\[-0.3em]
        \quad\qquad \kvd{in}~e_2 : \tau_2 \\[-0.3em]
        ~ \\[-0.3em]
   \end{array}}
  {f}
  {g}
  {\hspace{-1em}\begin{array}{l}
  \lambda\ctx.~~\\[-0.3em]
    \quad \kvd{let}~\ctx_0 = \ident{map}_{\cclrd{r} \;\cclrd{\cup}\; \cclrd{(s\setminus\{\ident{?p}\})}}~\ident{dup}~\ctx\\[-0.3em]
    \quad \kvd{let}~(\ctx_1, \ctx_2) = \ident{split}_{\cclrd{r}, \cclrd{(s\setminus\{\ident{?p}\})}}~\ctx_0\\[-0.3em]
    \quad g~(\ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{(s\setminus\{\ident{?p}\})}}~(f~\ctx_1)~\ctx_2)
  \end{array} }
\end{array}
\end{equation*}

\vspace{1em}
\paragraph{Reduction rules}

\begin{equation*}
\begin{array}{rl}
{\footnotesize(\emph{counit})} & \begin{array}{l}
\ident{counit}_{\cclrd{ \emptyset }}~(\ident{Impl} (v, \ldots))   \rightsquigarrow v
\end{array}
\\[0.5em]
{\footnotesize(\emph{cobind})} & \begin{array}{l}
\ident{cobind}_{\cclrd{r}, \cclrd{s}}~f~(\ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_{n}\mapsto v_n \})) \rightsquigarrow
\\[-0.25em]
\quad \ident{Impl}(f~(\ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{r} \} )), \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{s} \} )
\end{array}
\\[1em]
{\footnotesize(\emph{merge})} & \begin{array}{l}
\ident{merge}_{\cclrd{r}, \cclrd{s}}
              (~\ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_{n}\mapsto v_n \})  \\[-0.25em]
\hspace{4.4em}    \ident{Impl}(v', \{ \ident{?p}'_1 \mapsto v'_1, \ldots, \ident{?p}'_{n}\mapsto v'_n \})~) \rightsquigarrow \\[-0.25em]
\quad \ident{Impl}((v, v'), \{ \ident{?p}_i \mapsto v_i \;|\; \ident{?p}\in\cclrd{r \setminus s}  \} \cup \{ \ident{?p}'_i \mapsto v'_i \;|\; \ident{?p}'\in\cclrd{s}  \})
\end{array}
\\[1.75em]
{\footnotesize(\emph{split})} & \begin{array}{l}
\ident{split}_{\cclrd{r}, \cclrd{s}} (\ident{Impl}((v,v'), \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_{n}\mapsto v_n \}))  \rightsquigarrow
\\[-0.25em]
\quad \ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{r} \} ), \ident{Impl}(v', \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{s} \} )
\end{array}
\\[1em]
{\footnotesize(\emph{letimpl})} & \begin{array}{l}
\ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}~v'~(\ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_{n}\mapsto v_n \}))  \rightsquigarrow
\\[-0.25em]
\quad \ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i\;|\; \ident{?p}_i \in \cclrd{r}, \ident{?p}_i \neq \ident{?p} \} \cup \{ \ident{?p} \mapsto v' \} )
\end{array}
\\[1em]
{\footnotesize(\emph{lookup})} & \begin{array}{l}
\ident{lookup}_{\cclrd{\ident{?p}_i}} (\ident{Impl}(v, \{\ident{?p}_i\mapsto v_i\}) \rightsquigarrow v_i
\end{array}
\end{array}
\end{equation*}

\vspace{-0.5em}
\caption{Additional constructs embedding implicit parameters into the language}
\label{fig:semantics-ext-impl}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Properties.}
We now prove the type safety of of a context-aware programming language with implicit parameters.
To do this, we prove safety of the target functional language with specific extensions for implicit
parameters and we show that the translation from context-aware programming language with implicit
parameters produces well-typed programs in the target language.

The target language consists of the core functional language subset (Figure~\ref{fig:semantics-target})
with the comonadically-inspired extensions (Figure~\ref{fig:semantics-ext}) and the domain-specific
extensions for implicit parameters defined in Figure~\ref{fig:semantics-ext-impl}. The well-typedness
of the translation has been discussed earlier (Theorem~\ref{thm:semantics-welltyped}) and we extend
it to cover operations specific for implicit parameters below (Theorem~\ref{thm:semantics-impl-welltyped}).

As for dataflow computations, we prove the type safety by extending the preservation
(Theorem~\ref{thm:semantics-fp-pres}) and progress (Theorem~\ref{thm:semantics-fp-prog})
for the core functional subset of the language, but it is worth noting that the key parts of
the proofs are centered around the new reduction rules for comonadically-inspired primitives
and newly defined \ident{Impl} values. These do not interact with the rest of the language in
any unexpected ways.

\begin{theorem}[Well-typedness of the implicit parameters translation]
\label{thm:semantics-impl-welltyped}
Given a typing derivation for a well-typed closed expression $\coctx{}{\cclrd{r}} \vdash e : \tau$,
the translated program $f$ obtained using the rules in Figure~\ref{fig:semantics-translation}
and Figure~\ref{fig:semantics-ext-impl} is well-typed, \ie~in the target language: $\vdash f : \sem{\coctx{\Gamma}{\cclrd{r}}} \rightarrow \sem{\tau}$.
\end{theorem}
\begin{proof}
By rule induction over the derivation of the translation.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{var, num, abs, app}): As before.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{lookup}): The type of $\ctx$ has a coeffect  $\cclrd{ \{\ident{?p}\} }$
  which includes the parameter \ident{?p} as required in order to use the (\emph{lookup}) typing rule.

\vspace{0.5em}\noindent\hangindent=0.6cm
Case (\emph{letimpl}): The type of $\ctx$ matches with the input type of
  $\ident{map}_{  \cclrd{r \cup (s\setminus\{\ident{?p}\})} }$. After duplication and splitting
  the context, $\ctx_1$ and $\ctx_2$ have types $\ctyp{\cclrd{r}}(\ldots)$ and
  $\ctyp{\cclrd{s\setminus\{\ident{?p}\}}}(\ldots)$, respectively. This matches with the expected
  types of $\ident{f}$ and $\ident{letimpl}$. The context returned by $\ident{letimpl}$ then
  matches the one required by $\ident{g}$.
\end{proof}

\begin{lemma}[Canonical forms]
\label{thm:semantics-impl-canon}
For all $e, \tau$, if $\vdash e : \tau$ and $e$ is a value then:
\begin{enumerate}
  \item If $\tau=\ident{num}$ then $e = n$ for some $n \in \mathbb{Z}$
  \item If $\tau=\tau_1 \rightarrow \tau_2$ then $e = \lambda x.e'$ for some $x, e'$
  \item If $\tau=\tau_1\times\ldots\times\tau_n$ then $e = (v_1, \ldots, v_n)$ for some $v_i$
  \item If $\tau=\ctyp{\cclrd{ \{ \ident{?p}_1, \ldots, \ident{?p}_n \} }}\tau_1$ then $e = \ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_n \mapsto v_n \} )$
\end{enumerate}
\end{lemma}
\begin{proof}
  (1,2,3) as before; for (4) the last typing rule must have been (\emph{impl}).
\end{proof}

\begin{lemma}[Preservation under substitution]
\label{thm:semantics-impl-pres-subst}
For all $\Gamma, e, e', \tau, \tau'$, if $\Gamma, x:\tau \vdash e : \tau'$ and $\Gamma \vdash e' : \tau$
then $\Gamma \vdash e[x \leftarrow e'] : \tau$.
\end{lemma}
\begin{proof}
  By induction over the derivation of $\Gamma, x:\tau \vdash e : \tau'$ as before, with new
  cases for $\ident{Impl}(e, \{ \ldots \})$, $\ident{lookup}_{\cclrd{\ident{?p}}}$ and
  $\ident{letimpl}_{\cclrd{\ident{?p}}, \cclrd{r}}$.
\end{proof}

\begin{theorem}[Type preservation]
\label{thm:semantics-impl-pres}
  If $\Gamma \vdash e : \tau$ and $e \rightsquigarrow e'$ then $\Gamma \vdash e' : \tau$
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{fn}, \emph{prj}, \emph{ctx}): As before, using Lemma~\ref{thm:semantics-impl-pres-subst} for (\emph{fn}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{counit}): $e = \ident{counit}_{\cclrd{0}}(\ident{Impl}(v, \{\;\}))$. The last rule in the type
  derivation of $e$ must have been (\emph{counit}) with $\Gamma \vdash \ident{Impl}(v, \{ \; \}) : \ctyp{\cclrd{\emptyset}}\tau$
  which, in turn, required that $\Gamma \vdash v : \tau$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{cobind}): $e = \ident{cobind}_{\cclrd{r}, \cclrd{s}}~f~(\ident{Impl}(v, \{ \ident{?p}_1\mapsto v_1, \ldots, \ident{?p}_n\mapsto v_n  \}))$.
  The last rule in the type derivation of $e$ must have been (\emph{cobind}) with a type $\tau = \ctyp{\cclrd{s}}\tau_2$ and assumptions
  $\Gamma \vdash \ident{Impl}(v, \{ \ident{?p}_1\mapsto v_1, \ldots, \ident{?p}_n\mapsto v_n  \}) : \ctyp{\cclrd{r}}{\tau}$ and
  $\Gamma \vdash f : \ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2$.
  The reduced expression has a type $\ctyp{\cclrd{s}}\tau_2$:
\begin{equation*}
\inference
  { \inference
      { \Gamma \vdash f : \ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2 &
        \Gamma \vdash \ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{r} \} ) :  \ctyp{\cclrd{r}}{\tau_1}}
      { \Gamma \vdash f~(\ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{r} \} )) : \tau_2} }
  { \Gamma \vdash \ident{Impl}(f~(\ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{r} \} )), \{ \ident{?p}_i \mapsto v_i \;|\; \ident{p}_i \in \cclrd{s} \}) : \ctyp{\cclrd{s}}\tau_2 }
\end{equation*}

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{lookup}): $e = \ident{lookup}_{\cclrd{\ident{?p}_i}}(\ident{Impl}(v, \{\; \ldots, \ident{?p}_i \mapsto v_i \ldots \}))$. The last rule in the type
  derivation must have been (\emph{lookup}) with $\tau = \ident{num}$ and an assumption $\Gamma\vdash\ident{Impl}(v, \{\; \ldots, \ident{?p}_i\mapsto v_i \ldots \}) : \ctyp{\cclrd{ \{\ldots,\ident{?p}_i,\ldots\} }}{\tau}$,
  which requires $\Gamma \vdash v_i : \ident{num}$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{merge}, \emph{split}, \emph{letimpl}): Similar. In all three cases, the last typing rule in the derivation of $e$
  guarantees that all values of all implicit parameters that are required for the reduction are available.
\end{proof}

\begin{theorem}[Progress]
\label{thm:semantics-impl-prog}
  If $\vdash e : \tau$ then either $e$ is a value or there exists $e'$ such that $e \rightsquigarrow e'$
\end{theorem}
\begin{proof}
  By rule induction over $\vdash$.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{num,abs,var,app,proj,tup}): As before, using the adapted canonical forms lemma
  (Lemma~\ref{thm:semantics-impl-canon}) for (\emph{app}) and (\emph{proj}).

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{counit}): $e = {\ident{counit}_\cunit}~e_1$. If $e_1$ is not a value, it can be reduced
  using (\emph{ctx}) with context ${\ident{counit}_\cunit}~\_$, otherwise it is a value. From Lemma~\ref{thm:semantics-df-canon},
  $e_1 = \ident{Impl}(v, \{\;\})$ and so we can apply (\emph{counit}) reduction rule.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{cobind}): $e = \ident{cobind}_{\cclrd{r}, \cclrd{s}}~e_1~e_2$. If $e_1$ is not a value,
  reduce using (\emph{ctx}) with context ${\ident{cobind}_{\cclrd{r},\cclrd{s}}}~\_~e$. If $e_2$ is
  not a value reduce using (\emph{ctx}) with context ${\ident{cobind}_{\cclrd{r},\cclrd{s}}}~v~\_$.
  If both are values, then from Lemma~\ref{thm:semantics-impl-canon}, we have
  $e_2 = \ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{?p}_i \in \cclrd{r}\cup\cclrd{s} \})$
  and we apply the (\emph{cobind}) reduction.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{merge}): $e = \ident{merge}_{\cclrd{r}, \cclrd{s}} e_1$. If $e_1$ is not a value,
  reduce using (\emph{ctx}) with context $e = \ident{merge}_{\cclrd{r}, \cclrd{s}}~\_$. If $e_1$ is
  a value, it must be a pair of values $(
    \ident{Impl}(v, \{ \ident{?p}_i \mapsto v_i \;|\; \ident{?p}_i \in\cclrd{r} \}),
    \ident{Impl}(v', \{ \ident{?p}_i \mapsto v_i \;|\; \ident{?p}_i \in\cclrd{s} \}))$
  using Lemma~\ref{thm:semantics-df-canon} and it can reduce using (\emph{merge}) reduction.


\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{impl}): $e = \ident{Impl}(e', \{ \ident{?p}_1 \mapsto e_1, \ldots, \ident{?p}_n \mapsto e_n\})$.
  If $e$ is not a value, reduce using (\emph{ctx}) with context
  $\ident{Impl}(\_, \{ \ident{?p}_1 \mapsto e_1, \ldots, \ident{?p}_n \mapsto e_n\})$.
  If $e_i$ is not a value, reduce using (\emph{ctx}) with context
  $\ident{Impl}(v, \{ \ident{?p}_1 \mapsto v_1, \ldots, \ident{?p}_{i-1} \mapsto v_{i-1}, \ident{?p}_i \mapsto \_, \ident{?p}_{i+1} \mapsto v_{i+1}, \ldots \ident{?p}_n \mapsto e_n\})$.
  Otherwise, $e, e_0, \ldots, e_n$ are values and so
  $\ident{Impl}(e', \{ \ident{?p}_1 \mapsto e_1, \ldots, \ident{?p}_n \mapsto e_n\})$
  is also a value.

\vspace{0.25em}\noindent\hangindent=0.6cm
Case (\emph{split}, \emph{letimpl}): Similar. Either sub-expression is not a value,
  or the type guarantees that it is a comonadic value with implicit parameter bindings
  that enable the (\emph{split}) or (\emph{letimpl}) reduction, respectively.
\end{proof}

\begin{theorem}[Safety of context-aware langauge with implicit parameters]
  If $\Gamma \vdash e : \tau$ and $e \rightsquigarrow^* e'$ then either $e'$ is a value of type $\tau$ or
  there exists $e''$ such that $e' \rightsquigarrow e''$ and $\Gamma \vdash e'' : \tau$.
\end{theorem}
\begin{proof}
  Rule induction over $\rightsquigarrow^*$ using Theorem~\ref{thm:semantics-impl-pres} and Theorem~\ref{thm:semantics-impl-prog}.
\end{proof}

% --------------------------------------------------------------------------------------------------

\section{Generalized safety of comonadic embedding}
\label{sec:semantics-generalising}

In Section~\ref{sec:semantics-df} and Section~\ref{sec:semantics-proofs-impl}, we proved the
safety property of two concrete context-aware programming languages based on the coeffect
language framework. The proofs for the two systems were very similar and relied on the
same key principle.

The principle is that the coeffect annotation $\cclrd{r}$ on the type modelling
the indexed comonad structure $\ctyp{\cclrd{r}}\tau$ in the target language guarantees
that the comonadic value will provide the necessary context. As a result the reductions for
operations accessing the context do not get stuck. In case of dataflow, $\ident{prev}_\cclrd{n}$
can always access the tail of the stream and and $\ident{counit}_\cunit$ can always access the
head (because the stream has a sufficient number of elements). In case of implicit parameters,
the context passed to $\ident{lookup}_{\cclrd{\ident{?p}}}$ will always contain a binding for
$\ident{?p}$.

Our core functional target language is not expressive enough to capture the relationship between
the coeffect annotation and the structure of the \ident{Df} or \ident{Impl} value and so we
resorted to adding those as ad-hoc extensions. However, given a target language with a sufficiently
expressive type system, the properties proved in Section~\ref{sec:semantics-proofs} would be
guaranteed directly by the target language. This includes dependently-typed languages such as
Idris or Agda \cite{other-idris,other-agda}, but type-level numerals and sets can also be encoded
in the Haskell type system \cite{effects-embedding}.

In other words, the flat coeffect type system, together with the translation for introduced in this
chapter, can be embedded into a Haskell-like languages and it can provide a succinct and safe way
of implementing context-aware domain specific languages.

\paragraph{Coeffects for liveness.}
As an example, we consider the third instance of coeffect calculus that was discussed in
Chapter~\ref{ch:flat}. If we wanted to follow the development in the previous section for liveness,
we would extend the target language with two kinds of expressions, \ident{Dead} representing a dead
context with no value and \ident{Live} representing a context with a value:
%
\begin{equation*}
\begin{array}{rcl}
e &=& \ldots \sep \ident{Dead} \sep \ident{Live}~e \\
\end{array}
\end{equation*}
%
The typing rules promote the information about whether a value is available into the type-level
and so a context carrying a live value is marked as $\ctyp{\cclrd{\ident{L}}}{\tau}$ while a
dead context has a type $\ctyp{\cclrd{\ident{D}}}{\tau}$.
%
\begin{equation*}
\tyrule{live}
  { \Gamma \vdash e:\tau }
  { \Gamma \vdash \ident{Live}~e : \ctyp{\cclrd{\ident{L}}}{\tau} }
\qquad
\tyrule{dead}
  { ~ }
  { \Gamma \vdash \ident{Dead} : \ctyp{\cclrd{\ident{D}}}{\tau} }
\end{equation*}
%
Finally, we need to add reduction rules that define the meaning of the comonadically-inspired
operations for liveness. Those follow the definitions given in Example~\ref{thm:semantics-indexed-opt}
when discussing the categorical semantics:
%
\begin{equation*}
\begin{array}{rl}
{\footnotesize(\emph{counit})} &
  \ident{counit}_{\cclrd{ \ident{L} }}~(\ident{Just}~v)   \rightsquigarrow v
\\[0.5em]
{\footnotesize(\emph{cobind-1})} &
  \ident{cobind}_{\cclrd{\ident{L}}, \cclrd{\ident{L}}}~f~(\ident{Live}~v) \rightsquigarrow \ident{Live}~(f~v)
\\
{\footnotesize(\emph{cobind-2})} &
  \ident{cobind}_{\cclrd{\ident{D}}, \cclrd{\ident{L}}}~f~(\ident{Live}~v) \rightsquigarrow \ident{Live}~(f~\ident{Dead})
\\
{\footnotesize(\emph{cobind-3})} &
  \ident{cobind}_{\cclrd{\ident{L}}, \cclrd{\ident{D}}}~f~v \rightsquigarrow \ident{Dead}
\\
{\footnotesize(\emph{cobind-4})} &
  \ident{cobind}_{\cclrd{\ident{D}}, \cclrd{\ident{D}}}~f~v \rightsquigarrow \ident{Dead}
\end{array}
\end{equation*}
%
This language extension is safe because the reductions respect the typing of the
comonadically-inspired operations. The $\ident{counit}_\cunit$ reduction does not get stuck
for well-typed terms because $\cunit = \cclrd{\ident{L}}$ in the coeffect algebra and thus its
argument is of type $\ctyp{\cclrd{\ident{L}}}{\tau}$ and will always be a value $\ident{Live}~v$.

Similarly, the when reducing $\ident{cobind}_{\cclrd{r}, \cclrd{s}}$, the typing ensures that
the value passed as the second argument is of type $\ctyp{\cclrd{r}\cseq\cclrd{s}}{\tau_1}$.
In case of liveness, $\cclrd{r}\,\cseq\,\cclrd{s}=\cclrd{\ident{L}}$ if either
$\cclrd{r}=\cclrd{\ident{L}}$ or $\cclrd{s}=\cclrd{\ident{L}}$. This means that reductions
(\emph{cobind-1}) and (\emph{cobind-2}) will not get stuck because the value will be
$\ident{Live}~v$ and not \ident{Dead}. The reduction rules also preserve typing -- the resulting
value is of type $\ctyp{\cclrd{s}}\tau_2$, that is $\ident{Live}~v$ for (\emph{cobind-1}),
(\emph{cobind-2}) and \ident{Dead} for (\emph{cobind-3}) and (\emph{cobind-4}).


\paragraph{Encoding liveness in Haskell.}
The liveness example can be encoded in Haskell using type-level features such as generalized
algebraic data types (GADTs) and type families \cite{haskell-faking,haskell-promotion,haskell-families},
which encode some of the features known from dependently-typed languages such as Agda \cite{other-agda}.
We do not aim to give a complete implementation, but to show that such encoding is possible and
would provide the necessary safety guarantees.

We first define types \ident{D} and \ident{L} to capture the coeffect annotations.
Then we define a comonadically-inspired type $\ident{C}~r~a$ as a GADT with cases for
\ident{Live} and \ident{Dead} contexts. The type parameter $r$ represents a coeffect
annotation:
%
\begin{equation*}
\begin{array}{l}
\kvd{data}~\ident{L} \\[-0.2em]
\kvd{data}~\ident{D} \\[0.5em]
\kvd{data}~\ident{C}~r~a~\kvd{where} \\[-0.2em]
\quad \ident{Live} \hspace{0.45em}:: a \rightarrow \ident{C}~\ident{L}~a\\[-0.2em]
\quad \ident{Dead} :: \ident{C}~\ident{D}~a
\end{array}
\end{equation*}
%
The definition matches with the typing rules (\emph{live}) and (\emph{dead}). The coeffect
annotation for a live value is \ident{L} and the annotation for a dead value is \ident{D}.
To give the type of \ident{cobind}, we need a type-level function that encodes the operations
of the flat coeffect algebra. We model $\cseq$ as $\ident{Seq}~a~b$. The operation is defined
on types $\ident{L}$ and $\ident{D}$ and returns a type $\ident{D}$ if and only if both its
arguments are $\ident{D}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{type}~\kvd{family}~\ident{Seq}~r~s :: *\\[-0.2em]
\quad \kvd{type}~\kvd{instance}~\ident{Seq}~\ident{D}~\ident{D} = \ident{D}\\[-0.2em]
\quad \kvd{type}~\kvd{instance}~\ident{Seq}~\ident{L}~s = \ident{L}\\[-0.2em]
\quad \kvd{type}~\kvd{instance}~\ident{Seq}~r~\ident{L} = \ident{L}
\end{array}
\end{equation*}
%
The \ident{counit} and \ident{cobind} operations can then be defined as Haskell functions
that have types corresponding to the typing rules (\emph{counit}) and (\emph{cobind}) given
in Figure~\ref{fig:semantics-ext}:
%
\begin{equation*}
\begin{array}{rcl}
\ident{counit} &::& \ident{C}~\ident{L}~a \rightarrow a \\[-0.2em]
\ident{cobind} &::& (\ident{C}~\ident{r}~a \rightarrow b) \rightarrow \ident{C}~(\ident{Seq}~r~s)~a \rightarrow \ident{C}~\ident{s}~b
\end{array}
\end{equation*}
%
Here, the additional type parameter is used as a phantom type \cite{types-phantom} and ensures that
\ident{counit} can only be called on a context that contains a value and so calling the operation
is not going to fail. Similarly, the type of the \ident{cobind} operation now guarantees that if a
function (used as the first argument) or the result require a live context, it will be called with
a value $\ident{C}~\ident{L}~a$ that is guaranteed to contain a value.

\paragraph{Coeffects in dependently-typed languages.}
If we use the above encoding, type preservation is guaranteed by the type
system of the target language. The equivalent of the progress property is guaranteed by the
fact that the the implementation of the operations is well-defined.

It is worth noting that this is where coeffects need a target language with a more expressive
type system than monads. For monadic computations, it is sufficient to use a type $\ident{M}~a$
which represents that \emph{some} effect may happen. The the type does not specify which effects
and, indeed, this means that \emph{all possible effects} may happen.

With coeffects, we need to use indexed comonads $\ident{C}~r~a$ where the annotation $r$ specifies
what context may be required. Without the annotation, a type $\ident{C}~a$ would represent a
comonadic context that has \emph{all possible context} available, which is rarely useful in practice.



% ==================================================================================================
%
%      ####           ##            #                #
%      #   #           #            #                #
%      #   #   ###     #     ###   ####    ###    ## #
%      ####   #   #    #        #   #     #   #  #  ##
%      # #    #####    #     ####   #     #####  #   #
%      #  #   #        #    #   #   #  #  #      #  ##
%      #   #   ###    ###    ####    ##    ###    ## #
%
% ==================================================================================================

\section{Related categorical structures}
\label{sec:semantics-related}

Related work leading to coeffects has already been discussed in Chapter~\ref{ch:pathways}
and we covered work related to individual concepts throughout the thesis. However, there is a
number of related categorical structures that are related to our \emph{indexed comonads}
(Section~\ref{sec:semantics-flat-idx}) that deserve additional discussion.

In Section~\ref{sec:semantics-related-related}, we discuss related approaches to adding
indices to categorical structures (mostly monads). In Section~\ref{sec:semantics-related-monad},
we discuss a question that often arises when discussing coeffects and that is
\emph{when is a coeffect (not) an effect?}

\subsection{Indexed categorical structures}
\label{sec:semantics-related-related}

Ordinary comonads have the \emph{shape preservation} property \cite{comonads-codo}. Intuitively,
this means that the core comonad structure does not provide a way of modeling computations where
the additional context changes during the computation. For example, in the \ident{NEList} comonad,
the length of the list stays the same after applying \ident{cobind}.

Indexed comonads are not restricted by this property of comonads. For example, given the indexed
product comonad, in the computation $\ident{cobind}_{\cclrd{r}, \cclrd{s}} f$, the shape of
the context changes from providing implicit parameters $\cclrd{r} \cup \cclrd{s}$  to providing
just implicit parameters $\cclrd{s}$. Thus \emph{indexed comonads} are a generalization of
\emph{comonads} that captures structures that fail to form a comonad without indexing. In the
rest of the section, we look at work that discusses indexing in the context of \emph{monads.}

\paragraph{Families of monads.}
When linking effect systems and monads, Wadler and Thiemann \cite{monad-notions} propose a
\emph{family of monads} as the categorical structure. The dual structure, \emph{family of
comonads}, is defined as follows.

\begin{definition}
\label{def:flat-family}
A \emph{family of comonads} is formed by triples $(\ctyp{\cclrd{r}}{}, \ident{cobind}_{\cclrd{r}},
  \ident{counit}_{\cclrd{r}})$ for all $\cclrd{r}$ such that each triple forms a comonad. Given
$\cclrd{r}, \cclrd{r'}$ such that $\cclrd{r} \leq \cclrd{r'}$, there is also a mapping
$\iota_{\cclrd{r'}, \cclrd{r}} : \ctyp{\cclrd{r'}}{} \rightarrow \ctyp{\cclrd{r}}{}$ satisfying
certain coherence conditions.
\end{definition}

\noindent
A \emph{family of comonads} is not as expressive as an \emph{indexed comonads}. Many indexed
comonads cannot be captured by a family of comonads. This is because each of the data
types needs to form a comonad separately. For example, our indexed Maybe does not form a family of
comonads (again, because \ident{counit} is not defined on $\ctyp{\ident{D}}{\alpha}=1$). However, given
a family of comonads and indices such that $\cclrd{r} \leq \cclrd{r}\cseq\cclrd{s}$, we can define
an indexed comonad. Briefly, to define $\ident{cobind}_{\cclrd{r},\cclrd{s}}$ of an indexed comonad,
we use $\ident{cobind}_{\cclrd{r}\cseq\cclrd{s}}$ from the family, together with two lifting operations:
$\iota_{\cclrd{r}\cseq\cclrd{s}, \cclrd{r}}$ and $\iota_{\cclrd{r}\cseq\cclrd{s}, \cclrd{s}}$.

\paragraph{Parameteric effect monads.}
Parametric effect monads introduced by Katsumata \cite{monads-parametric} (independently to our
indexed comonads) are closely related to our definition.  Although presented in a more general
categorical framework (and using monads), the model (i) defines the \ident{unit} operation only on the
unit of a monoid and (ii) the \ident{bind} operation composes effect annotations using the provided
monoidal structure.

\subsection{When is coeffect not a monad}
\label{sec:semantics-related-monad}

Coeffect systems differ from effect systems in three important ways:

\begin{itemize}
\item Semantically, coeffects capture different notions of computation. As demonstrated in
  Chapter~\ref{ch:pathways}, coeffects track additional contextual properties required by a
  computation, many of which cannot be captured by a monad (\eg~liveness or dataflow).
  In terms of program analysis \cite{other-optcomp}, monas capture forward dataflow analyses and
  comonads correspond to backward dataflow analyses.

\item Syntactically, coeffect calculi use a richer algebraic structure with pointwise composition,
  sequential composition and context merging ($\cpar, \cseq$, and $\czip$) while most effect systems
  only use a single operation for sequential composition (used by monadic bind). Effect systems
  may use a richer algebraic structure to support additional language constructs such as conditionals
  \cite{effects-nielson,effects-revisited}, but not for abstraction and application.

\item Syntactically, the second difference is in the lambda abstraction (\emph{abs}). In
  coeffect systems, the context demands of the body can be split between (or duplicated
  at) declaration site and call site, while lambda abstraction in monadic effect systems always
  defer all effects -- creating a function value has no effect.
\end{itemize}

\noindent
Despite the differences, our implicit paremeters resemble, in many ways, the \emph{reader} monad.
As discussed in Section~\ref{sec:semantics-related-monads}, the \emph{reader} monad is semantically
equivalent to the \emph{product} comonad when we consider just sequential composition. For a
language with lambda abstraction, we need a slight extension to the usual treatment of monads in
order to model implicit parameters using a monad.

% -------------------------------------------------------------------------------------------------

\subsection{When is coeffect a monad}
\label{sec:semantics-related-monads}

Implicit parameters can be captured by a monad, but \emph{just} a monad is not enough.
Lambda abstraction in effect systems does not provide a way of splitting the context
demands between declaration site and call site (or, semantically, combining the implicit
parameters available in the scope where the function is defined and those specified by the caller).

\paragraph{Categorical relationship.}
Before looking at the necessary extensions, consider the two ways of modelling implicit
parameters. We assume that the function $\cclrd{r} \rightarrow \ident{num}$ is a lookup function
for reading implicit parameter values that is defined on a set $\cclrd{r}$. The two definitions
are:
%
\begin{equation*}
\begin{array}{lll}
 \ctyp{\cclrd{r}}\tau = \tau \times (\cclrd{r} \rightarrow \sigma) &~\hspace{10em}~& (\emph{product comonad}) \\
 \mtyp{\cclrd{r}}\tau = (\cclrd{r} \rightarrow \sigma) \rightarrow \tau && (\emph{reader monad})
\end{array}
\end{equation*}
%
The \emph{product comonad} simply pairs the value $\tau$ with the lookup function, while
the \emph{reader monad} is a function that, given a lookup function, produces a $\tau$ value.
As noted by Orchard \cite{comonads-vs-monads}, when used to model computation semantics, the
two representations are equivalent:
%
\begin{remark}
Computations modelled as $\ctyp{\cclrd{r}}{\tau_1}\rightarrow\tau_2$ using the product comonad
are isomorphic to computations modelled as $\tau_1\rightarrow\mtyp{\cclrd{r}}{\tau_2}$ using the
reader monad via currying/uncurrying isomorphism.
\end{remark}
\begin{proof}
The isomorphism is demonstrated by the following equation:
\begin{equation*}
\begin{array}{lll}
 \ctyp{\cclrd{r}}{\tau_1} \rightarrow \tau_2 &\narrow{=}&
 (\tau_1 \times (\cclrd{r} \rightarrow \sigma)) \rightarrow \tau_2 \\
 &\narrow{=}& \tau_1 \rightarrow ((\cclrd{r} \rightarrow \sigma) \rightarrow \tau_2) =
 \tau_1 \rightarrow \mtyp{\cclrd{r}}{\tau_2} \hspace{23em}\qedhere \\
\end{array}
\end{equation*}
\end{proof}

\noindent
This equivalence shows an intriguing relationship between the \emph{product comonad} and
\emph{reader monad}, but it cannot be extended beyond that. In particular, comonads that model
dataflow computations or liveness do not have a corresponding monadic structure.
This equivalence holds for monads and comonads (as well as \emph{indexed} monads
and comonads), but it does not extend to \emph{flat} indexed comonads which also provide
the $\ident{merge}_{\cclrd{r}, \cclrd{s}}$ operation to model context merging. This can be
supported in monadic computations by adding an aditional operation discussed next.

\paragraph{Delaying effects in monads.}
In the syntax of the language, the above difference is manifested by the (\emph{abs}) rules for
monadic effect systems and comonadic coeffect systems. The following listing shows the two rules
side-by-side, using the effect system notation for both of them:
%
\begin{equation*}
\tyrule{cabs}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 \;\&\; \cclrd{r}\,\cclrd{\cup}\,\cclrd{s} }
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2 \;\&\; \cclrd{r}}
\quad
\tyrule{mabs}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 \;\&\; \cclrd{r}\,\cclrd{\cup}\,\cclrd{s}}
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\cclrd{r}\,\cclrd{\cup}\,\cclrd{s}} \tau_2 \;\&\; \cclrd{\emptyset} }
\qquad
\end{equation*}
%
In the comonadic (\emph{cabs}) rule, the implicit parameters of the body are split. However,
the monadic rule (\emph{mabs}) places all demands on the call site. This follows from the
fact that monadic semantics uses the \ident{unit} operation in the interpretation of lambda abstraction:
%
\begin{equation*}
\sem{\lambda x.e} \;=\; \ident{unit}~(\lambda x. \sem{e})
\end{equation*}
%
The type of $\ident{unit}$ is $\alpha\rightarrow\mtyp{\alpha}{\cclrd{\emptyset}}$, but in this specific
case, the $\alpha$ is instantiated to be $\tau_1\rightarrow\mtyp{\cclrd{r \cup s}}{\tau_2}$ and so this
use of \ident{unit} has a type:
%
\begin{equation*}
\ident{unit}~:~(\tau_1\rightarrow\mtyp{\cclrd{r \cup s}}{\tau_2}) \rightarrow \mtyp{\cclrd{\emptyset}}(\tau_1\rightarrow\mtyp{\cclrd{r \cup s}}{\tau_2})
\end{equation*}
%
In order to split the implicit parameters of the body ($\cclrd{r \cup s}$ on the left-hand side) between
the declaration site ($\cclrd{\emptyset}$ on the outer $\mtyp{}$ on the right-hand side) and the
call site ($\cclrd{r \cup s}$ on the inner $\mtyp{}$ on the right-hand side), we need an operation
(which we call \ident{delay}) with the following signature:
%
\begin{equation*}
\ident{delay}_{\cclrd{r}, \cclrd{s}}~:~(\tau_1\rightarrow\mtyp{\cclrd{r \cup s}}{\tau_2}) \rightarrow \mtyp{\cclrd{r}}(\tau_1\rightarrow\mtyp{\cclrd{s}}{\tau_2})
\end{equation*}
%
The operation reveals the difference between effects and coeffects -- intuitively, given a function
with effects $\cclrd{r \cup s}$, it should execute the effects $\cclrd{r}$ when wrapping the
function, \emph{before} the function actually performs the effectful operation with the effects.
The remaining effects $\cclrd{s}$ are delayed as usual, while effects $\cclrd{r}$ are removed
from the effect annotation of the body.

Another important aspect of the signature is that the function needs to be indexed by the coeffect
annotations $\cclrd{r}, \cclrd{s}$. The indices determine how the input context demands
$\cclrd{r \cup s}$ are split -- and thus guarantee determinism of the function at run-time.

The operation cannot be implemented in a useful way for most standard monads, but the
reader monad is, indeed, an exception. It is not difficult to see how it can be implemented
when we expand the definitions of $\mtyp{\cclrd{r}}\tau$:
%
\begin{equation*}
\ident{delay}_{\cclrd{r}, \cclrd{s}}~:~
(\tau_1\rightarrow(\cclrd{r \cup s} \rightarrow \sigma) \rightarrow \tau_2) \rightarrow
((\cclrd{r} \rightarrow \sigma) \rightarrow \tau_1\rightarrow(\cclrd{s} \rightarrow \sigma) \rightarrow \tau_2)
\end{equation*}
%
This suggests that the \emph{reader monad} is a special case among monads. Our work suggests that
passing read-only information to a computation is better captured by a product comonad, which also
matches the intuition -- read-only information is a \emph{contextual capability}.

\paragraph{Restricting coeffects in comonads.}
As just demonstrated, we can extend monads so that the reader monad is capable of capturing
the semantics of implicit parameters, including the splitting of implicit parameter demands
in lambda abstraction. Can we also go the other way round and \emph{restrict} the comonadic
semantics so that all demands are delayed as in the (\emph{mabs}) rule, thus modelling
fully dynamically scoped parameters?

This is, indeed, possible. Recall that the semantics of lambda abstraction in the flat
coeffect calculus is modelled using $\ident{merge}_{\cclrd{r}, \cclrd{s}}$. The operation takes
two contexts (wrapped in an indexed comonad $\ctyp{\cclrd{r}}\alpha$), combines their carried
values and additional contextual information (implicit parameters). To obtain the (\emph{mabs})
rule, we can restrict the first parameter, which corresponds to the declaration site context:

\begin{equation*}
\begin{array}{rcll}
 \ident{merge}_{\cclrd{r}, \cclrd{s}} &\narrow{:}& \ctyp{\cclrd{r}}\alpha \times \ctyp{\cclrd{s}}\beta \rightarrow \ctyp{\cclrd{r \cup s}}(\alpha \times \beta)
 &\hspace{4em}(\textit{normal}) \\
 \ident{merge}_{\cclrd{r}, \cclrd{s}} &\narrow{:}& \ctyp{\cclrd{\emptyset}}\alpha \times \ctyp{\cclrd{s}}\beta \rightarrow \ctyp{\cclrd{s}}(\alpha \times \beta)
 &\hspace{4em}(\textit{restricted})
\end{array}
\end{equation*}
%
In the (\emph{restricted}) version of the operation, the declaration site context requires
no implicit parameters and so all implicit parameters have to be satisfied by the call site.
The semantics using the restricted version corresponds to the (\emph{mabs}) rule shown above.

The idea of restricting the operations of the coeffect calculus semantics could be used more
generally. We could allow any of the coeffect algebra operations $\cseq, \czip, \cpar$ to be
\emph{partial} and thus the restricted (fully dynamically-scoped) version of implicit parameters
could be obtained just by changing the definition of $\czip$. Similarly, we could obtain \eg~a
fully lexically-scoped version of the system. The ability to restrict operations to partial
functions has been used in the semantics of effectful computations by Tate~\cite{effects-producer-semantics}.



% ==================================================================================================
%
%     #####
%    #     #  ####  #    #  ####  #      #    #  ####  #  ####  #    #  ####
%    #       #    # ##   # #    # #      #    # #      # #    # ##   # #
%    #       #    # # #  # #      #      #    #  ####  # #    # # #  #  ####
%    #       #    # #  # # #      #      #    #      # # #    # #  # #      #
%    #     # #    # #   ## #    # #      #    # #    # # #    # #   ## #    #
%     #####   ####  #    #  ####  ######  ####   ####  #  ####  #    #  ####
%
% ==================================================================================================

\section{Conclusions}

In the previous chapter, we defined a \emph{type system} for flat coeffect calculi that uniformly
captures the shared structure of context-aware computations. In this chapter, we completed
the unification by providing \emph{semantics} for flat coeffect calculi and proving the
\emph{safety} of coeffect languages for dataflow and implicit parameters. The semantics shown
here also guides the implementation that is discussed later in Chapter~\ref{ch:impl}.

The development presented in this chapter follows the well-known example of effects and monads.
We introduced the notion of \emph{indexed comonad}, which generalizes comonads
and adds additional operations needed to provide categorical semantics of the flat coeffect
calculus and we demonstrated how implicit parameters, liveness and dataflow computations form
indexed comonads.

We then used the comonadic semantics to define a \emph{comonadically-inspired translation}
that turns programs written in a domain-specific coeffect language into a functional target
language. This is akin to the Haskell do-notation for monads. Finally, we extended the target
language with concrete implementations of comonadic operations for dataflow and implicit parameters
and we presented a syntactic safety proof. In summary, the proof states that well-typed
context-aware programs written in a coeffect language \emph{do not go wrong} (when translated
to a simple functional language and evaluated).

The proof relies on the fact that coeffect annotations (provided by the coeffect type system)
guarantee that the required context is available in the comonadic value that represents the
context and we also discussed how this would guarantee safety in languages with sufficiently
expressive type system such as Haskell.

In the following chapter, we move from \emph{flat} coeffect calculi, tracking whole-context
properties to \emph{structural} coeffect calculi, tracking per-variable information, thus
covering systems from the second half of Chapter~\ref{ch:applications}.
