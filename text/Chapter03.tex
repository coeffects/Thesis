%!TEX root = ../main.tex

% ==================================================================================================

\chapter{Context-aware systems} 
\label{ch:applications} 

Software developers as well as programming language researchers choose abstractions based not 
just on how appropriate they are. Other factors may include social aspects -- how well is the 
abstraction known, how well is it documented and whether it is a standard tool of the 
\emph{research programme}\footnote{ Research programme, as introduced by Lakatos \cite{philosophy-lakatos},
is a network of scientists sharing the same basic assumptions and techniques.}. This may
partly be why no unified context tracking mechanism has been developed so far.

In Chapter~\ref{ch:intro}, we argued that context-awareness had, so far, only limited influence 
on the design of programming languages because it is a challenge that is not easy to
see. However, many of the properties that this thesis treats uniformly as \emph{coeffects} have been
previously tracked by other means. This includes special-purpose type systems, systematic 
approaches arising from modal logic S4, as well as techniques based on abstractions designed 
for other purpose, most frequently monads.

In this chapter, we describe a number of simple calculi for tracking a wide range of contextual
properties. The systems are adapted from existing work, but the uniform presentation in this 
chapter is a novel contribution. The fact that we find a common structure in all systems presented 
here lets us develop unified coeffect calculi in the upcoming three chapters.




% ===================================================================================================
%	                                                               
% 	  ###    #                           #                         
% 	 #   #   #                           #                         
% 	 #      ####   # ##   #   #   ###   ####   #   #  # ##    ###  
% 	  ###    #     ##  #  #   #  #   #   #     #   #  ##  #  #   # 
% 	     #   #     #      #   #  #       #     #   #  #      ##### 
% 	 #   #   #  #  #      #  ##  #   #   #  #  #  ##  #      #     
% 	  ###     ##   #       ## #   ###     ##    ## #  #       ###  
%
% ===================================================================================================

\section{Structure of coeffect systems}

When introducing coeffect systems in Section~\ref{sec:intro-theory}, we related coeffect systems
with effect systems. Effect systems track how program affects the environment, or, in other words 
capture some \emph{output impurity}. In contrast, coeffect systems track what program requires from the 
environment, or \emph{input impurity}.

Effect systems generally use judgements of the form $\Gamma \vdash e : \tau \;\&\; \aclrd{\sigma}$, 
associating effects $\sigma$ with the output type. In contrast, we choose to write coeffect 
systems using judgements of the form $\coctx{\Gamma}{\aclrd{\sigma}} \vdash e : \tau$, associating
the context requirements with $\Gamma$. Thus, we extend the traditional notion of free-variable
context $\Gamma$ with richer notions of context. Besides the notation, there are more important 
differences between effects and coeffects.

% --------------------------------------------------------------------------------------------------

\subsection{Lambda abstraction}
\label{sec:applications-structure-lam}

The difference between effects and coeffects becomes apparent when we consider lambda abstraction.
The typical lambda abstraction rule for effect systems looks as (\emph{abs-eff}) in 
Figure~\ref{fig:applications-abs}. Wadler and Thiemann~\cite{monads-effects-marriage} explain how 
the effect analysis works as follows:
%
\begin{quote}
\emph{In the rule for abstraction, the effect is empty because evaluation immediately
returns the function, with no side effects. The effect on the function arrow
is the same as the effect for the function body, because applying the function will
have the same side effects as evaluating the~body.}
\end{quote}
%
This is the key property of \emph{output impurity}. The effects are only produced when the
function is evaluated and so the effects of the body are attached to the function. A recent
work by Tate~\cite{effects-producer-semantics} uses the term \emph{producer} effect systems
for such standard systems and characterises them as follows:
%
\begin{quote}
\emph{Indeed, we will define an effect as a producer effect if all computations with that 
effect can be thunked as ``pure'' computations for a domain-specific notion of purity.}
\end{quote} 
%
The thunking is typically performed by a lambda abstraction -- given an effectful expression 
$e$, the function $\lambda x.e$ is an effect free value (thunk) that delays all effects.
As shown in the next section, contextual properties do not follow this pattern.

% --------------------------------------------------------------------------------------------------

\begin{figure}
\[
\tyrule{abs-pure}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2}
  { \Gamma \vdash \lambda x.e : \tau_1 \rightarrow \tau_2}
\;\;
\tyrule{abs-eff}
  { \Gamma, x\!:\!\tau_1 \vdash e : \tau_2 \,\&\, \aclrd{\sigma} }
  { \Gamma \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{\sigma}} \tau_2 \,\&\, \aclrd{\emptyset} }
\]
\caption{Lambda abstraction for pure and effectful computations}
\label{fig:applications-abs}
\end{figure}

% --------------------------------------------------------------------------------------------------

\subsection{Notions of context}

We look at three notions of context. The first is the standard free-variable context in 
$\lambda$-calculus. This is well understood and we use it to demonstrate how contextual 
properties behave. Then we consider two notions of context introduced in this thesis --
\emph{flat coeffects} refer to overall properties of the environment and \emph{structural coeffects} 
refer to properties attached to individual variables. 

\paragraph{Variable coeffects.}

In standard $\lambda$-calculus, variable access can be seen as a primitive operation that 
accesses the context. The expression $x$ introduces a context requirement -- the expression 
is typeable only in a context that contains $x:\tau$ for some type $\tau$. 

The standard lambda abstraction (\emph{abs-pure}), shown in Figure~\ref{fig:applications-abs},
splits the free-variable context of an expression into two parts. The value of the parameter
has to be provided by the \emph{call site} (dynamic scope) and the remaining values are provided 
by the \emph{declaration site} (lexical scope). Here, the splitting is determined syntactically --
the notation $\lambda x.e$ names the variable whose value comes from the call site.

The flat and structural coeffects behave in the same way. They also split context-requirements
between the declaration site and call site, but they do it in two different ways.

\paragraph{Flat coeffects.}

In Section~\ref{sec:intro-context-example}, we used \emph{resources} in a distributed system as an 
example of flat coeffects. These could be, for example, a database, GPS sensor or access to the current 
time. We also outlined that such context requirements can be tracked as part of the typing assumption,
for example, say we have an expression $e$ that requires GPS coordinates and the current time. 
The context of such expression will be $\coctx{\Gamma}{ \aclrd{\ident{\{ gps, time \}}} }$.

The interesting case is when we construct a lambda function $\lambda x.e$, marshall it and
send it to another node. In that case, the context requirements can be satisfied in a number of
ways. When the same resource is available at the target machine (\eg.~current time), we can
send the function with a context requirement and \emph{rebind} the resource. However, if the
resource is not available (\eg.~GPS on the server), we need to capture a \emph{remote reference}.

In the example discussed here, $\lambda x.e$ would require GPS sensor from the declaration
site (lexical scope) where the function is declared, which is attached to the current context
as $\coctx{\Gamma}{ \aclrd{\ident{\{ gps \}}} }$. The current time is required from the caller
of the function. So, the context requirement on the call site (dynamic scope) will be
$\aclrd{r}=\aclrd{\footnotesize\ident{\{ time \}}}$. In coeffect systems, we attach this information
to the function writing $\tau_1 \xrightarrow{ \aclrd{r} } \tau_2$.

We look at resources in distributed programming in more details in Section~\ref{sec:applications-flat-distr}.
The important point here is that in flat coeffect systems, contextual requirements are 
\emph{split} between the call-site and declaration-site. Furthermore, in case of distributed
programming, the resources can be freely distributed between the two sites.

\paragraph{Structural coeffects.}

On the one hand, variable context provides a \emph{fine-grained tracking} mechanism of how context
(variables) are used. On the other hand, flat coeffects let us track \emph{additional information} about 
the context. The purpose of \emph{structural coeffects} is to reconcile the two and to provide a way
for fine-grained tracking of additional information related to variables in programs.

In Section~\ref{sec:intro-why-array}, we used an example of tracking array access patterns. For every
variable, the additional coeffect annotation keeps a range of indices that may be accessed relatively
to the current cursor. For example, consider an expression 
$x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$.

Here, the variable context $\Gamma$ contains two variables, both of type \ident{Arr}. This means
$\Gamma = x\!:\!\ident{Arr},\, y\-!\-!\ident{Arr}$. For simplicity, we treat \kvd{cursor} as a 
language primitive. The coeffect annotations will be $(0,0)$ for $x$ and $(-1,1)$ for $y$, 
denoting that we access only the current value in $x$, but we need access to both left and right 
neighbours in the $y$ array. In order to unify the flat and structural notions, we attach this information 
as a \emph{vector} of annotations associated with a \emph{vector} of variable and write:
$\coctx{x\!:\!\ident{Arr},\, y\!:\!\ident{Arr}}{ \aclrd{\alift{ (0,0), (-1,1) }} }$.
The unification is discussed in Chapter~\ref{ch:unified}.

Unlike in flat coeffects, in the structural systems, splitting of context determined by the syntax. 
For example, consider a function that takes $y$ and contains the above body:
$\lambda y.x[\kvd{cursor}] = y[\kvd{cursor}-1] + y[\kvd{cursor}+1]$. Here, the declaration site
contains $x$ and needs to provide access at least within a range $(0,0)$. The call site provides
a value for $y$, which needs to be accessible at least within $(-1, 1)$. In this way, structural
coeffects remove the non-determinism of flat coeffect systems.

Before looking at concrete flat and structural systems in mode details, we briefly overview 
some notation used in this thesis. As structural coeffects keep annotations as \emph{vectors},
we use a number of operations related to scalars and vectors.

% --------------------------------------------------------------------------------------------------

\subsection{Scalars and vectors}
\label{sec:applications-strucutre-vec}

The $\lambda$-calculus is asymmetric -- it maps a context with \emph{multiple} variables to a 
\emph{single} result. An expression with free variables of types $\tau_i$ can be modelled by a function 
$\tau_1 \times \ldots \times \tau_n \rightarrow \tau$ with a product on the left, but a single value
on the right. Effect systems attach effect annotations to the result $\tau$. In coeffect systems,
we attach a coeffect annotation to the context $\tau_1 \times \ldots \times \tau_n$.

Structural coeffects have one coeffect annotation per each variable. Thus, the annotation consists
of multiple values -- one belonging to each variable. To distinguish between the overall annotation
and individual (per-variable) annotations, we call the overall coeffect a \emph{vector} consisting of 
\emph{scalar} coeffects. This asymmetry also explains why coeffect systems are not trivially dual to 
effect systems.

It is useful to clarify how vectors are used in this thesis. Suppose we have a set $\C$ of
\emph{scalars} such that $\cclrd{r_1},\ldots,\cclrd{r_n} \in \C$. A vector $\aclrd{R}$ 
over $\C$ is a tuple $\alift{ \cclrd{r_1}, \ldots, \cclrd{r_n} }$ of scalars. 
We use bold-face letters like $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}, \aclrd{\textbf{t}}$ for vectors and lower-case
letters $\cclrd{r},\cclrd{s},\cclrd{t}$ for scalars\footnote{For better readability, the thesis
also distinguishes different structures using colours. However ignoring the colour does not introduce 
any ambiguity.}. We also say that a \emph{shape} of a vector $\slift{\aclrd{\textbf{r}}}$ (or more generally any container) 
is the set of \emph{positions} in a vector. So, a vector of length $n$ has shape $\{ 1, 2, \ldots, n \}$. 
We discuss containers and shapes further in Chapter~\ref{ch:unified} and also discuss how our use
relates to containers of Abbott, Altenkirch and Ghani \cite{types-containers}.

Just as in the usual multiplication of a vector by scalar, we lift any binary operation on scalars into a 
scalar-vector one. For any binary operation on scalars $\circ : \C \times \C \rightarrow \C$, we define
 $\cclrd{s} \circ \aclrd{\textbf{r}} = \alift{ \cclrd{s}\circ\cclrd{r_1}, \ldots, \cclrd{s}\circ\cclrd{r_n}}$.
Relations on scalars can be also lifted to vectors. Given two vectors $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}$ of the
same shape with positions $\{ 1, \ldots, n \}$ and a relation $\varpropto\, \subseteq \C \times \C$ we define 
$\aclrd{\textbf{r}} \varpropto \aclrd{\textbf{s}} \Leftrightarrow (\cclrd{r_1} \varpropto \cclrd{s_1}) \wedge \ldots \wedge (\cclrd{r_n} \varpropto \cclrd{s_n}) $
Finally, we often concatenate vectors -- for example, when joining two variable contexts.
Given vectors $\aclrd{\textbf{r}}, \aclrd{\textbf{s}}$ with (possibly different) shapes $\{ 1, \ldots, n \}$ and 
$\{ 1, \ldots, m \}$, the associative operation for concatenation $\times$ is defined as 
$\aclrd{\textbf{r}}\times\aclrd{\textbf{s}} = \alift{\cclrd{r_1},\ldots,\cclrd{r_n},\cclrd{s_1},\ldots,\cclrd{s_m}}$.

We note that an environment $\Gamma$ containing $n$ uniquely named, typed variables is also a vector, 
but we continue to write `$,$' for the product, so $\Gamma_1, x\!:\!\tau, \Gamma_2$ should 
be seen as $\Gamma_1 \times \langle x\!:\!\tau\rangle \times \Gamma_2$.




% ===================================================================================================
%	                            
% 	 #####   ##            #    
% 	 #        #            #    
% 	 #        #     ###   ####  
% 	 ####     #        #   #    
% 	 #        #     ####   #    
% 	 #        #    #   #   #  # 
% 	 #       ###    ####    ##  
%	                            
% ===================================================================================================

\section{Flat coeffect systems}
\label{sec:applications-flat}

In flat coeffect systems, the additional contextual information are independent of the variables.
As such, flat coeffects capture properties where the execution environment provides some 
additional data, resources or information about the execution context.

In this section, we look at a number of examples ranging from Haskell's type constraints
and implicit parameters to distributed computing. For three of our examples --
implicit parameters, liveness analysis and data-flow -- we show an ad-hoc type system that
captures their properties. This serves as a basis for Chapter~\ref{ch:flat}, which develops
a unified flat coeffect calculus.

%---------------------------------------------------------------------------------------------------

\subsection{Implicit parameters and type classes} 
\label{sec:applications-flat-impl}

Haskell provides two examples of flat coeffects -- type class and implicit parameter constraints
\cite{app-type-classes,app-implicit-parameters}. Both of the features introduce additional 
\emph{constraints} on the context requiring that the environment provides certain operations for
a type (type classes) or that it provides values for named implicit parameters.
In the Haskell type system, constraints $C$ are attached to the types of top-level declarations,
such as let-bound functions. The Haskell notation $\Gamma \vdash e : C \Rightarrow \tau$ 
corresponds to our notation $\coctx{\Gamma}{C} \vdash e : \tau$. 

In this section, we present a type system for implicit parameters in terms of the coeffect typing
judgement. We briefly consider type classes, but do no give a full type system.

\paragraph{Implicit parameters.}
Implicit parameters are a special kind of variables that support dynamic scoping.
They can be used to parameterise a computation (involving a long chain of function calls)
without passing parameters explicitly as additional arguments of all involved functions. 

The dynamic scoping means that if a function uses a parameter $\ident{?param}$ then the caller of the 
function must set a value of $\ident{?param}$ before calling the function. However, implicit 
parameters also support lexical scoping. If the parameter $\ident{?param}$ is available in the 
lexical scope where a function (which uses it) is defined, then the function will not require a
value from the caller.

A simple language with implicit parameters has an expression $\ident{?param}$ to read a parameter 
and an expression\footnote{Haskell uses $\kvd{let}~\ident{?p} = e_1~\kvd{in}~e_2$, but we use a 
different keyword to avoid confusion.} $\kvd{letdyn}~\ident{?param} = e_1~\kvd{in}~e_2$ that sets a 
parameter $\ident{?param}$ to the value of $e_1$ and evaluates $e_2$ in a context containing 
$\ident{?param}$. 

The fact that implicit parameters support both lexical and dynamic scoping becomes interesting
when we consider nested functions. The following function does some pre-processing and then returns a 
function that builds a formatted string based on two implicit parameters $\ident{?width}$ and 
$\ident{?size}$:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{format} = \lambda \ident{str}~\rightarrow \\[-0.25em]
\quad \kvd{let}~\ident{lines} = \ident{formatLines}~\ident{str}~\ident{?width}~\kvd{in}\\[-0.25em]
\quad (\lambda \ident{rest}~\rightarrow~\ident{append}~
         \ident{lines}~\ident{rest}~\ident{?width}~\ident{?size})
\end{array}
\end{equation*}
%
The body of the outer function accesses the parameter $\ident{?width}$, so it certainly requires a context 
$\{ \ident{?width} : \ident{int} \}$. The nested function (returned as a result) uses the parameter 
$\ident{?width}$, but in addition also uses $\ident{?size}$. Where should the parameters used by the 
nested function come from?

To keep examples in this chapter uniform, we do not use the Haskell notation and instead
write $\tau_1 \xrightarrow{r} \tau_2$ for a function that requires implicit parameters specified $r$.
In a purely dynamically scoped system, they would have to be defined when the user invokes the nested function.
However, implicit parameters behave as a combination of lexical and dynamic scoping. This means
that the nested function can capture the value of $\ident{?width}$ and require just $\ident{?size}$.
The following shows the two options:
%
\begin{equation}
\tag{dynamic}
\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int}, \ident{?size} : \ident{int} \} } \ident{string})
\end{equation}
\vspace{-1em}
\begin{equation}
\tag{mixed}
\ident{string} \xrightarrow{ \{ \ident{?width} : \ident{int} \} }
  (\ident{string} \xrightarrow{ \{ \ident{?size} : \ident{int} \} } \ident{string})
\end{equation}
%
This is not a complete list of possible typings, but it demonstrates the options. The \emph{dynamic}
case requires the parameter \ident{?width} twice (this may be confusing when the caller provides
two different values). In the \emph{mixed} case, the nested function captures the \ident{?width} 
parameter available from the declaration site. As a result, the latter function can be called as follows:\
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{formatHello} = \\[-0.25em]
\quad(~\kvd{letdyn}~\ident{?width}=5~\kvd{in}~\ident{format}~\texttt{"Hello"})\\[-0.25em]
\kvd{in}\,(~\kvd{letdyn}~\ident{?size} = 10~\kvd{in}~\ident{formatHello}~\texttt{"world"}~)
\end{array}
\end{equation*}
%
For different typings of \ident{format}, different ways of calling it are valid. This illustrates
the point made in Section~\ref{sec:applications-structure-lam} -- flat coeffect systems may 
introduce certain non-determinism in the typing. The following section shows how this looks in the
type system for implicit parameters.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{\emptyset}} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{param}
  {}
  {\coctx{\Gamma}{ \{\ident{?param}:\tau \} } \vdash \ident{?param} : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \subseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \cup \aclrd{s} \cup \aclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{r \cup s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r} \cup \aclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 }
\end{equation*}
\vspace{-0.9em}
\caption{Coeffect rules for tracking implicit parameters}
\label{fig:applications-flat-impl}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}

Figure~\ref{fig:applications-flat-impl} shows a type system that tracks the set of expression's 
implicit parameters. The type system uses judgements of the form $\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau$
meaning that an expression $e$ has a type $\tau$ in a free-variable context $\Gamma$ with a set 
of implicit parameters specified by $\aclrd{r}$. The annotations $\aclrd{r},\aclrd{s},\aclrd{t}$ are sets of 
pairs consisting of implicit parameter names and types, \ie~$\aclrd{r},\aclrd{s},\aclrd{t} \subseteq 
  \ident{Names} \times \ident{Types}$. The expressions include \ident{?param} to read implicit
parameter and \kvd{letdyn} to bind an implicit parameter. The types are standard, but functions are
annotated with the set of implicit parameters that must be available on the call-site, \ie~
$\tau_1 \xrightarrow{\aclrd{s}} \tau_2$.

Accessing an ordinary variable (\emph{var}) does not require any implicit parameters. The rule that 
introduces primitive context requirements is (\emph{param}) -- accessing a parameter \ident{?param} 
of type $\tau$ requires it to be available in the context. The context may provide more (unused) 
implicit parameters thanks to the (\emph{sub}) rule.

When we read the rules from the top to the bottom, application (\emph{app}) and let binding 
(\emph{let}) simply union the context requirements of the sub-expressions. However, lambda abstraction
(\emph{abs}) is where the example differs from effect systems. The implicit parameters required by
the body $\aclrd{r} \cup \aclrd{s}$ can be freely split between the declaration-site ($\coctx{\Gamma}{\aclrd{r}}$)
and the call-site ($\tau_1 \xrightarrow{\aclrd{s}} \tau_2$).

The union operation $\cup$ is not a disjoint union, which means that the values for implicit 
parameters can also be provided by both sites. For example, consider a function with a body
$\ident{?a} + \ident{?b}$. Assuming that the function takes and returns $\ident{int}$, the following
list shows 4 out of 9 possible valid typing. Full typing derivations can be found in Appendix~?:
%
\begin{equation*}
\begin{array}{rcllllr}
\coctx{\Gamma}{\aclrd{ \{ \ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{ \ident{?b}:\ident{int} \} } \ident{int} &\qquad\qquad&(1) \\
\coctx{\Gamma}{\aclrd{ \{ \ident{?b}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{ \ident{?a}:\ident{int} \} } \ident{int} &&(2)\\
\coctx{\Gamma}{\aclrd{ \{\ident{?a}:\ident{int} \} }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} } \ident{int} &&(3)\\
\coctx{\Gamma}{\aclrd{ \emptyset }} &\vdash& \lambda x.\ident{?a} + \ident{?b} &:& 
  \ident{int} \xrightarrow{ \{\ident{?a}:\ident{int}, \ident{?b}:\ident{int} \} } \ident{int} &&(4)
\end{array}
\end{equation*}
%
The first two examples demonstrate why the system does not have the principal typing property. 
Both ($1$) and ($2$) are valid typings and they may both be desirable in certain contexts where
the function is used. 

In ($3$), the parameter \ident{?a} has to be provided from both the declaration-site and call-site.
We describe system that supports dynamic rebinding, meaning that when the caller provides a 
value, it hides the value that may be available from the declaration-site. This means that 
$4$ is a more precise typing modelling the same situation. 

%---------------------------------------------------------------------------------------------------

\begin{figure}

{\small The semantics is defined inductively over the typing derivation:}
\begin{equation}
\tag{\emph{var}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash x_i : \tau_i} = \lambda ((x_1, \ldots, x_n), \_) \rightarrow x_i
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{param}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash ?p : \sigma} = \lambda (\_, f) \rightarrow f~?p
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{sub}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau} = \lambda (x, f) \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau}~(x, \restr{f}{\aclrd{r'}})
\end{equation}
\vspace{-1.5em}
\begin{equation}
\tag{\emph{abs}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 } = \lambda ((x_1, \ldots, x_n), f) \rightarrow\\[-0.25em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{r}\cup\aclrd{s}} \vdash e : \tau_2 }~((x_1, \ldots, x_n, y), f \uplus g)   	 
\end{array}
\end{equation}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}\cup\aclrd{s}\cup\aclrd{t}} \vdash e_1~e_2 : \tau_2 } = \lambda (x, f) \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 }~(x, \restr{f}{\aclrd{r}})\\[-0.25em]
  \qquad\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }~(x, \restr{f}{\aclrd{s}} ), \restr{f}{\aclrd{t}})
\end{array}
\end{equation*}

\vspace{1em}
{\small Monadic semantics using the reader monads differs as follows:}
\begin{equation}
\tag{\emph{rdabs}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 } = \lambda ((x_1, \ldots, x_n), \_) \rightarrow\\[-0.25em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{r}\cup\aclrd{s}} \vdash e : \tau_2 }~((x_1, \ldots, x_n, y), g)   	 
\end{array}
\end{equation}

\vspace{1em}
{\small Where $\uplus$ and $\restr{f}{\aclrd{r}}$ are auxiliary definitions:}
\begin{equation*}
\begin{array}{rcl}
 \restr{f}{\aclrd{r}} &=& \{ (p,v) \;|\; (p,v) \in f, \;p \in \aclrd{r} \}\\[-0.25em]
 f \uplus g &=& \restr{f}{\, \textit{dom}(f) \setminus \textit{dom}(g)} \cup g 
\end{array}
\end{equation*}


\caption{Semantics of a language with implicit parameters}
\label{fig:applications-flat-implsem}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
Implicit parameters can be implemented by passing around a hidden dictionary that provides values
to the implicit parameters. Accessing a parameter then becomes a lookup in the dictionary and
the \kvd{letdyn} construct extends the dictionary. To elucidate how such hidden dictionaries 
are propagated through the program when using lambda abstractions and applications, we present a 
simple semantics for implicit parameters. The goal here is not to prove properties of the language,
but simply to provide a better explanation. A detailed semantics in terms of indexed comonads is
shown in Chapter~\ref{ch:flat}.

For simplicity, we assume that all implicit parameters have the same type $\sigma$. In that setting, 
coeffect annotations $\aclrd{r}$ are just sets of names, \ie~$\aclrd{r}, \aclrd{s}, \aclrd{t} \subseteq \ident{Names}$.
Given an expression $e$ of type $\tau$ that requires free variables $\Gamma$ and implicit parameters 
$\aclrd{r}$, our interpretation is a function that takes a product of variables from $\Gamma$ together 
with a hidden dictionary of implicit parameters and returns $\tau$:
%
\begin{equation*}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{r} } \vdash e : \tau} 
  ~:~ (\tau_1 \times \ldots \times \tau_n) \times (\aclrd{r} \rightarrow \sigma) \rightarrow \tau
\end{equation*}
%
The hidden dictionary is represented as a function from $\aclrd{r}$ to $\sigma$. This means that it 
provides a $\sigma$ value for all implicit parameters that are required according to the typing.
Note that the domain of the function is not the set of all possible implicit parameter names, but
only a set of those that are specified by the type system.

A hidden dictionary also needs to be attached to all functions. A function $\tau_1 \xrightarrow{\aclrd{s}} \tau_2$
is interpreted by a function that takes $\tau_1$ together with a dictionary that defines values for
implicit parameters in $\aclrd{s}$:
%
\begin{equation*}
\begin{array}{l}
\sem{\tau_1 \xrightarrow{\aclrd{s}} \tau_2} = \tau_1 \times (\aclrd{s} \rightarrow \sigma) \rightarrow \tau_2
\end{array}
\end{equation*}
%
The definition of the semantics is shown in Figure~\ref{fig:applications-flat-implsem}. Let binding
can be viewed as a syntactic sugar for $(\lambda x.e_2)~e_1$ and so it is omitted for brevity. The 
(\emph{var}) and (\emph{param}) rules are simple -- they project the appropriate variable and 
implicit parameter, respectively.

When an expression requires implicit parameters $\aclrd{r}$, the semantics always provides a 
dictionary defined \emph{exactly} on $\aclrd{r}$. To achieve this, the (\emph{sub}) rule restricts
the function to $\aclrd{r'}$ (which is valid because $\aclrd{r'} \subseteq \aclrd{r}$).

The most interesting rules are (\emph{abs}) and (\emph{app}). In abstraction, we get two dictionaries
$f$ and $g$ (from the declaration-site and call-site, respectively), which are combined and passed 
to the body of the function. The semantics prefers values from the call-site, which is captured by
the $\uplus$ operation. In application, we first evaluate the expression $e_1$, then $e_2$ and finally
call the returned function. The three calls use (possibly overlapping) restrictions of the dictionary
as required by the static types.

Without providing a proof here, we note that the semantics is sounds with respect to the type 
system -- when evaluating an expression, it provides it with a dictionary that is guaranteed to
contain values for all implicit parameters that may be accessed. This can be easily checked by
examining the semantic rules (and noting that the restriction and union always provide the
expected set of parameters).

\paragraph{Monadic semantics.}
Implicit parameters are related to the \emph{reader mo\-nad}. The type 
$\tau_1 \times (\aclrd{r} \rightarrow \sigma) \rightarrow \tau_2$ is equivalent to
$\tau_1 \rightarrow ((\aclrd{r} \rightarrow \sigma) \rightarrow \tau_2)$ through currying. Thus, we can
express the function as $\tau_1 \rightarrow M\tau_2$ for $M\tau = (\aclrd{r} \rightarrow \sigma) \rightarrow \tau$.
Indeed, the reader monad can be used to model dynamic scoping. However, there is an important distinction
from implicit parameters. The usual monadic semantics models fully dynamic scoping, while implicit
parameters combine lexical and dynamic scoping.

The (\emph{rdabs}) rule in Figure~\ref{fig:applications-flat-implsem} shows a semantics that
matches the usual monadic semantics using the reader monad. Note that the declaration-site dictionary
is ignored and the body is called with only the dictionary provided by the call-site. This is
a consequence of the fact that monadic functions are always pure values created using \emph{unit}.

As we discuss later in Section~\ref{sec:flat-related-monads}, the reader monad can be extended 
to model rebinding. However, later examples in this chapter, such as liveness in 
Section~\ref{sec:applications-flat-live} show that other context-aware computations 
cannot be captured by \emph{any} monad.

%---------------------------------------------------------------------------------------------------

\paragraph{Type classes.}
Another type of constraints in Haskell that is closely related to implicit parameters are 
\emph{type class} constraints \cite{app-type-classes}. They provide a principled form of ad-hoc
polymorphism (overloading). When a code uses an overloaded operation (e.g.~comparison or numeric 
operators) a constraint is placed on the context in which the operation is used. For example:
%
\begin{equation*}
\begin{array}{l}
\ident{twoTimes}~::~\ident{Num}~\alpha \Rightarrow \alpha \rightarrow \alpha \\[-0.25em]
\ident{twoTimes}~x=x+x
\end{array}
\end{equation*}
%
The constraint $\ident{Num}~\alpha$ on the function type arises from the use of the $+$ operator. 
Similarly to implicit parameters, type classes can be implemented using a hidden dictionary. In 
the above case, the function \ident{twoTimes} takes a hidden dictionary that provides an operation
$+$ of type $\alpha \times \alpha \rightarrow \alpha$.

Type classes could be modelled as a coeffect system. The type system would annotate the context
with a set of required type classes. The typing of the body of \ident{twoTimes} would look as 
follows:
%
\begin{equation*}
\coctx{x\!:\!\alpha}{ \{ \ident{Num}_\alpha \} } \vdash x + x : \alpha
\end{equation*}
%
Similarly, the semantics of a language with type class constraints can be defined in a way
similar to implicit parameters. The interpretation of the body is a function that takes $\alpha$
together with a hidden dictionary of operations: $\alpha \times \ident{Num}_\alpha \rightarrow \alpha$.

Type classes and implicit parameters show two important points about flat coeffect systems.
First, the context requirements are associated with some \emph{scope}, such as the body
of a function. Second, they are associated with the input. To call a function that takes an 
implicit parameter or has a type-class constraint, the caller needs to pass a (hidden) parameter
together with the function inputs.

\paragraph{Summary.}
Implicit parameters are the simplest example of a system where function abstraction does not 
delay all impurities of the body. As discussed in Section~\ref{sec:applications-structure-lam},
this is the defining feature of \emph{coeffect} systems. 

In this section, we have seen how this affects both the type system and the semantics of the 
language. In the type system, the (\emph{abs}) rule places context-requirements on both the 
declaration-site and the call-site. For implicit parameters, this rule introduces non-determinism,
because the parameters can be split arbitrarily. However, as we show in the next section, this is 
not always the case. Semantically, lambda abstraction \emph{merges} two parts of context (implicit 
parameter dictionaries) that are provided by the call-site and declaration-site. 

%---------------------------------------------------------------------------------------------------

\subsection{Distributed computing}
\label{sec:applications-flat-distr}

Distributed programming was used as one of the motivating examples for coeffects in 
Chapter~\ref{ch:intro}. This section explores the use case. We look at rebindable resources and
cross-compilation. The structure of both is very similar to implicit parameters and type
class constraints, but they demonstrate that there is a broader use for coeffect systems.

% --------------------------------------------------------------------------------------------------

\paragraph{Rebindable resources.}

The need for parameters that support dynamic scoping also arises in distributed computing.
To quote an example discussed by Bierman et al. \cite{app-distributed-rebinding}: \emph{``Dynamic 
binding is required in various guises, for example when a marshalled value is received from the 
network, containing identifiers that must be rebound to local resources.''} 

Rebindable parameters are identifiers that refer to some specific resource. When a function value
is marshalled and sent to another machine, rebindable resources can be handled in two ways. 
First, if the resource is available on the target machine, the parameter is \emph{rebound} to
the resource on the new machine. This is captured by dynamic scoping rules. Second, if the 
resource is not available on the target machine, the resource is either marshalled or a \emph{remote 
reference} is created. This is captured by lexical scoping rules.

A practical language that supports rebindable resources is for example Acute \cite{app-distributed-acute}.
In the following example, we use the construct $\kvd{access}~\ident{Res}$ to represent
access to a rebindable resource named $\ident{Res}$. The following simple function accessed
a database and a current date and filters values based on the date:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{recentEvents} = \lambda () \rightarrow\\[-0.25em]
\quad\kvd{let}~\ident{db} = \kvd{access}~\ident{News}~\kvd{in}\\[-0.25em]
\quad\ident{query}~\ident{db}~\str{SELECT * WHERE Date > \%1}~(\kvd{access}~\ident{Clock})
\end{array}
\end{equation*}
%
When \ident{recentEvents} is created on the server and sent to the client, a remote reference to 
the database (available only on the server) must be captured. If the client device supports a 
clock, then \ident{Clock} can be locally \emph{rebound}, e.g., to accommodate time-zone changes. 
Otherwise, the date and time needs to be obtained from the server too.

The type system and semantics for rebindable resources are essentially the same as those for
implicit parameters. Primitive requirements are introduced by the $\kvd{access}$ keyword. 
Lambda abstraction splits the resources non-deterministically between declaration-site 
(capturing remote reference) and call-site (representing rebinding). For this reason, we do not
discuss the system in details and instead look at other uses.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation*}
\begin{array}{l}
\cmt{// Checks that input is valid; can run on both server and client}\\[-0.25em]
\kvd{let}~\ident{validateInput} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\ident{name} \neq \str{} ~~\&\&~~ \ident{forall~isLetter~name}
\\[0.5em]
\cmt{// Searches database for a product; can run on the server-side}\\[-0.25em]
\kvd{let}~\ident{retrieveProduct} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}~\ident{Some}(\ident{queryProductDb~name})\\[-0.25em]
\quad\kvd{else}~\ident{None}
\\[0.5em]
\cmt{// Client-side function to show price or error (for invalid inputs)}\\[-0.25em]
\kvd{let}~\ident{showPrice} = \lambda \ident{name} \rightarrow\\[-0.25em]
\quad\kvd{if}~\ident{validateInput name}~\kvd{then}\\[-0.25em]
\quad\quad\kvd{match}~(\kvd{remote}~\ident{retrieveProduct}())~\kvd{with}\\[-0.25em]
\quad\quad|~\ident{Some}~\ident{p} \rightarrow \ident{showPrice}~(\ident{getPrice}~\ident{p})\\[-0.25em]
\quad\quad|~\ident{None}~\rightarrow \ident{showError}~\str{Invalid input on the server}\\[-0.25em]
\quad\kvd{else}~\ident{showError}~\str{Invalid input on the client}
\end{array}
\end{equation*}

\vspace{1em}
\noindent\makebox[\linewidth]{\rule{\textwidth}{0.5pt}} 
\vspace{-1.5em}
\caption{Sample client-server application with input validation}
\label{fig:applications-flat-distr}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Cross-compilation.}
A related issue with distributed programming is the need to target increasing number of diverse
platforms. Modern applications often need to run on multiple platforms (iOS, Android, Windows or
as JavaScript) or multiple versions of the same platform. Many programming languages are capable
of targeting multiple different platforms. For example, functional languages that can be compiled 
to native code and JavaScript include, among others, F\#, Haskell and OCaml \cite{app-ocaml-js}.

Links \cite{app-distributed-links}, F\# WebTools and WebSharper \cite{app-fsharp-webapps,app-fsharp-webtools},
ML5 and QWeSST \cite{app-distributed-ml5, app-distributed-qwesst} and Hop \cite{app-hop-lang} go 
further and allow including code for multiple distinct platforms in a single source file. 
A single program is then automatically split and compiled to multiple target runtimes. This
posses additional challenges -- it is necessary to check where each part of the program can run
and statically guarantee that it will be possible to compile code to the required target 
platform (safe \emph{multi-targetting}).

We demonstrate the problem by looking at input validation. In applications that communicate over 
unsecured HTTP channel, user input needs to be validated interactively on the client-side (to 
provide immediate response) and then again on the server-side (to guarantee safety). 

Consider the client-server example in Figure~\ref{fig:applications-flat-distr}. The 
\ident{retrieveProduct} function represents the server-side, while \ident{showPrice} is called 
on the client-side and performs a remote call to the server-side function (how this is implemented 
is not our concern here). To ensure that the input is valid \emph{both} functions call 
\ident{validateInput} -- however, this is fine, because \ident{validateInput} uses only basic
functions and language features that can be cross-compiled to both client-side and server-side.

In Links \cite{app-distributed-links}, functions can be annotated as client-side, server-side
and database-side. F\# WebTools \cite{app-fsharp-webtools} supports cross-compiled (mixed-side)
functions similar to \ident{validateInput}. However, these are single-purpose language features 
and they are not extensible. A practical implementation needs to be able to capture multiple
different patterns -- sets of environments (client, server, mobile) for distributed computing,
but also Android API level \cite{app-android-multitarget} to cross-compile for multiple versions 
of the same platform.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]

{\small a.) Set based type system for cross-compilation, inspired by Links \cite{app-distributed-links}}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \supseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \cap \aclrd{s} \cap \aclrd{t}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r} \cup \aclrd{s}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{s}} \tau_2 }
\end{equation*}
\vspace{0.5em}

{\small b.) Version number based type system, inspired by Android API level \cite{app-android-multitarget}}

\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \leq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\ident{max} \{\aclrd{r}, \aclrd{s}, \aclrd{t} \}} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 }
\end{equation*}

\caption{Two variants of coeffect typing rules for cross-compilation}
\label{fig:applications-flat-cross}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type systems.}

Cross-compilation may seem similar to the tracking of resources (and thus to the tracking of implicit 
parameters), but it actually demonstrates a couple of new ideas that are important for flat coeffect 
systems. Unlike with implicit parameters, we will not present a specific existing system in this 
section -- instead we briefly look at two examples that let us explore the range of possibilities. 

In the first system, shown in Figure~\ref{fig:applications-flat-cross} (a), the coeffect annotations
are sets of execution environments, \ie~$\aclrd{r}, \aclrd{s}, \aclrd{t} \subseteq \{ \ident{client},
\ident{server}, \ident{database} \}$. Sub-coeffecting (\emph{sub}) lets us ignore some of the supported 
execution environments; application (\emph{app}) can be only executed in the \emph{intersection} of the
environments required by the two expressions and the function value.

Sub-coeffecting and application are trivially dual to the rules for implicit parameters. We just track
supported environments using intersection as opposed to tracking of required parameters using union.
However, this symmetry does not hold for lambda abstraction (\emph{abs}), which still uses \emph{union}.
This models the case where the function can be executed in two different ways:
%
\begin{itemize}
\item[--] The function is represented as executable code for an environment available at the call-site
  and is executed there, possibly after it is marshalled and transferred to another machine.
\vspace{-0.5em}
\item[--] The function body is compiled for the environment available at the declaration-site; the value
  that is returned is a remote reference to the code and function calls are performed as remote invocations.
\end{itemize}
%
This example ignores important considerations -- for example, it is likely desirable to make this
difference explicit and the implementation (and semantics) needs to be clarified. However, the
example shows that the algebraic structure of coeffect annotations may be more complex. Here, using
$\cap$ for application and $\cup$ for abstraction.

The second system, shown in Figure~\ref{fig:applications-flat-cross} (b) is inspired by the API
level requirements in Android. Coeffect annotations are simply numbers representing the level
($\aclrd{r}, \aclrd{s}, \aclrd{t} \in \mathbb{N}$). Levels are ordered increasingly, so we can
always require higher level (\emph{sub}). The requirement on function application (\emph{app}) is
the highest level of the levels required by the sub-expressions and the function. The system uses 
yet another variant of lambda abstraction (\emph{abs}) -- the requirements of the body are duplicated
and placed on \emph{both} the declaration-site and the call-site.

In addition to the work discussed already, ML5 \cite{app-distributed-ml5} is another important work 
that looks at tracking of execution environments. It uses modalities of modal S4 to represent the 
environment -- this approach is similar to coeffects, both from the practical perspective, but also 
through deeper theoretical links. We return to this topic in Section~\ref{sec:conclusions-meta} of
the final chapter.

% --------------------------------------------------------------------------------------------------

\subsection{Liveness analysis}
\label{sec:applications-flat-live}

\emph{Live variable analysis} (LVA) \cite{app-modern-compiler} is a standard technique in compiler 
theory. It detects whether a free variable of an expression may be used by a program during its
evaluation (it is \emph{live}) or whether it is definitely not needed (it is \emph{dead}). As an 
optimization, compiler can remove bindings to dead variables as they are never accessed. Wadler 
\cite{app-strictness-absecnce} describes the property of a variable that is dead as the 
\emph{absence} of a variable. 

\paragraph{Flat liveness analysis.}
In this section, we discuss a restricted form of liveness analysis. We do not track liveness of 
\emph{individual} variables, but of the \emph{entire} variable context. This is not practically
useful, but it provides interesting insight into how flat coeffects work. A per-variable liveness
analysis can be captured using structural coeffects and is discussed in Section~\ref{sec:applications-struct-live}.
Consider the following two examples:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant42} = \lambda \ident{x} \rightarrow 42\\
\kvd{let}~\ident{constant} = \lambda \ident{value} \rightarrow \lambda \ident{x} \rightarrow \ident{value}
\end{array}
\end{equation*}
%
The body of the first function is just a constant $42$ and so the context of the body is marked
as \emph{dead}. The parameter (call-site) of the function is not used and can also be marked as dead. 
Similarly, no variables from the declaration-site are used and so they are also marked as dead.

In contrast, the body of the second function accesses a variable \ident{value} and so the body 
of the function is marked as \emph{live}. In the flat system, we do not track \emph{which} 
variable was used and so we have to mark both the call-site and declaration-site as live (this will
be refined in structural liveness system).

\paragraph{Forward vs. backward \& may vs. must.}
Static analyses can be classified as either \emph{forward} or \emph{backward} (depending on how they 
propagate information) and as either \emph{must} or \emph{may} (depending on what properties they
guarantee). Liveness is a \emph{backward} analysis -- the requirements are propagated from variables 
to their declarations. The distinction between \emph{must} and \emph{may} is apparent when we look 
at an example with conditionals:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{defaultArg}~= \lambda \ident{cond} \rightarrow \lambda \ident{input} \rightarrow\\
\quad\kvd{if}~\ident{cond}~\kvd{then}~42~\kvd{else}~\ident{input}
\end{array}
\end{equation*}
%
Liveness analysis is a \emph{may} analysis meaning that it marks variable as live when it
\emph{may} be used and as dead if it is \emph{definitely} not used. This means that the variable
\ident{input} is \emph{live} in the example above. A \emph{must} analysis would mark the variable
only if it was used in both of the branches (this is sometimes called \emph{neededness}).
The distinction between \emph{may} and \emph{must} analyses demonstrates the importance of 
interaction between contextual properties and certain language constructs such as conditionals.

% --------------------------------------------------------------------------------------------------

\begin{figure}
{\small a.) The operations of a two-point lattice $\mathcal{L} = \{\ident{L}, \ident{D}\}$ 
where $\ident{D} \sqsubseteq \ident{L}$ are defined as:}
%
\begin{equation*}
\begin{array}{rcl}
\ident{L} \sqcup \ident{L} &=& \ident{L}\\
\ident{D} \sqcup \ident{L} &=& \ident{D}\\
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcup \ident{D} &=& \ident{D}\\
\ident{D} \sqcup \ident{D} &=& \ident{D}
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcap \ident{L} &=& \ident{L}\\
\ident{D} \sqcap \ident{L} &=& \ident{L}\\
\end{array}
\qquad
\begin{array}{rcl}
\ident{L} \sqcap \ident{D} &=& \ident{L}\\
\ident{D} \sqcap \ident{D} &=& \ident{D}
\end{array}
\end{equation*}

{\small b.) Sequential composition of (semantic) functions composes annotations using $\sqcup$:}
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\aclrd{s}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\aclrd{r} \sqcup \aclrd{s}} \tau_3 \qquad\qquad& ~
\\[0.75em]
f : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{L}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{L}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{D}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 &
g : \tau_2 \xrightarrow{\aclrd{\ident{D}}} \tau_3 &
g \circ f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 & (4)
\end{array}
\end{equation*}

{\small c.) Pointwise composition of (semantic) functions composes annotations using $\sqcap$:}
\begin{equation*}
\begin{array}{llll}
f : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\aclrd{s}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{r} \sqcap \aclrd{s}} \tau_2 \times \tau_3 \qquad&~
\\[0.75em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 \times \tau_3 & (1)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (2)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (3)
\\[-0.10em]
f : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 &
h : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_3 &
\langle f, h \rangle : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 \times \tau_3 & (4)
\end{array}
\end{equation*}

\caption{Liveness annotations with sequential and pointwise composition}
\label{fig:applications-flat-livealg}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
A type system that captures whole-context liveness annotates the context with value of a 
two-point lattice $\mathcal{L} = \{ \ident{L}, \ident{D} \}$. The annotation \ident{L} marks
the context as \emph{live} and \ident{D} stands for a \emph{dead} context. 
Figure~\ref{fig:applications-flat-livealg} (a) defines the ordering $\sqsubseteq$, meet $\sqcup$ and join 
operations $\sqcap$ of the lattice.

The typing rules for tracking whole-context liveness are shown in Figure~\ref{fig:applications-flat-liveness}.
The language now includes constants $c:\tau \in \Delta$. Accessing a constant (\emph{const}) annotates
the context as dead using \ident{D}. This contrasts with variable access (\emph{var}), which marks the
context as live using \ident{L}. A dead context (definitely not needed) can be treated as live context
(which may be used) using the (\emph{sub}) rule. This captures the \emph{may} nature of the analysis.

The (\emph{app}) rule is best understood by discussing its semantics. The semantics uses 
\emph{sequential composition} to compose the semantics of $e_2$ with the function obtained
as the result of $e_1$. However, we need more than just sequential composition. The same input
context is passed to the expression $e_1$ (in order to get the function value) and to the
sequentially composed function (to evaluate $e_2$ followed by the function call). This is captured 
by \emph{pointwise composition}.


Consider first \emph{sequential composition} of (semantic) functions $f, g$ annotated with 
$\aclrd{r}, \aclrd{s}$. The composed function $g \circ f$ is annotated with $\aclrd{r} \sqcup \aclrd{s}$
as shown in Figure~\ref{fig:applications-flat-livealg} (b).
The argument of the function $g \circ f$ is live only when the arguments of both $f$ and $g$ are 
live ($1$). When the argument of $f$ is dead, but $g$ requires $\tau_2$ ($2$), we can evaluate 
$f$ without any input and obtain $\tau_2$, which is then passed to $g$. When $g$ does not require
its argument ($3, 4$), we can just evaluate $g$, without evaluating $f$. Here, the semantics
\emph{implements} the dead code elimination optimization.

Secondly, a \emph{pointwise composition} passes the same argument to $f$ and $h$. The parameter 
is live if either the parameter of $f$ or $h$ is live. The pointwise composition is written as
$\langle f, h \rangle$ and it combines annotations using $\sqcap$ as shown in Figure~\ref{fig:applications-flat-livealg} (c).
Here, the argument is not needed only when both $f$ and $h$ do not need it ($1$). In all other cases,
the parameter is needed and is then used either once ($2,3$) or twice ($4$). The rule for function
application (\emph{app}) combines the two operations. The context $\Gamma$ is live if it is needed by
$e_1$ (which always needs to be evaluated) \emph{or} when it is needed by the function value \emph{and}
by $e_2$. 

The (\emph{abs}) rule duplicates the annotation of the body, similarly to the cross-compilation 
example in Figure~\ref{fig:applications-flat-cross}. When the body accesses any variables, it 
requires both the argument and the variables from declaration-site. When it does not use any variables,
it marks both as dead. Finally, the (\emph{let}) rule annotates the composed expression with the
liveness of the expression $e_2$ -- if the context of $e_2$ is live, then it also requires variables
from $\Gamma$; if it is dead, then it does not require $\Gamma$ or $x$. 
As further discussed later in Section~?, the (\emph{let}) rule is again just a syntactic sugar for 
$(\lambda x.e_2)~e_1$. Briefly, this follows from the simple observation that 
$\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{r}) = \aclrd{r}$.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{\ident{L} }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{const}
  {c : \tau \in \Delta}
  {\coctx{\Gamma}{ \aclrd{\ident{D}} } \vdash c : \tau }
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{r'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau }\quad\quad(\aclrd{r'} \sqsubseteq \aclrd{r})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 &
   \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{t})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{s}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{s}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{r}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{r}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{r}} \tau_2 }
\end{equation*}
\vspace{-0.9em}

\caption{Coeffect rules for tracking whole-context liveness}
\label{fig:applications-flat-liveness}
\vspace{-1.2em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Examples.}
Before looking at the semantics, we consider a number of simple examples to demonstrate the
key aspects of the system. Full typing derivations are shown in Appendix~?:
%
\begin{equation*}
\begin{array}{lll}
(\lambda x \rightarrow 42)~y &~\hspace{1em}~&(1)\\
\ident{twoTimes}~42          &&(2)\\
(\lambda x \rightarrow x)~42 &&(3)\\
\end{array}
\end{equation*}
%
In the first case, the context is dead. In ($1$), the function's parameter is dead and so the
overall context is dead, even though the argument uses a variable $y$ -- the semantics evaluates 
the function without passing it an actual argument. In the second case ($2$), the function is
a variable that needs to be obtained and so the context is live. In the last case ($3$), the 
function accesses a variable and so its declaration-site is marked as requiring the context 
(\emph{abs}). This is where structural coeffect analysis would be more precise -- the system shown
here cannot capture the fact that $x$ is a bound variable.

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation}
\tag{\emph{var}}
\sem{\coctx{\Gamma}{\aclrd{ \ident{L} }} \vdash x_i : \tau_i} = \lambda (x_1, \ldots, x_n) \rightarrow x_i
\end{equation}
\vspace{-1.75em}
\begin{equation}
\tag{\emph{const}}
\sem{\coctx{\Gamma}{\aclrd{ \ident{D} }} \vdash c_i : \tau_i} = \lambda () \rightarrow \delta(c_i)
\end{equation}
%
%
\vspace{-0.5em}
%
%
\begin{equation}
\tag{\emph{sub-1}}
\sem{\coctx{\Gamma}{\aclrd{\ident{L} }} \vdash e : \tau} = \lambda x \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{\ident{D} }} \vdash e : \tau}~()
\end{equation}
\vspace{-1.75em}
\begin{equation}
\tag{\emph{sub-2}}
\sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau} = \lambda x \rightarrow 
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash e : \tau}~x
\end{equation}
%
%
\vspace{-0.5em}
%
%
\begin{equation}
\tag{\emph{abs-1}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{L}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2 } = \lambda (x_1, \ldots, x_n) \rightarrow\\[-0.25em]
  \qquad\lambda y \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{\ident{L}}} \vdash e : \tau_2 }~(x_1, \ldots, x_n, y)   	 
\end{array}
\end{equation}
\vspace{-1.0em}
\begin{equation}
\tag{\emph{abs-2}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{D}}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2 } = \lambda () \rightarrow\\[-0.25em]
  \qquad\lambda () \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{\ident{D}}} \vdash e : \tau_2 }~()
\end{array}
\end{equation}
%
%
\vspace{0.0em}
%
%
%
\begin{equation*}
\tag{\emph{app-1}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r}} \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{ \ident{D} }} \tau_2 }~x
    ~\kvd{in}~g~()
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app-2}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{\ident{L}}} \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{ \ident{L} }} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{ \ident{L} }} \tau_2 }~x
    ~\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{ \ident{D} }} \vdash e_2 : \tau_1 }~())
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\tag{\emph{app-3}}
\hspace{-0.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{r} \sqcup (\aclrd{s} \sqcap \aclrd{t}) } \vdash e_1~e_2 : \tau_2 } = \lambda x \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{r}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{t}} \tau_2 }~x
    ~\kvd{in}~g~(\sem{ \coctx{\Gamma}{\aclrd{s}} \vdash e_2 : \tau_1 }~x)
\end{array}
\end{equation*}

\caption{Semantics of a language with liveness analysis}
\label{fig:applications-flat-livsem}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.} 
The type system presented above requires the semantics to \emph{implement} dead code elimination.
This means that when a function does not require an input (it is marked as dead), the semantics
does not evaluate the argument and passes an empty value as the input instead.

We can represent such empty values using the option type (known as \ident{Maybe} in Haskell).
We use the notation $\tau + 1$ to denote option types. Given a context with variables $x_i$ of
type $\tau_i$, the semantics is a function taking $(\tau_1 \times \ldots \times \tau_n) + 1$.
When the context is live, it will be called with the left value (product of variable assignments);
when the context is dead, it will be called with the right value (containing no information).

However, ordinary option type is not sufficient. We need to capture the fact that the 
representation depends on the annotation -- in other words, the type is \emph{indexed} by 
the coeffect annotation. The indexing is discussed in details in Section~X. For now, it suffices
to define the semantics using two separate rules:
%
\begin{equation*}
\begin{array}{rlrcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{\ident{L}} } \vdash e : \tau} 
  &:& (\tau_1 \times \ldots \times \tau_n) &\narrow{\rightarrow}& \tau\\
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{\ident{D}} } \vdash e : \tau} 
  &:& 1 &\narrow{\rightarrow}& \tau
\end{array}
\end{equation*}
%
The semantics of functions is defined similarly. When the argument of a function is live, the function 
takes the input value; when the argument is dead, the semantic function takes a unit as its argument:
%
\begin{equation*}
\begin{array}{l}
\sem{\tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2} = \tau_1 \rightarrow \tau_2\\
\sem{\tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2} = 1 \rightarrow \tau_2
\end{array}
\end{equation*}
%
Unlike with implicit parameters, the coeffect system for liveness tracking cannot be modelled 
using monads. Any monadic semantics would express functions as $\tau_1 \rightarrow M\, \tau_2$.
Unless laziness is already built-in in the semantics, there is no way to call such function without
first obtaining a value $\tau_1$. The above semantics makes this possible by taking a unit $1$ when
the argument is not live.

In Figure~\ref{fig:applications-flat-livsem}, we define the semantics directly. We write $()$ for
the only value of type $1$. This appears, for example, in (\emph{const}) which takes $()$ as the
input and returns constant using a global dictionary $\delta$. In (\emph{var}), the context is live
and so the semantics performs a projection. Sub-coeffecting is captured by two rules. A dead context 
can be treated as live using (\emph{abs-1}); in other cases, the annotation is not changed (\emph{abs-2}).

Lambda abstraction can be annotated in just two ways. When the body requires context (\emph{abs-1}),
the value of a bound variable $y$ is added to the context $\Gamma$ before passing it to the body.
When the body does not require context (\emph{abs-2}), it is called with $()$ as the input.

For application, there are 8 possible combinations of annotations. The semantics of some of them
is the same, so we only need to show 3 cases. The rules should be read as ML-style pattern matching,
where the last rule handles all cases not covered by the first two. In (\emph{app-1}), we handle the
case when the function $g$ does not require its argument -- $e_2$ is not used and instead, the function
is called with $()$ as the argument. The case (\emph{app-2}) covers the case when the expression
$e_1$ does not require a context, but $e_1$ does. Finally, in (\emph{app-3}), the same input
(which may be either tuple of variables or unit) is propagated uniformly to both $e_1$ and $e_2$.

\paragraph{Summary.}
Unlike with implicit parameters, the lambda abstraction for liveness analysis does not introduce 
non-determinism. It simply duplicates the context requirements. However, this still matches the
property of coeffects that impurities cannot be thunked.

The semantics of liveness reveals a number of interesting properties too. Firstly, the semantics
cannot be captured by any monad. Secondly, the system would not work without the coeffect annotations. 
The shape of the semantic function depends on the annotation (the input is either $1$ or $\tau$) and 
is \emph{indexed} by the annotation. Finally, we discussed at length how the semantics of application
arises from \emph{sequential} and \emph{pointwise} composition. This is another important aspect of
coeffect systems -- categorical semantics typically builds on \emph{sequential} composition, but to
model full $\lambda$ calculus it needs more. For coeffect systems, we need \emph{pointwise} composition
where the same context is shared by multiple sub-expressions.

% --------------------------------------------------------------------------------------------------

\subsection{Data-flow languages}
\label{sec:applications-flat-dataflow}

The Section~\ref{sec:intro-why-array} briefly demonstrated that we can treat array access as an 
operation that accesses a context. In case of arrays, the context is neighbourhood of a current
location in the array specified by a cursor. In this section, we make the example more concrete,
using a simpler and better studied programming model, data-flow languages.

Lucid \cite{app-lucid} is a declarative data-flow language designed by Wadge and Ashcroft. In Lucid, 
variables represent streams and programs are written as transformations over streams. A function 
application $\ident{square}(x)$ represents a stream of squares calculated from the stream of values $x$.

The data-flow approach has been successfully used in domains such as development of real-time embedded 
application where many \emph{synchronous languages} \cite{app-synchronous-lang} build on the data-flow
paradigm. The following example is inspired by the Lustre \cite{app-synchronous-lustre} language
and implements program to count the number of edges on a Boolean stream:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{edge} = \ident{false}~\kvd{fby}~(\ident{input}~\&\&~\ident{not}~(\kvd{prev}~\ident{input}))
\\[0.5em]
\kvd{let}~\ident{edgeCount} = \\[-0.25em]
\quad 0~\kvd{fby}~ (~\kvd{if}~\ident{edge}~\kvd{then}~1 + (\kvd{prev}~\ident{edgeCount})\\[-0.25em]
\quad\quad\quad~~~\, \kvd{else}~\kvd{prev}~\ident{edgeCount} ~)
\end{array}
\end{equation*}
%
The construct $\kvd{prev}~x$ returns a stream consisting of previous values of the stream 
$x$. The second value of $\kvd{prev}~x$ is first value of $x$ (and the first
value is undefined). The construct $y~\kvd{fby}~x$ returns a stream whose first element is the 
first element of $y$ and the remaining elements are values of $x$. Note that in Lucid, the constants
such as \ident{false} and $0$ are constant streams. Formally, the constructs are defined as follows
(writing $x_n$ for $n$-th element of a stream $x$):
%
\[ 
(\kvd{prev}~x)_n = \left\{ 
  \begin{array}{ll}
    nil     & \; \text{if $n=0$}\\
    x_{n-1} & \; \text{if $n>0$}
  \end{array} \right.
\quad
(y~\kvd{fby}~x)_n = \left\{ 
  \begin{array}{ll}
    y_0     & \; \text{if $n=0$}\\
    x_n     & \; \text{if $n>0$}
  \end{array} \right.
\]  
%
When reading data-flow programs, we do not need to think about variables in terms of streams --
we can see them as simple values. Most of the operations perform calculation just on the 
\emph{current} value of the stream. However, the operation \kvd{fby} and \kvd{prev} are different.
They require additional \emph{context} which provides past values of variables
(for \kvd{prev}) and information about the current location in the stream (for \kvd{fby}). 

The semantics of Lucid-like languages can be captured using a number of mathematical 
structures. Wadge \cite{app-lucid-monads} originally proposed to use monads, while Uustalu and 
Vene later used comonads \cite{app-dataflow-essence}. In Chapter~\ref{ch:flat}, we extend
the latter approach. However, the present chapter presents a sketch of a data-flow semantics
defined directly on streams.

In the introductory example with array access patterns, we used coeffects to track the range
of values accessed. In this section, we look at a simpler example -- we only consider the
\kvd{prev} operation and track the maximal number of \emph{past values} needed. This is an 
important information for efficient implementation of data-flow languages. When we can guarantee
that at most $x$ past values are accessed, the values can be stored in a pre-allocated buffer
rather than using \eg~on-demand computed lazy streams.


% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}
  {x : \tau \in \Gamma}
  {\coctx{\Gamma}{\aclrd{ 0 }} \vdash x : \tau }
\end{equation*}
\begin{equation*}
\tyrule{prev}
  {\coctx{\Gamma}{ \aclrd{n} } \vdash e : \tau}
  {\coctx{\Gamma}{ \aclrd{n}+1} \vdash \kvd{prev}~e : \tau}
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{n'}} \vdash e : \tau }
  {\coctx{\Gamma}{\aclrd{n}} \vdash e : \tau }\quad\quad(\aclrd{n'} \leq \aclrd{n})
\end{equation*}
\begin{equation*}
\tyrule{app}
  {\coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{p}} \tau_2 &
   \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }
  {\coctx{\Gamma}{\textnormal{max}(\aclrd{m}, \aclrd{n} + \aclrd{p})} \vdash e_1~e_2 : \tau_2}
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 &
    \coctx{\Gamma, x:\tau_1}{\aclrd{n}} \vdash e_2 : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}+\aclrd{m}} \vdash \kvd{let}~x=e_1~\kvd{in}~e_2 : \tau_2 }
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x:\tau_1}{\aclrd{n}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{n}} \vdash \lambda x.e : \tau_1 \xrightarrow{\aclrd{n}} \tau_2 }
\end{equation*}

\caption{Coeffect rules for tracking context-usage in data-flow language}
\label{fig:applications-flat-dataflow}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.}
A type system that tracks the maximal number of accessed past values annotates the context with
a single integer. The current value is always present, so $0$ means that no past values are 
needed, but the current value is still available. The typing rules of the system are shown
in Figure~\ref{fig:applications-flat-dataflow}.

Variable access (\emph{var}) annotates the context with $0$; sub-coeffecting (\emph{sub}) allows
us to require more values than is actually needed. Primitive context-requirements are introduced
in (\emph{prev}), which increments the number of past values by one. Thus, for example, 
$\kvd{prev}~(\kvd{prev}~x)$ requires 2 past values.

The (\emph{app}) rule follows the same intuition as for liveness. It combines \emph{sequential} 
and \emph{pointwise} composition of semantic functions. In case of data-flow, the operations
combine annotations using $+$ and \emph{max} operations:
%
\begin{equation*}
\begin{array}{lll}
f : \tau_1 \xrightarrow{\aclrd{m}} \tau_2 \qquad\qquad&
g : \tau_2 \xrightarrow{\aclrd{n}} \tau_3 \qquad\qquad&
g \circ f : \tau_1 \xrightarrow{\aclrd{m} + \aclrd{n}} \tau_3 \qquad\qquad
\\
f : \tau_1 \xrightarrow{\aclrd{m}} \tau_2 \qquad\qquad&
h : \tau_1 \xrightarrow{\aclrd{n}} \tau_3 \qquad\qquad&
\langle f, h \rangle : \tau_1 \xrightarrow{\textnormal{max}(\aclrd{m}, \aclrd{s})} \tau_2 \times \tau_3 \qquad
\end{array}
\end{equation*}
%
Sequential composition adds the annotations. The function $f$ needs $\aclrd{m}$ past values to 
produce a single $\tau_2$ value. To produce two $\tau_2$ values, we thus need $\aclrd{m}+1$ past
values of $\tau_1$; to produce three $\tau_2$ values, we need $\aclrd{m}+2$ past values of $\tau_1$,
and so on. To produce $\ident{n}$ past values that are required as the input of $g$, we need
$\aclrd{m}+\aclrd{n}$ past values of type $\tau_1$. The pointwise composition is simpler. It uses
the same stream to evaluate functions requiring $\aclrd{m}$ and $\aclrd{n}$ past values, and so it
needs maximum of the two at most.

In summary, function application (\emph{app}) requires maximum of the values needed to evaluate 
$e_1$ and the number of values needed to evaluate the argument $e_2$, sequentially composed with
the function. 

In function abstraction (\emph{abs}), the requirements of the body are duplicated on the declaration-site
and the call-site as in liveness analysis. If the body requires $\aclrd{n}$ past values, it may access
$\aclrd{n}$ values of any variables -- including those available in $\Gamma$, as well as the parameter
$x$. Finally, the (\emph{let}) rule simply adds the two requirements. This corresponds to the sequential
composition operation, but it is also a rule that we obtain by treating let-binding as a syntactic 
sugar for $(\lambda x.e_2)~e_1$.

% --------------------------------------------------------------------------------------------------

\paragraph{Example.} 
As with the liveness example, the application rule might require more explanation. The following 
example is somewhat arbitrary, but it demonstrates the rule well. We assume that \ident{counter} 
is a stream of positive integers (starting from zero) and \ident{tick} flips between $0$ and $1$.
The full typing derivation is shown in Appendix~?:
%
\begin{equation*}
\begin{array}{l}
(\,   \kvd{if}~~(\kvd{prev}~\ident{tick})=0\\[-0.25em]
\,\,\, \kvd{then}~(\lambda x \rightarrow \kvd{prev}~x)\\[-0.25em]
\,\,\, \kvd{else}~(\lambda x \rightarrow x) \,)\qquad(\kvd{prev}~\ident{counter})
\end{array}
\end{equation*}
%
The left-hand side of the application returns a function depending on the \emph{previous}
value of \ident{tick}. The resulting stream of functions flips between a function returning
a current value and a function returning the previous value. If the current \ident{tick} is 0, and
the function is applied to a stream $\langle{\ldots,4,3,2,1}\rangle$ 
(where $1$ is the current value), it yields the stream $\langle{\ldots,4,4,2,2}\rangle$. 

To obtain the function, we need one past value from the context (for $\kvd{prev}~\ident{tick}$). The 
returned function needs either none or one past value (thus a subtyping rule is required to type 
it as requiring one past value). So, the annotations for (\emph{app}) are $\aclrd{m}=1, \aclrd{p}=1$.
The function is called with $\kvd{prev}~\ident{counter}$ as an argument, meaning that the result
is either the first or second past element. Given 
$\ident{counter}\hspace{-0.1em}=\hspace{-0.1em}\langle{\ldots,5,4,3,2,1}\rangle$, the argument 
is $\langle{\ldots,5,4,3,2}\rangle$ and so the overall result is a stream $\langle{\ldots,5,5,3,3}\rangle$.
From the argument, we get the requirement $\aclrd{n}=1$.

Using the (\emph{app}) rule, we get that the overall number of past elements needed is
$\mathit{max}(1, 1+1) = 2$. This should match the intuition about the code -- when the first function
is applied to the argument, the computation will first access $\kvd{prev}~\ident{tick}$ (using one
past value) and then $\kvd{prev}~(\kvd{prev}~\ident{counter}))$ (using two past values).

%---------------------------------------------------------------------------------------------------

\begin{figure}
\begin{equation}
\tag{\emph{var}}
\hspace{-1em}
\sem{\coctx{\Gamma}{\aclrd{0}} \vdash x_i : \tau_i} = \lambda \langle(x_0, \ldots, x_n)\rangle \rightarrow x_i
\end{equation}
\vspace{-1.0em}
\begin{equation}
\tag{\emph{prev}}
\hspace{-1.5em}
\begin{array}{l}
\sem{\coctx{\Gamma}{\aclrd{n}+1} \vdash \kvd{prev}~e : \tau} = \lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}+1} \rangle \rightarrow\\[-0.1em]
  \qquad\sem{ \coctx{\Gamma}{ \aclrd{n} } \vdash e : \tau }~\langle \mathbf{v}_1, \ldots, \mathbf{v}_{ \aclrd{n}+1 }\rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation}
\tag{\emph{sub}}
\hspace{-1.5em}
\begin{array}{l}
\sem{\coctx{\Gamma}{\aclrd{n}} \vdash e : \tau} = \lambda \langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}} \rangle \rightarrow\\[-0.1em]
  \qquad\sem{ \coctx{\Gamma}{ \aclrd{n'} } \vdash e : \tau }~\langle \mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{n'} }\rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation}
\tag{\emph{abs}}
\hspace{-1.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\aclrd{n}} \vdash \lambda y. e : \tau_1 \xrightarrow{\aclrd{n}} \tau_2 } = 
    \lambda \langle \mathbf{v}_0, \ldots \mathbf{v}_{\aclrd{n}} \rangle \rightarrow\\[-0.1em]
  \qquad\lambda (y, g) \rightarrow \sem{ \coctx{\Gamma,y:\tau_1}{\aclrd{n}} \vdash e : \tau_2 
    }~\langle (\mathbf{v}_0, y_0), \ldots, (\mathbf{v}_{ \aclrd{n}  }, y_{ \aclrd{n} } ) \rangle
\end{array}
\end{equation}
\vspace{-0.5em}
\begin{equation*}
\tag{\emph{app}}
\hspace{-1.5em}
\begin{array}{l}
  \sem{\coctx{\Gamma}{\textnormal{max}(\aclrd{m}, \aclrd{n}+\aclrd{p})} \vdash e_1~e_2 : \tau_2 } = 
    \lambda (\mathbf{v}_0, \ldots, \mathbf{v}_{ \textnormal{max}(\aclrd{m}, \aclrd{n}+\aclrd{p}) } ) \rightarrow \\[-0.1em]
  \qquad\kvd{let}~g=\sem{ \coctx{\Gamma}{\aclrd{m}} \vdash e_1 : \tau_1 \xrightarrow{\aclrd{p}} \tau_2 
    }~(\mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{m} })\\[-0.1em]
  \qquad\kvd{in}~g~(~\sem{ \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }~(\mathbf{v}_0, \ldots, \mathbf{v}_{ \aclrd{n} }),\ldots, \\[-0.1em]
  \qquad\qquad\;~\sem{ \coctx{\Gamma}{\aclrd{n}} \vdash e_2 : \tau_1 }~(\mathbf{v}_{ \aclrd{p} }, \ldots, \mathbf{v}_{ \aclrd{n}+\aclrd{p} })~)
\end{array}
\end{equation*}

\caption{Semantics of a simple data-flow language}
\label{fig:applications-flat-dfsem}
\end{figure}

%---------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
The sample language discussed in this section is a \emph{causal} data-flow language. This means that
a computation can access \emph{past} values of the stream (but not future values). In the semantics, 
we again need richer structure over the input.

Uustalu and Vene \cite{comonads-notions} model causal data-flow computations using a non-empty list
$\ident{NeList}~\tau = \tau \times (\ident{NeList}~\tau + 1)$ over the input. A function $\tau_1 \rightarrow \tau_2$
is thus modelled as $\ident{NeList}~\tau_1 \rightarrow \tau_2$. This model is difficult to implement
efficiently, as it creates unbounded lists of past elements.

The coeffect system tracks maximal number of past values and so we can define the semantics using
a list of fixed length. As with liveness, this is a data structure \emph{indexed} by the coeffect
annotation. We write $\tau^{\aclrd{n}}$ for a list containing $\aclrd{n}$ elements (which can be 
also viewed as an $\aclrd{n}$-element product $\tau \times \ldots \times \tau$). 

As with the previous examples, our semantics interprets a judgement using a (semantic) function;
functions in the language are modelled as functions taking a list of inputs:
%
\begin{equation*}
\begin{array}{rcl}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \aclrd{n} } \vdash e : \tau} 
  &:& (\tau_1 \times \ldots \times \tau_n)^{\aclrd{n}+1} \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\aclrd{n}} \tau_2} &:& \tau_1^{\aclrd{n}+1} \rightarrow \tau_2
\end{array}
\end{equation*}
%
Note that the semantics requires one more value than is the number of past values. This is because 
the first value is the current value and has to be always available, even when the annotation is
zero as in (\emph{var}).

The rules defining the semantics are shown in Figure~\ref{fig:applications-flat-dfsem}. The
semantics of the context is a \emph{list of pairs}. To make the rules easier to follow, we write
$\langle \mathbf{v}_1, \ldots, \mathbf{v}_n \rangle$ for an $n$-element list containing pairs.
Pairs that model the entire context such as $\mathbf{v}_1$ are written in bold. When we access
individual variables, we write $\mathbf{v} = (x_1, \ldots, x_m)$ where $x_i$ denote individual
variables of the context.

In (\emph{var}), the context is a singleton-list containing a product of variables, from which
we project the right one. In (\emph{prev}) and (\emph{sub}), we drop some of the elements from 
the history (from the front and end, respectively) and then evaluate the original expression.

Lambda abstractions (\emph{abs}) receives two lists of the same size -- one containing values of
the variables from the declaration-site $\langle \mathbf{v}_0, \ldots, \mathbf{v}_{\aclrd{n}} \rangle$ and one
containing the argument provided by the call-site $\langle y_0, \ldots, v_{\aclrd{n}} \rangle$.
The semantics applies the well-known \emph{zip} operation on the lists and passes the result to the
body.

Finally, application (\emph{abs}) uses the input context in two ways, which gives rise to the
two requirements combined using \emph{max}. First, it evaluates the expression $e_1$ which is 
called with the past $\aclrd{m}$ values. The resulting function $g$ is then sequentially composed
with the semantics of $e_2$. To call the function, we need to evaluate $e_2$ repeatedly -- namely,
$\aclrd{p}+1$ times, which results in the overall requirement for $\aclrd{n}+\aclrd{p}$ past values.

\paragraph{Summary.}
The most interesting point about the data-flow example is that it is remarkably similar to our
earlier liveness example. In the type system, abstraction (\emph{abs}) duplicates the context
requirements and application (\emph{abs}) arises from sequential and pointwise composition.
We capture this striking similarity in Chapter~\ref{ch:flat}. Before doing that, we look at one
more example and then explore the \emph{structural} class of systems.

% --------------------------------------------------------------------------------------------------

\subsection{Permissions and safe locking}
In the implicit parameters and data-flow examples, the context provides additional resources or 
values that may be accessed at runtime. However, it may also track \emph{permissions} or 
\emph{capabilities} to perform some operation. Liveness can be seen as a trivial example -- when
the context is live, it contains a permission to access variables. In this section, we briefly
consider a system for safe locking of Flanagan and Abadi \cite{app-safe-locking} as one, more
advanced example. Calculus of capabilities of Cray et al. \cite{app-capabilities} is discussed 
later in Section~\ref{sec:applications-active-ccc}.

\paragraph{Safe locking.}
The system for safe locking prevents race conditions (by only allowing access to mutable state 
under a lock) and avoids deadlocks (by imposing strict partial order on locks). The following 
program uses a mutable state under a lock:
%
\begin{equation*}
\begin{array}{l}
\kvd{newlock}~l:\rho~\kvd{in}\\[-0.25em]
\kvd{let}~\ident{state}~=~\ident{ref}_\rho~10~\kvd{in}\\[-0.25em]
\kvd{sync}~l~(!\ident{state})
\end{array}
\end{equation*}
%
The declaration \kvd{newlock} creates a lock $l$ protecting memory region $\rho$. We can than
allocate mutable variables in that memory region (second line). An access to mutable variable
is only allowed in scope that is protected by a lock. This is done using the \kvd{sync} keyword,
which locks a lock and evaluates an expression in a context that contains permission to access
memory region of the lock ($\rho$ in the above example).

The type system for safe locking associates a list of acquired locks with the context. 
Interestingly, the original presentation of the system uses a coeffect-style judgements
of a form $\Gamma; p \vdash e : \tau$ where $p$ is a list of accessible regions (protected by
an acquired lock). Using our notation, the rule for \kvd{sync} looks as follows:
%
\begin{equation*}
\tyrule{sync}
  { \coctx{\Gamma}{\aclrd{p}} \vdash e_1 : m& 
    \coctx{\Gamma}{\aclrd{p} \cup \{m\} } \vdash e_2 : \tau }
  { \coctx{\Gamma}{\aclrd{p}} \vdash \kvd{sync}~e_1~e_2 : \tau }
\end{equation*}
%
The rule requires that $e_1$ yields a value of a singleton type $m$. The type is added as an
indicator of the locked region to the context $\aclrd{p}\cup \{m\}$ which is then used to evaluate
the expression $e_2$.

\paragraph{Summary.}
Despite attaching annotations to the variable context, the system for safe locking uses 
effect-style lambda abstraction. Lambda abstraction associates all requirements with the 
call-site -- a lambda function created under a lock cannot access protected memory available at 
the time of creation. It will be executed later and can only access the memory available then.
This suggests that safe locking is perhaps better seen as an effect system. 

Another interesting aspect is the extension to avoid deadlocks. In that case, the type system
needs to reject programs that acquire locks in an invalid order. One way to model this is to 
replace $\aclrd{p} \cup \{m\}$ with a \emph{partial} operation $\aclrd{p} \uplus \{m\}$ which
is only defined when the lock $m$ can be added to the set $\aclrd{p}$. Supporting partial 
operations on coeffect annotations is an interesting extension which we discuss in Section~?.
The extension also lets us capture systems with effect-style lambda abstraction such as safe
locking.




% ==================================================================================================
%	                                                                      
% 	  ###    #                           #                           ##   
% 	 #   #   #                           #                            #   
% 	 #      ####   # ##   #   #   ###   ####   #   #  # ##    ###     #   
% 	  ###    #     ##  #  #   #  #   #   #     #   #  ##  #      #    #   
% 	     #   #     #      #   #  #       #     #   #  #       ####    #   
% 	 #   #   #  #  #      #  ##  #   #   #  #  #  ##  #      #   #    #   
% 	  ###     ##   #       ## #   ###     ##    ## #  #       ####   ###  
%	                                                                      
% ==================================================================================================

\section{Structural coeffect systems}
\label{sec:applications-structural}

In structural coeffect systems, the additional information are associated with individual variables.
This is very often information about how the variables are used, or, in which contexts they are 
used. 

In Chapter~\ref{ch:intro}, we introduced the idea using an example that tracks array access patterns.  
Each variable is annotated with a range specifying which elements of the corresponding array 
may be accessed. In this section, we look at a number of examples. We first consider an example
inspired by linear logic. Then we revisit liveness and data-flow, for which the structural system 
provides a more precise analysis. Finally, we look at a number of other practical uses including 
security, tainting and provenance tracking.

%---------------------------------------------------------------------------------------------------

\subsection{Liveness analysis revisited}
\label{sec:applications-struct-live}

The flat system for liveness analysis presented in Section~\ref{sec:applications-flat-live} is 
interesting from a theoretical perspective, but it is not practically useful. In this section, we
revisit the problem and define a structural system that tracks liveness per-variable.

\paragraph{Structural liveness.} 
Recall two examples discussed earlier where the flat liveness analysis marked the whole context
as (syntactically) live, despite the fact part of it was (semantically) dead:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{constant} = \lambda y \rightarrow \lambda x \rightarrow y\\
\kvd{let}~\ident{answer} = (\lambda x \rightarrow x)~42
\end{array}
\end{equation*}
%
In the first case, the variable $x$ is dead, but was marked as live. In the second example, the
declaration-site of the \ident{answer} value is dead, but was marked as live. This is because in 
both of the expressions, \emph{some} variable is accessed. However, the (\emph{abs}) rule of flat
liveness has no way of determining \emph{which} variables are used by the body -- and, in particular,
whether the accessed variable is the \emph{bound} variable or some of the \emph{free} variables.

As discussed earlier, we can resolve this by attaching a \emph{vector} of liveness annotations to
a \emph{vector} of variables. In the first example, the available variables are $y$ and $x$, so
the variable context $\Gamma$ is a vector $\langle y\!:\!\tau, x\!:\!\tau \rangle$. Only the variable $y$
is used and so the annotated context is: $\coctx{y\!:\!\tau, x\!:\!\tau}{ \alift{\cclrd{\ident{L}}, \cclrd{\ident{D}}} }$.
When writing the contexts, we omit angle brackets around variables, but it should still be viewed
as a vector. There are two important points:

\begin{itemize}
\item The fact that variables are now a vector means that we cannot freely re-order them. This
  guarantees that $\coctx{x\!:\!\tau, y\!:\!\tau}{\alift{\cclrd{\ident{L}}, \cclrd{\ident{D}}}}$
  can not be confused with $\coctx{y\!:\!\tau, x\!:\!\tau}{\alift{\cclrd{\ident{L}}, \cclrd{\ident{D}}}}$.
  We need to define the type system in a way that is similar to sub-structural systems 
  (discussed in Section~\ref{sec:path-logic}) which provide explicit rules for manipulating
  the context. 

\item We choose to attach a vector of annotations to a vector of variables, rather than attaching
  individual annotations to individual variables. This lets us unify and combine flat and 
  structural systems as discussed in Chapter~\ref{ch:unified}, but the alternative is briefly
  explored in Section~\ref{sec:conclusions-meta}.
\end{itemize}

\paragraph{Type system.}
The structural system for liveness uses the same two-point lattice of annotations
$\mathcal{L}=\{ \ident{L}, \ident{D} \}$ that was used by the flat system. We also use the
$\sqcup, \sqcap$ and $\sqsubseteq$ operators that are defined in Figure~\ref{fig:applications-flat-livealg}.

The rules of the system are split into two groups. Figure~\ref{fig:applications-struct-live} (a) shows 
the standard syntax-driven rules plus sub-coeffecting. In (\emph{var}), the context contains just the 
single accessed variable, which is annotated as live. Other variables can be introduced using weakening. 
A constant (\emph{const}) is accessed in an empty context, which also carries no annotations. The
sub-coeffecting rule (\emph{sub}) uses a point-wise extension of the $\sqsubseteq$ relation over two
vectors as defined in Section~\ref{sec:applications-strucutre-vec}.

In the (\emph{abs}) rule, the variable context of the body $\Gamma, x\!:\!\tau_1$ is annotated with
a vector $\mathbf{\aclrd{r}}\cons\alift{\cclrd{s}}$, where the vector $\mathbf{\aclrd{r}}$ corresponds
to $\Gamma$ and the singleton annotation $\cclrd{s}$ corresponds to the variable $x$. Thus, the
function is annotated with $\cclrd{s}$. Note that the free-variable context is annotated with vectors,
but functions take only a single input and so are annotated with primitive annotations.

The (\emph{app}) rule is similar to function applications in flat systems, but there is an important
difference. In structural systems, the two sub-expressions have separate variable contexts
$\Gamma_1$ and $\Gamma_2$. Therefore, the composed expression just concatenates the variables
and their corresponding annotations. (We can still use the same variable in both sub-expressions
thanks to the structural contraction rule.) 

The context $\Gamma_1$ is used to evaluate $e_1$ and is thus annotated with $\aclrd{\mathbf{r}}$. 
The annotation for $\Gamma_2$ is more interesting. It is a result of sequential composition of two
semantic functions -- the first one takes the (multi-variable) context $\Gamma_2$ and evaluates 
$e_2$; the second takes the result of type $\tau_1$ and passes it to the function $\tau_1 \xrightarrow{\cclrd{t}} \tau_2$.
The composition is defined as follows:
%
\begin{equation*}
g : \tau_1 \times \ldots \times \tau_n \xrightarrow{\aclrd{\mathbf{s}}} \sigma
\qquad
f : \sigma \xrightarrow{\cclrd{t}} \tau
\qquad
f \circ g : \tau_1 \times \ldots \times \tau_n \xrightarrow{\cclrd{t} \sqcup \aclrd{\mathbf{s}}} \tau
\end{equation*}
%
This definition is only for illustration and is revised in Chapter~\ref{ch:structural}. The function
$g$ takes a product of multiple variables (and is annotated with a vector). The function $f$ takes
just a single value and is annotated with the scalar. As in the flat system, sequential composition
is modelled using $\sqcup$ -- but here, we use a scalar-vector extension of the operation. Finally,
the (\emph{let}) rule follows similar reasoning (and also corresponds to the typing of $(\lambda x.e_2)~e_1$.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
{\small a.) Ordinary, syntax-driven rules with sub-coeffecting}
\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{\ident L}}} \vdash x : \tau} 
\end{equation*}
\begin{equation*}
\tyrule{const}
  {c:\tau \in \Delta}
  {\coctx{()}{\alift{}} \vdash c : \tau} 
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{\textbf{r'}}} \vdash e : \tau}~\aclrd{\textbf{r}} \sqsubseteq \aclrd{\textbf{r'}}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda x . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2} 
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad 
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \sqcup \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} 
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma_1, x \!:\! \tau_1}{\aclrd{\textbf{r}} \times \langle{\cclrd{t}}\rangle} \vdash e_1 : \tau_2 \quad 
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \times (\cclrd{t} \sqcup \aclrd{\textbf{s}})} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau_2}
\end{equation*}
\vspace{0.5em}

{\small b.) Structural rules for context manipulation}
\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{\ident{D}} }} \vdash e : \sigma} 
\end{equation*}
\begin{equation*}
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\tau',y\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,y\!:\!\tau,x\!:\!\tau',\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
\quad
\begin{array}{l}
\slift{\Gamma_1} = \slift{\aclrd{\textbf{r}}}\\[-0.25em]
\slift{\Gamma_2} = \slift{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}\sqcap\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
~
\begin{array}{l}
\slift{\Gamma_1} = \slift{\aclrd{\textbf{r}}}\\[-0.25em]
\slift{\Gamma_2} = \slift{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}

\caption{Structural coeffect liveness analysis}
\label{fig:applications-struct-live}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Structural typing rules.}
The structural typing rules are shown in Figure~\ref{fig:applications-struct-live} (b). They mirror
the rules know from sub-structural type systems (Section~\ref{sec:path-logic}). Weakening (\emph{weak})
extends the context with a single unused variable $x$ and adds the $\ident{D}$ annotation to the
vector of coeffects.

The variable is always added to the end as in the (\emph{abs}) rule. However, the exchange rule 
(\emph{exch}) lets us arbitrarily reorder variables. It flips the variables $x$ and $x'$ and their
corresponding coeffect annotations in the vector. This is done by requiring that the lengths of the
remaining, unchanged, parts of the vectors match.

Finally, contraction (\emph{contr}) makes it possible to use a single variable multiple times.
Given a judgement that contains variables $y$ and $z$, we can derive a judgement for an expression
where both $z$ and $y$ are replaced by a single variable $x$. Their annotations $\cclrd{s}, \cclrd{t}$
are combined into $\cclrd{s} \sqcap \cclrd{t}$, which means that $x$ is live if either $z$ or $y$
were live in the original expression.

\paragraph{Example.} To demonstrate how the system works, we consider the expression
$(\lambda x \rightarrow v)~y$. This is similar to an example where flat liveness mistakenly marks
the entire context as live. Despite the fact that the variable $y$ is accessed (syntactically), it
is not live -- because the function that takes it as an argument always returns $v$.

The typing derivation for the body uses (\emph{var}) and (\emph{abs}). However, we also need (\emph{weak})
to add the unused variable $x$ to the context:
%
\begin{equation*}
\tyrule{weak}
{ \tyruler{var}
    {}
    { \coctx{v\!:\!\tau}{\alift{ \cclrd{\ident{L}} }} \vdash v : \tau } }
{ \tyruler{abs}
    { \coctx{v\!:\!\tau, x\!:\!\tau}{\alift{ \cclrd{\ident{L}},\cclrd{\ident{D}} }} \vdash v : \tau }
    { \coctx{v\!:\!\tau}{\alift{ \cclrd{\ident{L}} }} \vdash (\lambda x \rightarrow v) : \tau \xrightarrow{\cclrd{\ident{D}}} \tau }}
\end{equation*}
%
The interesting part is the use of the (\emph{app}) rule in the next step. Although the variable $y$ is live in the expression $y$,
it is marked as dead in the overall expression, because the function is annotated with $\ident{\cclrd{D}}$:
%
\begin{equation*}
\hspace{-2em}
\tyrule{app}
  {
    \begin{array}{l}
    \vspace{-1.2em}
    \coctx{v\!:\!\tau}{\alift{ \cclrd{\ident{L}} }} \vdash (\lambda x \rightarrow v) : \tau \xrightarrow{\cclrd{\ident{D}}} \tau 
    \end{array} &
    \tyruler{var}{}{\coctx{y\!:\!\tau}{\alift{ \cclrd{\ident{L}} }} \vdash y : \tau}
  }
  { 
  \inference
  	{ \coctx{v\!:\!\tau, y\!:\!\tau}{\alift{ \cclrd{\ident{L}} } \cons\, ({ \cclrd{\ident{D}} \sqcup \alift{\cclrd{\ident{L}}} })} 
  	     \vdash (\lambda x \rightarrow v)~y : \tau }
  	{ \coctx{v\!:\!\tau, y\!:\!\tau}{\alift{ \cclrd{\ident{L}}, \cclrd{\ident{D}} }} \vdash (\lambda x \rightarrow v)~y : \tau }  	
  }
\end{equation*}
%
The application is written in two steps -- the first one directly applies the (\emph{app}) rule
and the second one simplifies the coeffect annotation. The key part is the use of the scalar-vector 
operator $\cclrd{\ident{D}} \sqcup \alift{\cclrd{\ident{L}}}$. Using the definition of the scalar-vector
extension, this equals $\alift{\cclrd{\ident{D}} \sqcup \cclrd{\ident{L}}}$ which is
$\alift{\cclrd{\ident{D}}}$.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
{\small a.) Semantics of ordinary expressions}
\begin{equation*}
\tag{\emph{var}}
\sem{\coctx{x \!:\! \tau}{\alift{\cclrd{\ident L}}} \vdash x : \tau} = \lambda(x) \rightarrow x
\end{equation*}
\vspace{-1.5em}
\begin{equation*}
\tag{\emph{const}}
\sem{\coctx{()}{\alift{}} \vdash c : \tau} = \lambda () \rightarrow \delta(c)
\end{equation*}
\vspace{-1.5em}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{abs}}
\begin{array}{l}
\sem{\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda y . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2} = \lambda \textbf{v} \rightarrow\\[-0.25em]
\qquad\lambda y \rightarrow \sem{\coctx{\Gamma, y \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}~(\textbf{v}, y)
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{app-1}}
\begin{array}{l}
\sem{ \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{\ident{L}} \sqcup \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} = 
  \lambda (\mathbf{v_1}, \mathbf{v_2}) \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g = \sem{ \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\ident{L}}} \tau_2 }~\mathbf{v_1}\\[-0.25em]
  \qquad\kvd{in}~g~(\sem{ \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1 }~\mathbf{v_2})
\end{array}
\end{equation*}
\vspace{-1.0em}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{app-2}}
\begin{array}{l}
\sem{ \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{\ident{D}} \sqcup \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} = 
  \lambda (\mathbf{v_1}, \mathbf{v_2}) \rightarrow \\[-0.25em]
  \qquad\kvd{let}~g = \sem{ \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{\ident{D}}} \tau_2 }~\mathbf{v_1}~
  \kvd{in}~g~()
\end{array}
\end{equation*}
\vspace{0.5em}

{\small b.) Semantics of structural context manipulation}
\begin{equation*}
\tag{\emph{weak}}
\sem{\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{\ident{D}} }} \vdash e : \sigma} = 
  \lambda(\textbf{v}, ()) \rightarrow
    \sem{\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}~\textbf{v}
\end{equation*}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{exch}}
\begin{array}{l}
\sem{\coctx{\Gamma_1,y\!:\!\tau,x\!:\!\tau',\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma} = 
  \lambda(\mathbf{v_1}, y, x, \mathbf{v_2}) \rightarrow\\[-0.25em]
\qquad
  \sem{\coctx{\Gamma_1,x\!:\!\tau',y\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}~
  (\mathbf{v_1}, x, y, \mathbf{v_2})
\end{array}
\end{equation*}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{contr-1}}
\begin{array}{l}
\sem{\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{D}}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma} = \lambda(\mathbf{v_1}, (), \mathbf{v_2}) \rightarrow \\[-0.25em]
\qquad\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{D}},\cclrd{\ident{D}}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma} ~(\mathbf{v_1}, (), (), \mathbf{v_2})
\end{array}
\end{equation*}
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{contr-2}}
\begin{array}{l}
\sem{\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{L}}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma} = \lambda(\mathbf{v_1}, x, \mathbf{v_2}) \rightarrow \\[-0.25em]
\quad\begin{cases}
~~\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{L}},\cclrd{\ident{L}}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}~(\mathbf{v_1}, x, x, \mathbf{v_2})\\[-0.25em]
~~\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{D}},\cclrd{\ident{L}}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}~(\mathbf{v_1}, (), x, \mathbf{v_2})\\[-0.25em]
~~\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{\ident{L}},\cclrd{\ident{D}}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}~(\mathbf{v_1}, x, (), \mathbf{v_2})
\end{cases}
\end{array}
\end{equation*}
\vspace{-0.5em}
\caption{Semantics of structural liveness}
\label{fig:applications-struct-livesem}
\end{figure}
\vspace{-0.5em}

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
When defining the semantics of flat liveness calculus, we used an indexed form of the option type
$1 + \tau$ (which is $1$ for dead contexts and $\tau$ for live contexts). In the semantics of 
expressions, the type wrapped the entire context, \ie~$1+(\tau_1 \times \ldots \times \tau_n)$.
In the structural version, the semantics wraps individual elements of the free-variable context
pair: $(1+\tau_1) \times \ldots \times (1+ \tau_n)$. For each variable, the type is indexed by 
the corresponding annotation. More formally:
%
\begin{equation*}
\begin{array}{r}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau} 
  ~:~ (\tau'_1 \times \ldots \times \tau'_n) \rightarrow \tau\\[0.5em]
\textnormal{where}~\tau'_i = \begin{cases}
\tau_i & (\cclrd{r_i} = \cclrd{\ident{L}})\\
1      & (\cclrd{r_i} = \cclrd{\ident{D}})
\end{cases}
\end{array}
\end{equation*}
%
Note that the product of the free variables is not an ordinary tuple of our language, but a special
construction. This follows from the asymmetry of $\lambda$-calculus, as discussed in 
Section~\ref{sec:applications-strucutre-vec}. Functions take just a single input and so they are
interpreted in the same way as in flat calculus:
%
\begin{equation*}
\sem{\tau_1 \xrightarrow{\aclrd{\ident{L}}} \tau_2} = \tau_1 \rightarrow \tau_2 \qquad\qquad
\sem{\tau_1 \xrightarrow{\aclrd{\ident{D}}} \tau_2} = 1 \rightarrow \tau_2
\end{equation*}
%
The rules that define the semantics are shown in Figure~\ref{fig:applications-struct-livesem}.
To make the definition simpler, we are somewhat vague when working with products. We write 
variables of product type such as $\mathbf{v}$ in bold-face and individual values like $x$ in 
normal face. We freely re-associate products and so $(\mathbf{v}, x)$ should not be seen as a
nested product, but simply a product with a number of variables represented as another product
$\mathbf{v}$ with one more variable $x$ at the end. We shall be more precise in Chapter~\ref{ch:structural}.

In (\emph{var}), the context contains just a single variable and so we do not even need to apply
projection; (\emph{cosnt}) receives no variables and uses global constant lookup function $\delta$.
In (\emph{abs}), we obtain two parts of the context and combine them into $(\mathbf{v}, x)$. This
works the same way regardless of whether the variables are live or dead. For simplicity, we omit
sub-coeffecting, which just turns some of the available values $v_i$ to unit values $()$.

In application, we again need to ``implement'' dead code elimination. When the input parameter
of the function $g$ is live (\emph{app-1}), we first evaluate $e_2$ and then pass the result to
$g$. When the parameter is dead (\emph{app-2}), we do not need to evaluate $e_2$ and so all values
in $\mathbf{v_2}$ can be dead, \ie~$()$.

In the structural rules, (\emph{weak}) receives context containing a dead variable as the last one.
It drops the $()$ value and evaluates the expression in a context $\mathbf{v}$. Exchange (\emph{exch})
simply swaps two variables. In contraction, we either duplicate a dead value (\emph{contr-1}),
or a live value (\emph{contr-2}). In the latter, one of the duplicates may be dead and 
so we need to consider three separate cases.

\paragraph{Summary.}
The structural liveness calculus is a typical example of a system that tracks per-variable 
annotations. In a number of ways, the system is simpler than the flat coeffect calculi. In
lambda abstraction, we simply annotate function with the annotation of a matching variable 
(this rule is the same for all upcoming systems). In application, the \emph{pointwise} composition
is no longer needed, because the sub-expressions use separate contexts. On the other hand, 
we had to add weakening, contraction and exchange rules to let us manipulate the contexts.

The semantics of weakening demonstrates an important point about coeffects that may be quite
confusing. When we read the \emph{typing rule} from top to bottom, weakening adds a variable
to the context. When we read the \emph{semantic rule}, weakening drops a variable value from the 
context! This duality is caused by the fact that coeffects talk about context -- they describe
how to build the context required by the sub-expressions and so the semantics implements 
transformation from the context in the (typing) conclusion to the (typing) assumption.

The structural systems discussed in the upcoming sections are remarkably similar to the one
shown here. We discuss two more examples in details to explore the design space, but we shall
omit details that are the shared with the system in this section.

%---------------------------------------------------------------------------------------------------

\subsection{Bounded variable use}
\label{sec:applications-struct-bll}

Liveness analysis checks whether a variable is used or unused. With structural coeffects, we can go
further and track how many times is the variable accessed. Girard et al. \cite{logic-bounded} coined
this idea as \emph{bounded linear logic} and use it to restrict well-typed programs to 
polynomial-time algorithms. We first introduce the system in our, coeffect, style and then 
relate it with the original formulation.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
{\small a.) Ordinary, syntax-driven rules with sub-coeffecting}
\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{1}}} \vdash x : \tau} 
\end{equation*}
\begin{equation*}
\tyrule{sub}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{\aclrd{\textbf{r'}}} \vdash e : \tau}~\aclrd{\textbf{r}} \leq \aclrd{\textbf{r'}}
\end{equation*}
\begin{equation*}
\tyrule{abs}
  {\coctx{\Gamma, x \!:\! \tau_1}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}}} \vdash e : \tau_2}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash \lambda x . e : \tau_1 \xrightarrow{\cclrd{s}} \tau_2} 
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad 
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \ast \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} 
\end{equation*}
\begin{equation*}
\tyrule{let}
  { \coctx{\Gamma_1, x \!:\! \tau_1}{\aclrd{\textbf{r}} \times \langle{\cclrd{t}}\rangle} \vdash e_1 : \tau_2 \quad 
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  {\coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \times (\cclrd{t} \ast \aclrd{\textbf{s}})} \vdash \kvd{let}~x=e_2~\kvd{in}~e_1 : \tau_2}
\end{equation*}
\vspace{0.5em}

{\small b.) Structural rules for context manipulation}
\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{0} }} \vdash e : \sigma} 
\end{equation*}
\begin{equation*}
\tyrule{exch}
  {\coctx{\Gamma_1,x\!:\!\tau',y\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,y\!:\!\tau,x\!:\!\tau',\Gamma_2}{\aclrd{\textbf{r}} \cons\alift{\cclrd{t},\cclrd{s}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
\quad
\begin{array}{l}
\slift{\Gamma_1} = \slift{\aclrd{\textbf{r}}}\\[-0.25em]
\slift{\Gamma_2} = \slift{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
~
\begin{array}{l}
\slift{\Gamma_1} = \slift{\aclrd{\textbf{r}}}\\[-0.25em]
\slift{\Gamma_2} = \slift{\aclrd{\textbf{s}}}
\end{array}
\end{equation*}

\caption{Structural coeffect bounded reuse analysis}
\label{fig:applications-struct-bll}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Bounded variable use.} 
The system discussed in this section tracks the number of times a variable is accessed in the 
call-by-name evaluation. Although we look at an example that tracks \emph{variable usage}, the same
system could be used to track access to resources that are always passed as a reference (and behave
effectively as call-by-name) and so the system is relevant for call-by-value languages too.
To demonstrate the idea, consider the following term:
%
\begin{equation*}
(\lambda v.x + v + v)~(x+y)
\end{equation*}
%
When evaluated, the body of the function directly accesses $x$ once and then twice indirectly, via
the function argument. Similarly, $y$ is accessed twice indirectly. Thus, the overall expression uses
$x$ three times and $y$ twice.

As discussed in Chapter~\ref{ch:structural}, the system preserves type and coeffect annotations under
the $\beta$-reduction. Reducing the expression in this case gives $x + (x+y) + (x+y)$. This has the 
same bounds as the original expression -- $x$ is used three times and $y$ twice.

\paragraph{Type system.}
The type system in Figure~\ref{fig:applications-struct-bll} annotates contexts with vectors of integers.
The rules have the same structure as those of the system for liveness analysis. The only difference is
how annotations are combined -- here, we use integer multiplication ($\ast$) and addition ($+$).

Variable access (\emph{var}) annotates a variable with $1$, meaning that it has been used once. An
unused variable (\emph{weak}) is annotated with $0$. Multiple occurrences of the same variable are 
introduced by contraction (\emph{contr}), which adds the numbers of the two contracted variables.

As previously, application (\emph{app}) and let binding (\emph{let}) combine two separate contexts.
The second part applies a function that uses its parameter $\cclrd{t}$-times to an argument that uses
variables in $\Gamma_2$ at most $\aclrd{\mathbf{s}}$-times (here, $\aclrd{\mathbf{s}}$ is a vector of
integers with an annotations for each variable in $\Gamma_2$). The sequential composition (modelling
call-by-name) multiplies the uses, meaning that the total number of uses is $(\cclrd{t} \ast \aclrd{\mathbf{s}})$
(where $\ast$ is a multiplication of a vector by a scalar). This models the fact that for each use of
the function parameter, we replicate the variable uses in $e_2$.

Finally, the sub-coeffecting rule (\emph{sub}) safely overapproximates
the number of uses using the pointwise
$\leq$ relation. We can view any variable as being used a greater
number of times than it actually is.

\paragraph{Example.} To type check the expression $(\lambda v.x+v+v)~(x+y)$ discussed earlier, we need
to use abstraction, application, but also the contraction rule. Assuming the type judgement for the body,
abstractions yields:
%
\begin{equation*}
\tyrule{abs}
 { \coctx{x\!:\!\mathbb{Z},v:\mathbb{Z}}{\alift{\cclrd{1},\cclrd{2}}} \vdash x+v+v : \mathbb{Z} }
 { \coctx{x\!:\!\mathbb{Z}}{\alift{\cclrd{1}}} \vdash (\lambda v.x+v+v) : \mathbb{Z} \xrightarrow{\cclrd{2}} \mathbb{Z} }
\end{equation*}
%
To type-check the application, the contexts of $e_1$ and $e_2$ need to contain disjoint variables.
For this reason, we $\alpha$-rename $x$ to $x'$ in the argument $(x+y)$ and later join $x$ and $x'$ using
the contraction rule. Assuming $(x'+y)$ is checked in a context that marks $x'$ and $y$ as used once, the 
application rule yields a judgement that is simplified as follows:
%
\begin{equation*}
\inference
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}
          {\alift{\cclrd{1}} \cons (\cclrd{2} \ast \alift{\cclrd{1},\cclrd{1}}) } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
{\tyrule{contr}
  { \coctx{x\!:\!\mathbb{Z},x'\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{1}, \cclrd{2}, \cclrd{2}} } \vdash (\lambda v.x+v+v)~(x'+y) : \mathbb{Z} }
  { \coctx{x\!:\!\mathbb{Z},y\!:\!\mathbb{Z}}{\alift{\cclrd{3}, \cclrd{2}}} \vdash (\lambda v.x+v+v)~(x+y)  : \mathbb{Z}} }
\end{equation*}
%
The first step performs scalar multiplication, producing the vector
$\alift{\cclrd{1},\cclrd{2},\cclrd{2}}$. In the second step, we use contraction to join variables 
$x$ and $x'$ from the function and argument terms respectively.

% --------------------------------------------------------------------------------------------------

\paragraph{Semantics.}
In the previous examples, we defined the semantics -- somewhat informally -- using a simple 
$\lambda$-calculus language to encode the model. More formally, this could be a Cartesian closed 
category. In that model, we can reuse variables arbitrarily and so it is not
a good fit for modelling bounded reuse. Girard et al. \cite{logic-bounded} model their bounded
linear logic in an (ordinary) linear logic where variables can be used at most once.

Following the same approach, we could model a variable $\tau$, annotated with $\cclrd{r}$ as 
a product containing $\cclrd{r}$ copies of $\tau$, that is $\tau^{\cclrd{r}}$:
%
\begin{equation*}
\begin{array}{r}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau} 
  ~:~ (\tau^{\cclrd{r_1}}_1 \times \ldots \times \tau^{\cclrd{r_n}}_n) \rightarrow \tau\\[0.5em]
\textnormal{where}~\tau^{\cclrd{r_i}}_i = \underbrace{\tau_i \times \ldots \times \tau_i}_{\cclrd{r_i}-\text{times}}
\end{array}
\end{equation*}
%
The functions are interpreted similarly. A function $\tau_1 \xrightarrow{\cclrd{t}} \tau_2$ is modelled
as a function taking $\cclrd{t}$-element product of $\tau_1$ values: $\tau_1^{\cclrd{t}} \rightarrow \tau_2$.

The rules that define the semantics of bounded calculus are mostly the same as (or easy to adapt 
from) the semantic rules of liveness in Figure~\ref{fig:applications-struct-livesem}. The ones that
differ are those that use sequential composition (application and let binding) and the contraction
rule, which represents pointwise composition. 

In the following, we use variable names $\mathbf{v}_i$ for context containing multiple variables (where 
each variable may be available multiple times), \ie~have a type $\tau_1^{\cclrd{r_1}}\times\ldots\times\tau_m^{\cclrd{r_m}}$;
We do not explicitly write the sizes of these vectors (number of variables in a context; number of 
instances of a variable) as these are clear from the coeffect annotations. We assume that $\Gamma_2$ 
contains $n$ variables and that $\aclrd{s}=\alift{\cclrd{s}_1, \ldots, \cclrd{s}_n}$:
%
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{contr}}
\begin{array}{l}
\sem{\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s}+\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma} =\\[-0.25em] 
\qquad  \lambda(\mathbf{v_1}, (x_1, \ldots, x_{\cclrd{s}+\cclrd{t}}), \mathbf{v_2}) \rightarrow \\[-0.25em]
\qquad\qquad\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}\\[-0.25em]
\qquad\qquad\qquad (\mathbf{v_1}, (x_1, \ldots, x_{\cclrd{s}}), (x_{\cclrd{s}+1}, \ldots, x_{\cclrd{s}+\cclrd{t}} ), \mathbf{v_2})
\end{array}
\end{equation*}
%
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{app}}
\begin{array}{l}
\sem{ \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} \ast \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} = \\[-0.25em]
  \qquad\lambda (\mathbf{v_1}, ((x_{1,1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_1}), \ldots, (x_{n,1}, \ldots, x_{n,\cclrd{t}\ast\cclrd{s}_n}) ) \rightarrow \\[-0.25em]
  \qquad\qquad\kvd{let}~g = \sem{ \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 }~\mathbf{v_1}\\[-0.25em]
  \qquad\qquad\kvd{let}~\mathbf{y}_1 = ((x_{1,1}, \ldots, x_{1,\cclrd{s}_1}), \ldots, (x_{n,1}, \ldots, x_{1,\cclrd{s}_n})  )\\[-0.25em]
  \qquad\qquad\kvd{let}~\ldots \\[-0.25em]
  \qquad\qquad\kvd{let}~\mathbf{y}_{ \cclrd{t} } = ((x_{1,(\cclrd{t}-1)\ast\cclrd{s}_1 + 1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_1}), \ldots, \\[-0.25em]
  \hspace{8.2em}                                         (x_{n,(\cclrd{t}-1)\ast\cclrd{s}_n + 1}, \ldots, x_{1,\cclrd{t}\ast\cclrd{s}_n})  )\\[-0.25em]
  \qquad\qquad\kvd{in}~g~(\sem{ \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}~\mathbf{y}_1, \ldots, 
    \sem{ \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}~\mathbf{y}_{\cclrd{t}})
\end{array}
\end{equation*}
%
In the (\emph{contr}) rule, the semantic function is called with $\cclrd{s}+\cclrd{t}$ copies of
a value for the $x$ variable. The values are split between $\cclrd{s}$ and $\cclrd{t}$ separate
copies of variables $y$ and $z$, respectively.

The (\emph{app}) rule is similar in that it needs to split the input variable context. However,
it needs to split values of multiple variables -- in $x_{i,j}$, the index $i$ stands for an
index of the variable while $j$ is an index of one of multiple copies of the value. In the
semantic function, the second
part of the context consists of $n$ variables where the multiplicity of each value is specified 
by the annotation $\cclrd{s}_i$ multiplied by $\cclrd{t}$. The rule needs to evaluate the argument 
$e_2$ $\cclrd{t}$-times and each call requires $\cclrd{s}_i$ copies of the $i^\textnormal{th}$ 
variable. To do this, we create contexts $\mathbf{y}_1$ to $\mathbf{y}_{\cclrd{t}}$, each containing
$\cclrd{s}_i$ copies of the variable (and so we require $\cclrd{s}_i\ast\cclrd{t}$ copies of each 
variable). Note that the contexts are created such that each value is used exactly once.

It is worth noting that the (\emph{var}) rule requires exactly one copy of a variable and so 
the system tracks precisely the number of uses. However, the (\emph{sub}) rule lets us 
ignore additional copies of a value. Thus, permitting (\emph{sub}) rule is only possible if the
underlying model is \emph{affine} rather than \emph{linear}.

\paragraph{Bounded linear logic.}
The system presented in this section differs from bounded linear logic (BLL) \cite{logic-bounded}.
Using the terminology from Section~\ref{sec:path-sem-contextdep}, our system is written in the
\emph{language semantics} style, while BLL is written in the \emph{meta-language} style.

This means that the terms and types of our system are the terms and types of ordinary 
$\lambda$-calculus, with the only difference that functions carry coeffect annotations.
In BLL, the language of types is extended with a type constructor $!_k A$ (where $A$ is
a proposition, corresponding to a type $\tau$ in our system). The type denotes a value
$A$ that can be used at most $k$ times. 

As a result, BLL does not need to attach additional annotation to the variable context 
as a whole. The requirements are attached to individual variables and so our context
$\coctx{\tau_1, ..., \tau_n}{\langle \cclrd{k_1}, ..., \cclrd{k_n}\rangle}$ corresponds
to a BLL assumption $!_{k_1} A_1, ..., !_{k_n} A_n$. 

Using the formulation of bounded logic (and omitting the terms), the weakening and
contraction rules are written as follows:
%
\[
\tyrule{weak}
  {\Gamma \vdash B}
  {\Gamma, !_0 A \vdash B}
\quad
\tyrule{contr}
  {\Gamma, !_n A, !_m A \vdash B}
  {\Gamma, !_{n+m} A \vdash B}
\]
%
The system captures the same idea as the structural coeffect system presented above.
Variable access in bounded linear logic is simply an operation that produces a value
$!_n A$ and so the system further introduces \emph{dereliction} rule which lets us 
treat $!_1 A$ as a value $A$. We further explore difference between \emph{language
semantics} and \emph{meta-language} in Section~\ref{sec:conclusions-meta}.

\paragraph{Summary.}
Comparing the structural coeffect calculus for tracking liveness and for bounded variable reuse
reveals which parts of the systems differ and which parts are shared. In particular, both systems
use the same vector operations ($\times$, $\alift{\cclrd{\textnormal{--}}}$) and also share the
lambda abstraction rule (\emph{abs}). They differ in the primitive values used to annotate used
and unused variables (\cclrd{L}, \cclrd{D} and $1$, $0$, respectively) and in the operators used
for sequential composition and contraction ($\sqcup$, $\sqcap$ and $\ast$, $+$, respectively).
The algebraic structure capturing these operators is developed in Chapter~\ref{ch:structural}.

The brief overview of bounded linear logic shows an alternative approach to tracking properties
related to individual variables -- we could attach annotations to the variables themselves 
rather than attaching a \emph{vector} of annotations to the entire context. Our approach has
two benefits -- it lets you unify flat and structural systems (Chapter~\ref{ch:unified}) and 
it also makes it possible to build composed systems that mix both flat and structural properties.


% --------------------------------------------------------------------------------------------------

\subsection{Data-flow languages revisited}

When discussing data-flow languages in the previous section, we said that the context provides 
past values of variables. In Section~\ref{sec:applications-flat-dataflow}, we tracked this as 
a \emph{flat} property, which gives us a system that keeps the same number of past values for
all variables. However, data-flow can also be adapted to a structural system which keeps the number 
of required past values individually for each variable. Consider the 
following example:
%
\begin{equation*}
\kvd{let}~\ident{offsetZip} = \ident{left} + \kvd{prev}~\ident{right}
\end{equation*}
%
The value \ident{offsetZip} adds values of \ident{left} with previous values of \ident{right}.
To evaluate a current value of the stream, we need the current value of \ident{left} and one past
value of \ident{right}. Flat system is not able to capture this level-of-detail and simply
requires $1$ past values of both streams in the variable context.

Turning a flat data-flow system to a structural data-flow system is a change similar to the one
between flat ans structural liveness. In case of liveness analysis, we included the flat system
only as an illustration (it is not practically useful). 

For data-flow, the flat system is less precise, but still practically useful (simplicity may outweigh 
precision). As discussed in Section~X, the structural system is necessary when we allow arbitrary 
recursion and cannot (easily) determine the number of required values statically.

% --------------------------------------------------------------------------------------------------

\begin{figure}[t]
\begin{equation*}
\tyrule{var}{}
  {\coctx{x \!:\! \tau}{\alift{\cclrd{0}}} \vdash x : \tau} 
\end{equation*}
\begin{equation*}
\tyrule{prev}
  {\coctx{\Gamma}{\aclrd{\textbf{r}}} \vdash e : \tau}
  {\coctx{\Gamma}{1 + \aclrd{\textbf{r}}} \vdash \kvd{prev}~e : \tau}  
\end{equation*}
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma_1}{\aclrd{\textbf{r}}} \vdash e_1 : \tau_1 \xrightarrow{\cclrd{t}} \tau_2 \quad 
    \coctx{\Gamma_2}{\aclrd{\textbf{s}}} \vdash e_2 : \tau_1}
  { \coctx{\Gamma_1, \Gamma_2}{\aclrd{\textbf{r}} \cons (\cclrd{t} + \aclrd{\textbf{s}})} \vdash e_1 \, e_2 : \tau_2} 
\end{equation*}
\begin{equation*}
\tyrule{weak}
  {\coctx{\Gamma}{ \aclrd{\textbf{r}} } \vdash e : \sigma}
  {\coctx{\Gamma,x \!:\! \tau}{\aclrd{\textbf{r}} \cons \alift{ \cclrd{0} }} \vdash e : \sigma} 
\end{equation*}
\begin{equation*}
\tyrule{contr}
  {\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}
  {\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\textnormal{max}(\cclrd{s},\cclrd{t})} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma}
\end{equation*}

\caption{Structural coeffect bounded reuse analysis}
\label{fig:applications-struct-df}
\vspace{-1em}
\end{figure}

% --------------------------------------------------------------------------------------------------

\paragraph{Type system.} 
The type system in Figure~\ref{fig:applications-struct-df} annotates the variable context with a
vector of integers. This is similar as in the bounded reuse system, but the integers \emph{mean} a
different thing. Consequently, they are also calculated differently. We omit rules that are the
same for all structural coeffect systems (exchange, lambda abstraction).

In data-flow, we annotate both used variables (\emph{var}) and unused variables (\emph{weak}) with
$0$, meaning that no past values are required. This is the same as in flat data-flow, but different
from bounded reuse and liveness (where difference between using and not using a variable matters).
Primitive requirements are introduced by the (\emph{prev}) rule, which increments the annotation of
all variables in the context.

In flat data-flow, we identified sequential composition and point-wise composition as two primitive
operations that were used in the (flat) application. In the structural system, these are used in 
(\emph{app}) and (\emph{contr}), respectively. Thus application combines coeffect annotations using
$+$ and contraction using \emph{max}. This contrasts with bounded reuse, which uses $\ast$ and $+$,
respectively.

\paragraph{Example.} As an example, consider a function $\lambda x.\kvd{prev}~(y+x)$ applied to an argument
$\kvd{prev}~(\kvd{prev}~y)$. The body of the function accesses the past value of two variables, one free
and one bound. The (\emph{abs}) rule splits the annotations between the declaration-site and call-site
of the function:
%
\begin{equation*}
\tyrule{abs}
  {\coctx{y\!:\!\mathbb{Z}, x\!:\!\mathbb{Z}}{\alift{1, 1}} \vdash \kvd{prev}~(y+x) : \mathbb{Z} }
  {\coctx{y\!:\!\mathbb{Z}}{\alift{1}} \vdash \lambda x . \kvd{prev}~(y+x) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} }
\end{equation*}
%
The expression always requires the previous value of $y$ and adds it to a previous value of the 
parameter $x$. Evaluating the value of the argument $\kvd{prev}~(\kvd{prev}~y)$ requires two past 
values of $y$ and so the overall requirement for the (free) variable $y$ is $3$ past values. In 
order to use the contraction rule, we rename $y$ to $y'$ in the argument:
%
\begin{equation*}
\inference
  { \coctx{y\!:\!\mathbb{Z}}{\alift{1} } \vdash \lambda x.~(\ldots) : \mathbb{Z} \xrightarrow{\cclrd{1}} \mathbb{Z} &
    \coctx{x\!:\!\mathbb{Z}}{\alift{2}} \vdash (\kvd{prev}~(\kvd{prev}~y') : \mathbb{Z} }
{\inference
  { \coctx{y\!:\!\mathbb{Z}, y'\!:\!\mathbb{Z}}{\alift{1,3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y')) : \mathbb{Z} }
  { \coctx{y\!:\!\mathbb{Z}}{\alift{3}} \vdash (\lambda x.\kvd{prev}~(y+x))~(\kvd{prev}~(\kvd{prev}~y)) : \mathbb{Z} } }
\end{equation*}
%
The derivation uses (\emph{app}) to get requirements $\alift{1,3}$ and then (\emph{contr}) to take 
the maximum, showing three past values are sufficient. 

Note that we get the same requirements when we perform $\beta$ reduction of the expression. 
Substituting the argument for $x$ yields the expression $\kvd{prev}~(y+(\kvd{prev}~(\kvd{prev}~y)))$. 
Semantically, this performs stream lookups $y[1]$ and $y[3]$ where the indices are the 
number of enclosing $\kvd{prev}$ constructs.

\paragraph{Semantics.}
To define the semantics of our structural data-flow language, we can use the same approach as when
adapting flat liveness to structural liveness. Rather than wrapping the whole context in some wrapper
(list or option type), we now wrap individual components of the product representing the variables
in the context. 

The result is similar as the structure used for bounded reuse. The only difference is that, given
a variable annotated with $\cclrd{r}$, we need $1+\cclrd{r}$ values. That is, we need the current
value, followed by $\cclrd{r}$ past values:
%
\begin{equation*}
\begin{array}{l}
\sem{\coctx{x_1\!:\!\tau_1, \ldots, x_n\!:\!\tau_n}{ \alift{\cclrd{r_1}, \ldots, \cclrd{r_n}} } \vdash e : \tau} 
  ~:~ (\tau^{(\cclrd{r_1}+1)}_1 \times \ldots \times \tau^{(\cclrd{r_n}+1)}_n) \rightarrow \tau\\
\sem{\tau_1 \xrightarrow{\cclrd{s}} \tau_2} ~=~ \tau_1^{(\cclrd{s}+1)} \rightarrow \tau_2
\end{array}
\end{equation*}
%
Despite the similarity with the semantics for bounded reuse, the values here \emph{represent}
different things. Rather than providing multiple copies of a value (out of which each can be
used just once), the pair provides past values (that can be reused and freely accessed).
To illustrate the behaviour we consider the semantics of the \kvd{prev} construct and of the
structural contraction rule:
%
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{prev}}
\begin{array}{l}
\sem{\coctx{\Gamma}{\alift{(\cclrd{s}_1 + 1), \ldots, (\cclrd{s}_n + 1)}} \vdash \kvd{prev}~e : \tau} = \\[-0.25em]
  \qquad\lambda ((x_{1,0}, \ldots, x_{1,{\cclrd{s}_1 + 1}}), \ldots, (x_{n,0}, \ldots, x_{n,{\cclrd{s}_n + 1}})) \rightarrow \\[-0.25em]
\qquad\qquad\sem{\coctx{\Gamma}{\alift{\cclrd{s}_1, \ldots, \cclrd{s}_n}} \vdash e : \tau}\\[-0.25em]
\qquad\qquad\qquad ((x_{1,0}, \ldots, x_{1,\cclrd{s}_1}), \ldots, (x_{n,0}, \ldots, x_{n,\cclrd{s}_n}))
\end{array}
\end{equation*}
%
\begin{equation*}
\hspace{-0.5em}
\tag{\emph{contr}}
\begin{array}{l}
\sem{\coctx{\Gamma_1,x\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\textnormal{max}(\cclrd{s},\cclrd{t})} \cons \aclrd{\textbf{q}}} \vdash \subst{\subst{e}{z}{x}}{y}{x} : \sigma} =\\[-0.25em] 
\qquad  \lambda(\mathbf{v_1}, (x_0, x_1, \ldots, x_{ \textnormal{max}(\cclrd{s},\cclrd{t}) }), \mathbf{v_2}) \rightarrow \\[-0.25em]
\qquad\qquad\sem{\coctx{\Gamma_1,y\!:\!\tau,z\!:\!\tau,\Gamma_2}{\aclrd{\textbf{r}} \cons \alift{\cclrd{s},\cclrd{t}} \cons \aclrd{\textbf{q}}} \vdash e : \sigma}\\[-0.25em]
\qquad\qquad\qquad (\mathbf{v_1}, (x_0, \ldots, x_{\cclrd{s}}), (x_0, \ldots, x_{\cclrd{t}} ), \mathbf{v_2})
\end{array}
\end{equation*}
%
In (\emph{prev}), the semantic function is called with an argument that stores values of $n$
variables, such that a variable $x_i$ has values ranging from $x_{i,0}$ to $x_{i,\cclrd{s}_i + 1}$.
Thus, there is one current value, followed by $\cclrd{s_i} + 1$ past values. The expression $e$
nested under $\kvd{prev}$ requires only $\cclrd{s_i}$ past values and so the semantics simply
drops the last value.

In the (\emph{contr}) rule, the semantic function receives $\emph{max}(\cclrd{s}, \cclrd{t})$ values
of a specific variable $x$. It needs to produce values for two separate variables, $y$ and $z$ that
require $\cclrd{s}$ and $\cclrd{t}$ past values. Both of these numbers are certainly smaller than 
(or equal to) the number of values available. Thus we simply take the first values. Unlike in the
contraction for BLL, the values are duplicated and the same values are used for both variables.

\paragraph{Summary.}
Two of the structural examples shown so far (liveness and data-flow) extend an earlier flat 
version of a similar system. We discuss this relation in general later. However, a flat system 
can generally be turned into a structural one -- although this only gives a useful system when
the flat version captures properties related to variables.

The data-flow example demonstrates that the a flat system can also be turned into structural 
system. In general, this only works for systems where lambda abstraction duplicates context
requirements (as in Figure~\ref{fig:applications-flat-liveness}). 

% --------------------------------------------------------------------------------------------------

\subsection{Security, tainting and provenance}
Tainting is a mechanism where variables coming from potentially untrusted sources are marked
(\emph{tainted}) and the use of such variables is disallowed in contexts where untrusted input
can cause security issues or other problems. Tainting can be done dynamically as a runtime mark
(e.g.~in the Perl language) or statically using a type system. Tainting can be viewed as a special
case of \emph{provenance tracking}, known from database systems \cite{app-provenance-db}, where
values are annotated with more detailed information about their source.

Statically typed systems that based on tainting have been use to prevent cross-site scripting
attacks \cite{app-tainting-xss} and a well known attack known as SQL injection
\cite{app-tainting-sql,app-tainting-wasp}. In the latter chase, we want to check that SQL commands 
cannot be directly constructed from, potentially dangerous, inputs provided by the user. Consider the 
type checking of the following expression in a context containing variables \ident{id} and \ident{msg}:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{name} = \ident{query}(\str{SELECT Name WHERE Id = \%1}, \ident{id})\\[-0.25em]
\ident{msg}~+~\ident{name}
\end{array}
\end{equation*}
%
In this example, \ident{id} must not come directly from a user input, because \ident{query} requires 
untainted string. Otherwise, the attacker could specify values such as \str{1; DROP TABLE Users}. 
The variable \ident{msg} may or may not be tainted, because it is not used in protected context 
(i.e.~to construct an SQL query). 

In runtime checking, all (string) values need to be wrapped in an object that stores Boolean 
flag (for tainting) or more complex data (for provenance). In static checking, the information
need to be associated with the variables in the variable context. 

% --------------------------------------------------------------------------------------------------

\paragraph{Core dependency calculus.}
The checking of tainting is a special case of checking of the \emph{non-interference} property 
in \emph{secure information flow}. There, the aim is to guarantee that sensitive information (such
as credit card number) cannot be leaked to contexts with low secrecy (e.g.~sent via an unsecured
network channel). Volpano et al. \cite{app-secure-flow} provide the first (provably) sound type 
system that guarantees non-inference and Sabelfeld et al. \cite{app-secure-information-flow} survey
more recent work. The checking of information flows has been also integrated (as a single-purpose
extension) in the FlowCaml \cite{app-security-flowcaml} language. Finally, Russo et al. and 
Swamy et al. \cite{monad-secure-flow,monads-lightweight-ml} show that the properties can be checked
using a monadic library.

Systems for secure information flow typically define a lattice of security classes $(\mathcal{S}, \leq)$
where $\mathcal{S}$ is a finite set of classes and an ordering. For example a set $\{\ident{L}, \ident{H}\}$ 
represents low and high secrecy, respectively with $\ident{L} \leq \ident{H}$ meaning that low security
values can be treated as high security (but not the other way round).

\paragraph{Implicit flows.}
An important aspect of secure information flow is called \emph{implicit flows}. Consider the following
example which returns either $y$ or zero, depending on the value of $x$:
%
\begin{equation*}
\kvd{let}~z = \kvd{if}~x>0~\kvd{then}~y~\kvd{else}~0
\end{equation*}
%
If the value of $y$ is high-secure, then $z$ becomes high-secure after the assignment
(this is an \emph{explicit} flow). However, if $x$ is high-secure, then the value of
$z$ becomes high-secure, regardless of the security level of $y$, because the fact whether an 
assignment is performed or not performed leaks information in its own (this is an 
\emph{implicit} flow).

Abadi et al. realized that there is a number of analyses similar to secure information flow
and proposed to unify them using a single model called Dependency Core Calculus (DCC) \cite{app-dcc}.
It captures other cases where some information about expression relies on properties of variables
in the context where it executes.  The DCC captures, for example, \emph{binding time analysis}
\cite{app-binding-time-analysis}, which detects which parts of programs can be partially evaluated
(do not depend on user input) and \emph{program slicing} \cite{app-slicing-survey} that identifies
parts of programs that contribute to the output of an expression.

\paragraph{Coeffect systems.}
The work outlined in this section is another area where coeffect systems could be applied.
We do not develop coeffect systems for tracking of tainting, security and provenance in details,
but briefly mention some examples in the upcoming chapters.

The systems work in the same way as the examples discussed already. For example, consider the
tainting example with the \ident{query} function calling an SQL database. To capture such 
tainting, we annotate variables with $\cclrd{\ident{T}}$ for \emph{tainted} and with 
$\cclrd{\ident{U}}$ for \emph{untainted}. Simply accessing variable does not introduce taint, 
but using a variable in certain contexts -- such as in arguments of \ident{query} -- does introduce
a taint. This is captured using the standard application rule (\emph{app}):
%
\begin{equation*}
\tyrule{app}
  { \coctx{\Gamma}{\aclrd{r}} \vdash \ident{query} : \ident{string} \xrightarrow{\cclrd{\ident{T}}} \ident{Table} \qquad
    \coctx{\ident{id}:\ident{string}}{ \alift{\cclrd{\ident{U}}}} \vdash \ident{id} : \ident{string} }
  { \coctx{\Gamma, \ident{id}:\ident{string}}{ \aclrd{r} \cons \alift {\cclrd{\ident{T}}} \vdash \ident{query}(\str{...}, \ident{id}) : \ident{Table} } }
\end{equation*}
%
The derivation assumes that \ident{query} is a standard function that requires the parameters
to be tainted (it does not have to be a built-in language construct). The argument is a 
variable and so it is not tainted in the assumptions.

In the conclusion, we need to derive an annotation for the variable \ident{id}. To do this, we
combine \cclrd{\ident{T}} (from the function) and \cclrd{\ident{U}} (from the argument). In case
of tainting, the variable is tainted whenever it is already tainted \emph{or} the function marks
it as tainted. For different kinds of annotations, the composition would work differently -- for
example, for provenance, we could union the \emph{set} of possible data sources, or even combine 
\emph{probability distributions} modelling the influence of different sources on the value.
However, expanding such ideas is beyond the scope of this thesis.

% ==================================================================================================

\section{Beyond passive contexts}

In both flat and structural systems discussed so far, the context provides additional data (resources, 
implicit parameters, historical values) or meta-data (security, provenance). However, \emph{within} 
the language, it is impossible to write a function that modifies the context. We use the term 
\emph{passive} context for such applications. 

There is a number of systems that also capture contextual properties, but that make it possible to 
\emph{change} the context -- not just be evaluating certain code block in a different scope (e.g. by 
wrapping it in $\ident{prev}$ in data-flow), but also by calling a function that, for example, acquires 
new capabilities and returns those to the caller. While this thesis focuses on systems with passive 
contexts, we briefly consider the most important examples of the \emph{active} variant.

% --------------------------------------------------------------------------------------------------

\paragraph{Calculus of capabilities.}
\label{sec:applications-active-ccc}

Crary et al. \cite{app-capabilities} introduced the Calculus of Capabilities to provide 
a sound system with region-based memory management for low-level code that can be easily 
compiled to assembly language. They build on the work of Tofte and Talpin \cite{app-region-memory}
who developed an effect system (as discussed in Section~\ref{sec:path-sem-effects}) that uses
lexically scoped \emph{memory regions} to provide an efficient and controlled memory management.

In the work of Tofte and Talpin, the context is \emph{passive}. They extend a simple functional language
with the \kvd{letrgn} construct that defines a new memory region, evaluates an expression (possibly)
using memory in that region and then deallocates the memory of the region:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\[-0.25em]
\quad \kvd{letrgn}~\rho~\kvd{in}\\[-0.25em]
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho ~\ident{input}~\kvd{in}\\[-0.25em]
\quad \ident{x} :=\, !\ident{x} + 1;~ !\ident{x}
\end{array}
\end{equation*}
%
The memory region $\rho$ is a part of the context, but only in the scope of the body of 
\kvd{letrgn}. It is only available to the last two lines which allocate a memory cell in the region,
increment a value in the region and then read it. The region is de-allocated when the execution 
leaves its lexical scope -- there is no way to allocate a region inside a function and pass it back 
to the caller.

Calculus of capabilities differs in two ways. First, it allows explicit allocation and deallocation
of memory regions (and so region lifetimes do not follow strict LIFO ordering). Second, it
uses continuation-passing style. We ignore the latter aspect. The following example is almost 
identical as the previous one:
%
\begin{equation*}
\begin{array}{l}
\kvd{let}~\ident{calculate} = \lambda \ident{input} \rightarrow\\[-0.25em]
\quad \kvd{letrgn}~\rho~\kvd{in}\\[-0.25em]
\quad \kvd{let}~\ident{x} = \kvd{ref}_\rho ~\ident{input}~\kvd{in}\\[-0.25em]
\quad \ident{x} :=\, !\ident{x} + 1;~ \ident{x}
\end{array}
\end{equation*}
%
The difference is that the example does not return the \emph{value} of a reference using 
$!\ident{x}$, but returns the reference $\ident{x}$ itself. The reference is allocated in a newly 
created region $\rho$. Together with the value, the function returns a \emph{capability} to access 
the region $\rho$.

This is where systems with active context differ. To type check such programs, we do not only need
to know what context is required to call \ident{calculate}. We also need to know what effects it
has on the context when it evaluates and the current context meeds to be updated after a function 
call. 

\paragraph{Active contexts.}
In a systems with passive contexts, we only need an annotation that specifies the required 
context. In semantics, this is reflected by having some structure (data type) $\C$ over the
\emph{input} of the function. Without giving any details, the semantics generally has the 
following structure:
%
\begin{equation*}
\sem{\tau_1 \xrightarrow{\cclrd{r}} \tau_2} = \C^{\cclrd{r}} \tau_1 \rightarrow \tau_2
\end{equation*}
%
Systems with active contexts require two annotations -- one that specifies the context required
before the call is performed and one that specifies how the context changes after the call (this
could be either a \emph{new} context or \emph{update} to the original context). Thus the structure
of the semantics would look as follows:
%
\begin{equation*}
\sem{\tau_1 \xrightarrow{\cclrd{r}, \cclrd{s}} \tau_2} = \C^{\cclrd{r}} \tau_1 \rightarrow \M^{\cclrd{s}} \tau_2
\end{equation*}
%
In case of Calculus of Capabilities, both of the structures could be the same and they could
carry a set of available memory regions. In this thesis, we focus only on passive contexts. 
However, we briefly consider the problem of active contexts in the Section~X of the future work 
chapter.

% --------------------------------------------------------------------------------------------------

\paragraph{Software updating.}
Another example of a system that uses contextual information actively is dynamic software updating 
(DSU) \cite{app-dsu-programs,app-dsu}. The DSU systems have the ability to update programs at
runtime without stopping them. For example, Proteus developed by Stoyle et al. \cite{app-dsu-mutatis} 
investigates what language support is needed to enable safe dynamic software updating in C-like 
languages. The system is based on the idea of capabilities.

The system distinguishes between \emph{concrete} uses and \emph{abstract} uses of a value. When
a value is used concretely, the program examines its representation (and so it is not safe to
change the representation during an update). An abstract use of a value does not need to examine
the representation and so updating the value does not break the program.

The Proteus system uses capabilities to restrict what types may be used concretely after any point
in the program. All other types, not listed in the capability, can be dynamically updated as this
will not change concrete representation of types accessed later in the evaluation.

Similarly to Capability Calculus, capabilities in DSU can be changed by a function call. For 
example, calling a function that may update certain types makes it impossible to use those types
concretely following the function call. This means that DSU uses the context \emph{actively}
and not just \emph{passively}.

%===================================================================================================

\section{Summary}

This chapter served two purposes. The first aim was to present existing work on programming 
languages and systems that include some notion of \emph{context}. Because there was no well-known
abstraction capturing contextual properties, the languages use a wide range of formalisms -- including
from principled approaches based on comonads, ad-hoc type system extensions and static analyses as
well as approaches based on monads. We looked at a number of applications inclding Haskell's implicit 
parameters and type classes, data-flow languages such as Lucid, liveness analysis and also a number of 
security properties. 

The second aim of this chapter was to re-formulate the existing work in a more uniform style and thus
reveal that all \emph{context-dependent} languages share a common structure. In the upcoming three 
chapters, we identify the common structure more precisely and develop three calculi to capture it. We 
will then be able to re-create many of the examples discussed in this chapter by instantiating our 
unified calculi.

This chapter was divided into two major sections. First, we looked at \emph{flat} systems, which
track whole-context properties. Next, we look a \emph{structural} systems, which track per-variable
properties. Both of the variants are useful and important -- for example, implicit parameters can
only be expressed as \emph{flat} system, but liveness analysis is only useful as \emph{structural}.
For this reason, we explore both of these variants in this thesis (Chapter~\ref{ch:flat} and 
Chapter~\ref{ch:structural}, respectively). We can, however, unify the two variants into a single
system discussed in Chapter~\ref{ch:unified}.
